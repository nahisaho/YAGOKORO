{
  "paper": {
    "id": "2306.01116v1",
    "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
    "abstract": "Large language models are commonly trained on a mixture of filtered web data and curated high-quality corpora, such as social media conversations, books, or technical papers. This curation process is believed to be necessary to produce performant models with broad zero-shot generalization abilities. However, as larger models requiring pretraining on trillions of tokens are considered, it is unclear how scalable is curation and whether we will run out of unique high-quality data soon. At variance with previous beliefs, we show that properly filtered and deduplicated web data alone can lead to powerful models; even significantly outperforming models from the state-of-the-art trained on The Pile. Despite extensive filtering, the high-quality data we extract from the web is still plentiful, and we are able to obtain five trillion tokens from CommonCrawl. We publicly release an extract of 600 billion tokens from our RefinedWeb dataset, and 1.3/7.5B parameters language models trained on it.",
    "authors": [
      "Guilherme Penedo",
      "Quentin Malartic",
      "Daniel Hesslow",
      "Ruxandra Cojocaru",
      "Alessandro Cappelli",
      "Hamza Alobeidli",
      "Baptiste Pannier",
      "Ebtesam Almazrouei",
      "Julien Launay"
    ],
    "published": "2023-06-01T20:03:56.000Z",
    "updated": "2023-06-01T20:03:56.000Z",
    "primaryCategory": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "pdfUrl": "https://arxiv.org/pdf/2306.01116v1",
    "absUrl": "https://arxiv.org/abs/2306.01116v1"
  },
  "chunks": [
    {
      "id": "2306.01116v1-chunk-0",
      "content": "Guilherme Penedo 1 Quentin Malartic 2\n\nDaniel Hesslow 1 Ruxandra Cojocaru 2 Alessandro Cappelli 1 Hamza Alobeidli 2 Baptiste Pannier 2 1 3\n\nEbtesam Almazrouei Julien Launay https://huggingface.co/datasets/tiiuae/falcon-refinedweb",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "The Falcon LLM team",
        "chunkIndex": 0,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-1",
      "content": "Large language models are commonly trained on a mixture of filtered web data and curated 'high-quality' corpora, such as social media conversations, books, or technical papers. This curation process is believed to be necessary to produce performant models with broad zero-shot generalization abilities. However, as larger models requiring pretraining on trillions of tokens are considered, it is unclear how scalable is curation and whether we will run out of unique high-quality data soon. At variance with previous beliefs, we show that properly filtered and deduplicated web data alone can lead to powerful models; even significantly outperforming models from the state-of-the-art trained on The Pile. Despite extensive filtering, the high-quality data we extract from the web is still plentiful, and we are able to obtain five trillion tokens from CommonCrawl.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "Abstract",
        "chunkIndex": 1,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-2",
      "content": "he state-of-the-art trained on The Pile. Despite extensive filtering, the high-quality data we extract from the web is still plentiful, and we are able to obtain five trillion tokens from CommonCrawl. We publicly release an extract of 600 billion tokens from our REFINEDWEB dataset, and 1.3/7.5B parameters language models trained on it * .\n\nFigure 1. Models trained on REFINEDWEB alone outperform models trained on curated corpora. Zero-shot performance on our main-agg task aggregate (see Section 4.1 for details). At equivalent compute budgets, our models significantly outperform publicly available models trained on ▼ The Pile, and match the performance of the ■ GPT-3 models when tested within our evaluation setup.\n\n<!-- image -->\n\n1 LightOn 2 Technology Innovation Institute, 9639 Masdar City, Abu Dhabi, United Arab Emirates 3 LPENS, ´ Ecole normale sup´ erieure. Contact: &lt; falconllm@tii.ae &gt; .\n\n* Details about how to access Falcon LLM open source is available on falconllm.tii.ae",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "Abstract",
        "chunkIndex": 2,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-3",
      "content": "ity, Abu Dhabi, United Arab Emirates 3 LPENS, ´ Ecole normale sup´ erieure. Contact: &lt; falconllm@tii.ae &gt; .\n\n* Details about how to access Falcon LLM open source is available on falconllm.tii.ae\n\n1\n\nTable 1. REFINEDWEB improves on existing English pretraining datasets for large language models by combining extensive filtering with stringent deduplication at unprecedented scale. For additional details, see the full version in Table 12 of Appendix F.3.\n\n| Dataset                    | Size                       | Availability         | Web                  | CC Processing                                                                                             | Deduplication                                                                                                                 |\n|----------------------------|----------------------------|----------------------|----------------------|-------------------------------------------------------------------------------------------",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "Abstract",
        "chunkIndex": 3,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-4",
      "content": "|\n|----------------------------|----------------------------|----------------------|----------------------|-----------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------|\n| MASSIVE WEB DATASETS       | MASSIVE WEB DATASETS       | MASSIVE WEB DATASETS | MASSIVE WEB DATASETS | MASSIVE WEB DATASETS                                                                                      | MASSIVE WEB DATASETS                                                                                                          |\n| C4 OSCAR-21.09 OSCAR-22.01 | ∼ 360 GT ∼ 370 GT ∼ 283 GT | Public Public Public | 100 % 100 % 100 %    | Rules + NSFW words blocklist Built at the line-level Line-level rules + optional rules &NSFWURL blocklist | Exact: spans of 3 sentences Exact : per line ( ∼ 55% removed) Exact : per line (optional, not used",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "Abstract",
        "chunkIndex": 4,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-5",
      "content": "+ NSFW words blocklist Built at the line-level Line-level rules + optional rules &NSFWURL blocklist | Exact: spans of 3 sentences Exact : per line ( ∼ 55% removed) Exact : per line (optional, not used for results in this paper) |\n| CURATED DATASETS           | CURATED DATASETS           | CURATED DATASETS     | CURATED DATASETS     | CURATED DATASETS                                                                                          | CURATED DATASETS                                                                                                              |\n| ■ GPT-3                    | 300 GT                     | Private              | 60 %                 | Content filter trained on known high-quality sources                                                      | Fuzzy : MinHash ( ∼ 10% removed)                                                                                              |\n| ▼ The Pile                 | ∼ 340 GT                   | Public               | 18",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "Abstract",
        "chunkIndex": 5,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-6",
      "content": "h ( ∼ 10% removed)                                                                                              |\n| ▼ The Pile                 | ∼ 340 GT                   | Public               | 18 %                 | jusText for extraction, con- tent filter trained on curated data                                          | Fuzzy : MinHash ( ∼ 26% removed)                                                                                              |\n| ⋆ PaLM                     | 780 GT                     | Private              | 27 %                 | Filter trained on HQ data                                                                                 | Unknown                                                                                                                       |\n| OURS                       | OURS                       | OURS                 | OURS                 | OURS",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "Abstract",
        "chunkIndex": 6,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-7",
      "content": "OURS                       | OURS                       | OURS                 | OURS                 | OURS                                                                                                      | OURS                                                                                                                          |\n| REFINEDWEB                 | ∼ 5 , 000 GT               | Public (600GT)       | 100%                 | trafilatura for text extrac- tion, document and line-level rules, NSFW URL blocklist                      | Exact & fuzzy : exact sub- string+MinHash ( ∼ 50% removed)                                                                    |",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "Abstract",
        "chunkIndex": 7,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-8",
      "content": "Progress in natural language processing is increasingly driven by sheer compute scale alone (Sevilla et al., 2022): as more compute is expended to train large language models (LLM), they gain and exhibit powerful emergent capabilities (Brown et al., 2020; Wei et al., 2022). To best benefit from scaling, recent scaling laws dictate that both model size and dataset size should jointly be increased (Hoffmann et al., 2022). This is at variance with earlier findings, which had argued that scaling should focus on model size first and foremost, with minimal data scaling (Kaplan et al., 2020).\n\nThis joint scaling paradigm raises significant challenges: although plentiful, text data is not infinite, especially so when considerations on data quality and licensing are taken into account-leading some researchers to argue scaling may soon be bottlenecked by data availability (Villalobos et al., 2022).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "1. Introduction",
        "chunkIndex": 8,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-9",
      "content": "specially so when considerations on data quality and licensing are taken into account-leading some researchers to argue scaling may soon be bottlenecked by data availability (Villalobos et al., 2022). Concretely, optimally training a GPT-3 sized model (175B parameters) would require no less than 3,500 billion tokens of text according to Hoffmann et al. (2022). This is twice as much as the largest pretraining datasets ever demonstrated (Hoffmann et al., 2022; Touvron et al., 2023), and ten times more than the largest publicly available English datasets such as OSCAR (Ortiz Su´ arez et al., 2019), C4 (Raffel et al., 2020), or The Pile (Gao et al., 2020).\n\nMassively scaling-up pretraining data is made even more challenging by the fact LLMs are commonly trained using a mixture of web crawls and so-called 'high-quality' data (Brown et al., 2020; Gao et al., 2020).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "1. Introduction",
        "chunkIndex": 9,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-10",
      "content": "scaling-up pretraining data is made even more challenging by the fact LLMs are commonly trained using a mixture of web crawls and so-called 'high-quality' data (Brown et al., 2020; Gao et al., 2020). Typical highquality corpora include curated sources of books, technical documents, human-selected web pages, or social media conversations. The increased diversity and quality brought forth by these curated corpora is believed to be a key component of performant models (Scao et al., 2022b). Unfortunately, curation is labour intensive: typically, each source requires specialized processing, while yielding a limited amount of data. Furthermore, licensed sources raise legal challenges.\n\nNevertheless, most pretraining data is still sourced from massive web crawls which can be scaled up to trillions of tokens with limited human intervention. However, the quality of this data has traditionally been seen as (much) inferior to that of the manually curated data sources.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "1. Introduction",
        "chunkIndex": 10,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-11",
      "content": "can be scaled up to trillions of tokens with limited human intervention. However, the quality of this data has traditionally been seen as (much) inferior to that of the manually curated data sources. Even finely processed sources of web data, such as C4 (Raffel et al., 2020) or OSCAR (Ortiz Su´ arez et al., 2019), are regarded as inferior to curated corpora for LLMs (Rae et al., 2021; Scao et al., 2022b), producing less performant models.\n\nTo sustain the ever-increasing data needs of larger and larger LLMs, and to streamline data pipelines and reduce the need for human-intensive curation, we propose to explore how web data can be better processed to significantly improve its quality, resulting in models as capable, if not more capable, than models trained on curated corpora.\n\nContributions. We make the following contributions:",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "1. Introduction",
        "chunkIndex": 11,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-12",
      "content": "better processed to significantly improve its quality, resulting in models as capable, if not more capable, than models trained on curated corpora.\n\nContributions. We make the following contributions:\n\n- We introduce REFINEDWEB , a high-quality five trillion tokens web-only English pretraining dataset;\n- We demonstrate that web data alone can result in models outperforming both public and private curated corpora , as captured by zero-shot benchmarks, challenging current views about data quality;\n- We publicly release a 600B tokens extract of RefinedWeb, and 1/7B parameters LLMs trained on it , to serve as a new baseline high-quality web dataset for the natural language processing community.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "1. Introduction",
        "chunkIndex": 12,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-13",
      "content": "Pretraining data for large language models. Early large language models identified the importance of datasets with long, coherent documents (Radford et al., 2018; Devlin et al., 2019). Moving on from the previously used sentencewise datasets (Chelba et al., 2013), they instead leveraged document-focused, single-domain corpora like Wikipedia or BookCorpus (Zhu et al., 2015). As models increased in scale, datasets based on massive web-scrape gained prevalence (Ortiz Su´ arez et al., 2019; Raffel et al., 2020). However, further work argued that these untargeted web scrape fell short of human-curated data (Radford et al., 2019), leading to the wide adoption of curated datasets such as The Pile (Gao et al., 2020), which combine web data with books, technical articles, and social media conversations. At scale, it has been proposed to emulate the human curation process by leveraging weak signals: for instance, by crawling the top links of a forum (Gokaslan et al., 2019).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "2. Related works",
        "chunkIndex": 13,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-14",
      "content": "social media conversations. At scale, it has been proposed to emulate the human curation process by leveraging weak signals: for instance, by crawling the top links of a forum (Gokaslan et al., 2019). Targeted corpora can also produce domain-specific models (Beltagy et al., 2019), or broaden the expressiveness of models (e.g., for conversational modalities Adiwardana et al. (2020); Thoppilan et al. (2022)). Latest large language models (Brown et al., 2020; Rae et al., 2021; Chowdhery et al., 2022; Scao et al., 2022a) are trained on giant aggregated corpora, combining both massive web-scrape and so-called 'high-quality' curated single-domain sources (e.g., news, books, technical papers, social media conversations). These targeted sources are often upsampled-from one to five times is most common-to increase their representation in the final dataset.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "2. Related works",
        "chunkIndex": 14,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-15",
      "content": ".g., news, books, technical papers, social media conversations). These targeted sources are often upsampled-from one to five times is most common-to increase their representation in the final dataset. The diversity and 'higher-quality' brought fourth by these aggregated datasets is thought to be central to model quality; web data alone is considered insufficient to train powerful large language models (Liu et al., 2019; Scao et al., 2022b).\n\nPipelines for web data. Massive web datasets are typically built upon CommonCrawl, a publicly available scrape of the internet, which has now been running for 12 years and has collected petabytes of data. Working with data scraped from all over the internet presents unique challenges: notably, a significant portion is low-quality machine-generated spam or pornographic content (Trinh &amp; Le, 2018; Kreutzer et al., 2022). Accordingly, training on unfiltered web data is undesirable, resulting in poorly performing models (Raffel et al., 2020).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "2. Related works",
        "chunkIndex": 15,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-16",
      "content": "ed spam or pornographic content (Trinh &amp; Le, 2018; Kreutzer et al., 2022). Accordingly, training on unfiltered web data is undesirable, resulting in poorly performing models (Raffel et al., 2020). Modern pipelines focus on filtering out this undesirable content (Wenzek et al., 2020). Broadly speaking, these pipelines usually combine a variety of stages: (1) language identification , leveraging inexpensive n-gram models (e.g., fastText Joulin et al. (2016)); (2) filtering rules and heuristics , such as only keeping lines with valid punctuation, discarding lines with too many symbols, or removing documents containing banned words (Grave et al., 2018; Raffel et al., 2020); (3) ML-based quality filtering , using lightweight models trained on known gold data to identify similar high-quality web documents (Wenzek et al., 2020; Brown et al., 2020); (4) deduplication , removing either exact duplicate spans or similar documents (Lee et al., 2022).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "2. Related works",
        "chunkIndex": 16,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-17",
      "content": "n gold data to identify similar high-quality web documents (Wenzek et al., 2020; Brown et al., 2020); (4) deduplication , removing either exact duplicate spans or similar documents (Lee et al., 2022). While some filtering is necessary, excessive filtering can introduce undesirable biases in the model. This can overly impact minorities (Dodge et al., 2021), motivating the adoption of practices such as pseudo-crawling, wherein allowed URLs are manually curated (Laurenc ¸on et al., 2022).\n\nDeduplication. Deduplication removes repeated extracts and documents from a dataset: these could either be exact matches, identical in every character, or approximate matches, based on some similarity metric. For exact duplicates, it is common to match exact substrings of a minimum length using suffix arrays (Manber &amp; Myers, 1993).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "2. Related works",
        "chunkIndex": 17,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-18",
      "content": "ery character, or approximate matches, based on some similarity metric. For exact duplicates, it is common to match exact substrings of a minimum length using suffix arrays (Manber &amp; Myers, 1993). For fuzzy duplicates, methods based on locally-sensitive hashes such as MinHash (Broder, 1997) or SimHash (Charikar, 2002) have been adopted for the pretraining data of large language models (Brown et al., 2020; Zeng et al., 2021; Rae et al., 2021). Recently, Abbas et al. (2023) has proposed to leverage embeddings from pretrained models to imbue semantic understanding in approximate matching algorithms. Deduplication has been identified as playing a significant role in improving language models (Allamanis, 2019; Lee et al., 2022). Notably, it reduces memorization (Carlini et al., 2022), which is especially problematic in large models (Carlini et al., 2021).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "2. Related works",
        "chunkIndex": 18,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-19",
      "content": "role in improving language models (Allamanis, 2019; Lee et al., 2022). Notably, it reduces memorization (Carlini et al., 2022), which is especially problematic in large models (Carlini et al., 2021). Furthermore, repeated data has been shown to be increasingly harmful to model quality as parameter count increases (Hernandez et al., 2022): for a 1B parameters model, a hundred duplicates are harmful; at 175B, even a few duplicates could have a disproportionate effect. Concurrently to this work, the Pythia suite of models found that deduplicating The Pile had a limited impact on zero-shot performance (Biderman et al., 2023), questioning whether deduplication is as relevant for curated corpora as it for predominantly web-based datasets.\n\nWe provide an overview of some widely adopted existing pretraining English datasets for LLMs in Table 1, with additional information in Table 12 of Appendix F.3.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "2. Related works",
        "chunkIndex": 19,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-20",
      "content": "for predominantly web-based datasets.\n\nWe provide an overview of some widely adopted existing pretraining English datasets for LLMs in Table 1, with additional information in Table 12 of Appendix F.3. We also note that recent popular open models (Zhang et al., 2022; Touvron et al., 2023) often indirectly leverage The Pile (Gao et al., 2020) by doing a mix-and-match of its components.\n\nFocusing on building a large-scale high-quality web pretraining dataset, we extend upon the state-of-the-art in three ways: (1) we aggregate and combine best-practices for document preparation and filtering across multiple pipelines, and introduce line-wise corrections; (2) we combine both exact and fuzzy deduplication at very large-scale; (3) the scale of our final dataset is unique, with a total 5,000 billion tokens, and a 600 billion tokens extract available for public use with permissive licensing.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "2. Related works",
        "chunkIndex": 20,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-21",
      "content": "deduplication at very large-scale; (3) the scale of our final dataset is unique, with a total 5,000 billion tokens, and a 600 billion tokens extract available for public use with permissive licensing. Training large models on RefinedWeb also lead us to challenge the commonly held belief that web data is strictly worse than curated corpora.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "2. Related works",
        "chunkIndex": 21,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-22",
      "content": "We introduce MDR (MacroData Refinement), a pipeline for filtering and deduplicating web data from CommonCrawl at very large scale. Using MDR, we produce REFINEDWEB , an English pretraining dataset of five trillion tokens based on web data only. We leverage strict filtering and stringent deduplication to uplift the quality of web data, distilling it down to a corpus matching the quality of aggregated corpora used to train state-of-the-art models.\n\nDesign principles. We abide by the following guidelines:\n\n- Scale first. We intend MDR to produce datasets to be used to train 40-200B parameters models, thus requiring trillions of tokens (Hoffmann et al., 2022). For English-only RefinedWeb, we target a size of 3-6 trillion tokens. Specifically, we eschew any labour intensive human curation process, and focus on CommonCrawl instead of disparate single-domain sources.\n- Strict deduplication. Inspired by the work of Lee et al.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3. Macrodata Refinement and RefinedWeb",
        "chunkIndex": 22,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-23",
      "content": "ns. Specifically, we eschew any labour intensive human curation process, and focus on CommonCrawl instead of disparate single-domain sources.\n- Strict deduplication. Inspired by the work of Lee et al. (2022), which demonstrated the value of deduplication for large language models, we implement a rigorous deduplication pipeline. We combine both exact and fuzzy deduplication, and use strict settings leading to removal rates far higher than others have reported.\n- Neutral filtering. To avoid introducing further undesirable biases into the model (Dodge et al., 2021; Welbl et al., 2021), we avoid using ML-based filtering outside of language identification. We stick to simple rules and heuristics, and use only URL filtering for adult content.\n\nTable 2 and Figure 2 outline the full MDR pipeline.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3. Macrodata Refinement and RefinedWeb",
        "chunkIndex": 23,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-24",
      "content": "Reading the data. CommonCrawl is available in either WARC (raw HTML response), or WET files (preprocessed to only include plain text). Individual files correspond to a page at a given URL; these constitute single documents/samples. Working with WET files would spare us from running our own HTML extraction; however, in line with previous works (Gao et al., 2020; Rae et al., 2021), we found WET files to include undesirable navigation menus, ads, and other irrelevant texts. Accordingly, our pipeline starts from raw WARC files, read with the warcio library.\n\nURL filtering. Before undertaking any compute-heavy processing, we perform a first filtering based on the URL alone. This targets fraudulent and/or adult websites (e.g., predominantly pornographic, violent, related to gambling, etc.). We base our filtering on two rules: (1) an aggregated blocklist of 4.6M domains; (2) a URL score, based on the presence of words from a list we curated and weighed by severity.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3.1. Document preparation: reading data, filtering URLs, extracting text, and language identification",
        "chunkIndex": 24,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-25",
      "content": "ted to gambling, etc.). We base our filtering on two rules: (1) an aggregated blocklist of 4.6M domains; (2) a URL score, based on the presence of words from a list we curated and weighed by severity. We found that commonly used blocklists include many false positives, such as popular blogging platforms or even pop culture websites. Furthermore, word-based rules (like the one used in C4, Raffel et al. (2020)) can easily result in medical and legal pages being blocked. Our final detailed rules based on this investigation are shared in Appendix G.1. Since we intend RefinedWeb to be used as part of an aggregate dataset along with curated corpora, we also filtered common sources of high-quality data: Wikipedia, arXiv, etc. The detailed list is available in Appendix G.1.3.\n\nLoading [MathJax]/e t nsions/MathMenu.js Figure 2. Subsequent stages of Macrodata Refinement remove nearly 90% of the documents originally in CommonCrawl.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3.1. Document preparation: reading data, filtering URLs, extracting text, and language identification",
        "chunkIndex": 25,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-26",
      "content": "etailed list is available in Appendix G.1.3.\n\nLoading [MathJax]/e t nsions/MathMenu.js Figure 2. Subsequent stages of Macrodata Refinement remove nearly 90% of the documents originally in CommonCrawl. Notably, filtering and deduplication each result in a halving of the data available: around 50% of documents are discarded for not being English, 24% of remaining for being of insufficient quality, and 12% for being duplicates. We report removal rate (grey) with respect to each previous stage, and kept rate (shade) overall. Rates measured in % of documents in the document preparation phase, then in tokens.\n\n<!-- image -->\n\nTable 2. Macrodata Refinement aggregates best practices from the state-of-the-art and novel approaches (URL scoring, line-wise filtering, etc.) to produce high-quality web data. On deduplication, we note that MDR is unique in both the scale at which it is performed, and in applying subsequently fuzzy and exact substring methods to improve coverage and scalability.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3.1. Document preparation: reading data, filtering URLs, extracting text, and language identification",
        "chunkIndex": 26,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-27",
      "content": "y web data. On deduplication, we note that MDR is unique in both the scale at which it is performed, and in applying subsequently fuzzy and exact substring methods to improve coverage and scalability.\n\n| DOCUMENT PREPARATION                                                        | DOCUMENT PREPARATION                                                 | FILTERING                                                                                 | FILTERING                                                                                 | FILTERING                                                                                          | DEDUPLICATION                                                                                       | DEDUPLICATION                                                  |\n|-----------------------------------------------------------------------------|----------------------------------------------------------------------|---------------------------------------------",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3.1. Document preparation: reading data, filtering URLs, extracting text, and language identification",
        "chunkIndex": 27,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-28",
      "content": "|\n|-----------------------------------------------------------------------------|----------------------------------------------------------------------|-------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------|----------------------------------------------------------------|\n| URL filtering                                                               | Text extraction                                                      | Language identification                                                                   | Document-wise filtering                                                                   | Line-wise filtering",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3.1. Document preparation: reading data, filtering URLs, extracting text, and language identification",
        "chunkIndex": 28,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-29",
      "content": "| Document-wise filtering                                                                   | Line-wise filtering                                                                                | Deduplication                                                                                       | URL deduplication                                              |\n| Aggregated block- list, URL scoring, common HQ sources blocked Appendix G.1 | From WARC using warcio , trafilatura for extraction Barbaresi (2021) | fastText classi- fier from CCNet, thresholding on top language score Wenzek et al. (2020) | In-document repe- tition removal and quality heuristics from MassiveWeb Rae et al. (2021) | Remove undesirable lines (call to actions, navigation buttons, social counters, etc.) Appendix G.2 | Fuzzy deduplication w/ MinHash + exact substring deduplica- tion w/ suffix arrays Lee et al.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3.1. Document preparation: reading data, filtering URLs, extracting text, and language identification",
        "chunkIndex": 29,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-30",
      "content": "021) | Remove undesirable lines (call to actions, navigation buttons, social counters, etc.) Appendix G.2 | Fuzzy deduplication w/ MinHash + exact substring deduplica- tion w/ suffix arrays Lee et al. (2022) | Remove URLs revis- ited across Common- Crawl dumps Section 3.3 |\n\nText extraction. We want to extract only the main content of the page, ignoring menus, headers, footers, and ads among others: Lopukhin (2019) found that trafilatura (Barbaresi, 2021) was the best non-commercial library for retrieving content from blog posts and news articles. Although this is only a narrow subset of the kind of pages making up CommonCrawl, we found this finding to hold more broadly. We use trafilatura for text extraction, and apply extra formatting via regular expressions: we limit new lines to two consecutive ones, and remove all URLs.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3.1. Document preparation: reading data, filtering URLs, extracting text, and language identification",
        "chunkIndex": 30,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-31",
      "content": "we found this finding to hold more broadly. We use trafilatura for text extraction, and apply extra formatting via regular expressions: we limit new lines to two consecutive ones, and remove all URLs.\n\nLanguage identification. We use the fastText language classifier of CCNet (Wenzek et al., 2020) at the documentlevel: it uses characters n-gram and was trained on Wikipedia, supporting 176 languages. We remove documents for which the top language scores below 0.65: this usually corresponds to pages without any natural text. For this paper, we focus on English; RefinedWeb can also be derived for other languages, see Appendix D for details.\n\nThe data we retrieve at this stage, called RW-RAW , corresponds to what we can extract with the minimal amount of filtering. At this stage, only 48% of the original documents are left, mostly filtered out by language identification.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3.1. Document preparation: reading data, filtering URLs, extracting text, and language identification",
        "chunkIndex": 31,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-32",
      "content": "Repetition removal. Due to crawling errors and lowquality sources, many documents contain repeated sequences: this may cause pathological behavior in the final model (Holtzman et al., 2019). We could catch this content at the later deduplication stage, but it is cheaper and easier to catch it document-wise early on. We implement the heuristics of Rae et al. (2021), and remove any document with excessive line, paragraph, or n-gram repetitions.\n\nDocument-wise filtering. A significant fraction of pages are machine-generated spam, made predominantly of lists of keywords, boilerplate text, or sequences of special characters. Such documents are not suitable for language modeling; to filter them out, we adopt the quality filtering heuristics of Rae et al. (2021). These focus on removing outliers in terms of overall length, symbol-to-word ratio, and other criteria ensuring the document is actual natural language.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3.2. Filtering: document-wise and line-wise",
        "chunkIndex": 32,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-33",
      "content": "ality filtering heuristics of Rae et al. (2021). These focus on removing outliers in terms of overall length, symbol-to-word ratio, and other criteria ensuring the document is actual natural language. We note that these filters have to be adapted on a per language basis, as they may result in overfiltering if naively transferred from English to other languages.\n\nLine-wise corrections. Despite the improvements brought forth by using trafilatura instead of relying on preprocessed files, many documents remain interlaced with undesirable lines (e.g., social media counters 3 likes , navigation buttons). Accordingly, we devised a line-correction filter, targeting these undesirable items. If these corrections remove more than 5% of a document, we remove it entirely. See Appendix G.2 for details.\n\nThe data we retrieve at this stage has gone through all of the filtering heuristics in the MDR pipeline. We refer to this dataset as RW-FILTERED .",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3.2. Filtering: document-wise and line-wise",
        "chunkIndex": 33,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-34",
      "content": "we remove it entirely. See Appendix G.2 for details.\n\nThe data we retrieve at this stage has gone through all of the filtering heuristics in the MDR pipeline. We refer to this dataset as RW-FILTERED . Only 23% of the documents of CommonCrawl are left, with around 50% of the documents of RW-Raw removed by the filtering.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3.2. Filtering: document-wise and line-wise",
        "chunkIndex": 34,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-35",
      "content": "After filtering, although data quality has improved, a large fraction of the content is repeated across documents. This may be due to the crawler indirectly hitting the same page multiple times, to boilerplate content being repeated (e.g., licences), or even to plagiarism. These duplicates can strongly impact models, favoring memorization instead of generalization (Lee et al., 2022; Hernandez et al., 2022). Since deduplication is expensive, it has seen limited adoption in public datasets (Ortiz Su´ arez et al., 2019; Raffel et al., 2020). We adopt an aggressive deduplication strategy, combining both fuzzy document matches and exact sequences removal.\n\nFuzzy deduplication. We remove similar documents by applying MinHash (Broder, 1997): for each document, we compute a sketch and measure its approximate similarity with other documents, eventually removing pairs with high overlap.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3.3. Deduplication: fuzzy, exact, and across dumps",
        "chunkIndex": 35,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-36",
      "content": "e similar documents by applying MinHash (Broder, 1997): for each document, we compute a sketch and measure its approximate similarity with other documents, eventually removing pairs with high overlap. MinHash excels at finding templated documents: licenses with only specific entities differing, placeholder SEO text repeated across websites-see examples of the\n\nTable 3. To evaluate models trained on RefinedWeb and compare to the state-of-the-art, we build four aggregates across 18 tasks on which to measure zero-shot performance. small was built for internal ablations, based on tasks with consistent performance at small scale, core is based on tasks commonly reported for public suites of models (Dey et al., 2023; Biderman et al., 2023), main is based on tasks from the GPT-3 and PaLM paper (Brown et al., 2020; Chowdhery et al., 2022), and ext is based on tasks used by the BigScience Architecture and Scaling group (Scao et al., 2022b).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3.3. Deduplication: fuzzy, exact, and across dumps",
        "chunkIndex": 36,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-37",
      "content": "main is based on tasks from the GPT-3 and PaLM paper (Brown et al., 2020; Chowdhery et al., 2022), and ext is based on tasks used by the BigScience Architecture and Scaling group (Scao et al., 2022b). For all results reported, we flag with † results obtained in an arbitrary evaluation setup, and with ∗ results obtained with the EAI Harness (Gao et al., 2021), which we also employ for all our models.\n\n| Tasks                                       | Type                               |   Random | small   | core   | main   | ext   |\n|---------------------------------------------|------------------------------------|----------|---------|--------|--------|-------|\n| HellaSwag (Zellers et al., 2019)            | Sentence completion                |     25   | ✓       | ✓      | ✓      | ✓     |\n| LAMBADA (Paperno et al., 2016)              | Sentence completion                |      0   |         | ✓      | ✓      | ✓     |\n| Winogrande (Sakaguchi et al., 2021)         | Coreference resoluti",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3.3. Deduplication: fuzzy, exact, and across dumps",
        "chunkIndex": 37,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-38",
      "content": "| LAMBADA (Paperno et al., 2016)              | Sentence completion                |      0   |         | ✓      | ✓      | ✓     |\n| Winogrande (Sakaguchi et al., 2021)         | Coreference resolution             |     50   | ✓       | ✓      | ✓      | ✓     |\n| PIQA (Bisk et al., 2020)                    | Multiple-choice question answering |     50   | ✓       | ✓      | ✓      | ✓     |\n| ARC (Clark et al., 2018)                    | Natural language inference         |     25   | ✓       | ✓      | ✓      | ✓     |\n| OpenBookQA (Mihaylov et al., 2018)          | Multiple-choice question answering |     25   |         | ✓      | ✓      | ✓     |\n| BoolQ (Clark et al., 2019)                  | Multiple-choice question answering |     50   | ✓       |        | ✓      | ✓     |\n| COPA (Gordon et al., 2012)                  | Sentence completion                |     50   |         |        | ✓      | ✓     |\n| CB (De Marneffe et al., 2019)               | Natural language inference",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3.3. Deduplication: fuzzy, exact, and across dumps",
        "chunkIndex": 38,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-39",
      "content": "Gordon et al., 2012)                  | Sentence completion                |     50   |         |        | ✓      | ✓     |\n| CB (De Marneffe et al., 2019)               | Natural language inference         |     33.3 |         |        | ✓      | ✓     |\n| RTE (Dagan et al., 2010)                    | Natural language inference         |     50   |         |        | ✓      | ✓     |\n| ReCoRD (Zhang et al., 2018)                 | Question answering                 |      0   |         |        | ✓      |       |\n| ANLI (Nie et al., 2019)                     | Natural language inference         |     33.3 |         |        | ✓      |       |\n| LogiQA (Liu et al., 2021)                   | Multiple-choice question answering |     25   |         |        |        | ✓     |\n| HeadQA (Vilares &G´ omez-Rodr´ ıguez, 2019) | Multiple-choice question answering |     20   |         |        |        | ✓     |\n| MathQA (Amini et al., 2019)                 | Multiple-choice question answering |",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3.3. Deduplication: fuzzy, exact, and across dumps",
        "chunkIndex": 39,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-40",
      "content": "s &G´ omez-Rodr´ ıguez, 2019) | Multiple-choice question answering |     20   |         |        |        | ✓     |\n| MathQA (Amini et al., 2019)                 | Multiple-choice question answering |     20   |         |        |        | ✓     |\n| PROST (Aroca-Ouellette et al., 2021)        | Paraphrase identification          |     50   |         |        |        | ✓     |\n| PubMedQA (Jin et al., 2019)                 | Multiple-choice question answering |     50   |         |        |        | ✓     |\n| SciQ (Welbl et al., 2017)                   | Multiple-choice question answering |     25   | ✓       |        |        | ✓     |\n\nbiggest clusters in Appendix H.1. We perform MinHash deduplication using 9,000 hashes per document, calculated over 5-grams and divided into 20 buckets of 450 hashes. We found that using less aggressive settings, such as the 10 hashes of The Pile (Gao et al., 2020), resulted in lower deduplication rates and worsened model performance.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3.3. Deduplication: fuzzy, exact, and across dumps",
        "chunkIndex": 40,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-41",
      "content": "into 20 buckets of 450 hashes. We found that using less aggressive settings, such as the 10 hashes of The Pile (Gao et al., 2020), resulted in lower deduplication rates and worsened model performance. See Appendix G.3.1 for more details about our MinHash setup.\n\nExact deduplication. Exact substring operates at the sequence-level instead of the document-level, finding matches between strings that are exact token-by-token matches by using a suffix array (Manber &amp; Myers, 1993) (e.g., specific disclaimers or notices, which may not compromise the entire document as showcased in Appendix H.2). We remove any match of more than 50 consecutive tokens, using the implementation of Lee et al. (2022). We note that exact substring alters documents, by removing specific spans: we also experimented with dropping entire documents or loss-masking the duplicated strings instead of cutting them, but this didn't result in significant changes in zero-shot performance-see Appendix G.3.2.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3.3. Deduplication: fuzzy, exact, and across dumps",
        "chunkIndex": 41,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-42",
      "content": "o experimented with dropping entire documents or loss-masking the duplicated strings instead of cutting them, but this didn't result in significant changes in zero-shot performance-see Appendix G.3.2.\n\nURL deduplication. Because of computational constraints, it is impossible for us to perform deduplication directly on RW-Filtered. Instead, we split CommonCrawl into 100 parts, where each part contains a hundredth of each dump, and perform deduplication on individual parts. Most of the larger duplicate clusters (e.g., licences, common spams) will be shared across parts, and effectively removed. However, we found that CommonCrawl dumps had significant overlap, with URLs being revisited across dumps despite no change in content. Accordingly, we keep a list of the URLs of all samples we have kept from each part, and remove them from subsequent parts being processed.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "3.3. Deduplication: fuzzy, exact, and across dumps",
        "chunkIndex": 42,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-43",
      "content": "We now validate that RefinedWeb can be used to train powerful models, matching the zero-shot performance obtained with curated corpora and state-of-the-art language models. We first discuss our evaluation and pretraining setup, and models with which we compare. We perform experiments at small scale to internally compare with other popular datasets, and ablate the three main stages of RefinedWeb (raw, filtered, final). Then, we scale to 1B and 7B models trained on 350GT to compare with state-of-the-art models. Finally, we apply the MDR pipeline to existing pretraining datasets, and show that it can potentially deliver further improvements.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4. Experiments",
        "chunkIndex": 43,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-44",
      "content": "Evaluation. At variance with previous works studying pretraining datasets (Rae et al., 2021; Lee et al., 2022), we focus our evaluation on zero-shot generalization across many tasks rather than measuring validation loss. Perplexity alone can be at odds with end-task performance (Tay et al., 2021), and modern works on LLMs predominantly report zero-shot performance (Brown et al., 2020; Rae et al., 2021; Chowdhery et al., 2022). Furthermore, zero-shot generalization is the 'natural' setting for autoregressive decoder-only models, in which they perform best (Wang et al., 2022). Our evaluation setup is inspired by the one used by the architecture and scaling group of Big Science (Scao et al., 2022b).\n\nWe base our evaluation on the popular Eleuther AI evaluation harness (Gao et al., 2021), allowing us to evaluate across a wide range of tasks in the zero-shot setting.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4.1. Setting",
        "chunkIndex": 44,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-45",
      "content": "g Science (Scao et al., 2022b).\n\nWe base our evaluation on the popular Eleuther AI evaluation harness (Gao et al., 2021), allowing us to evaluate across a wide range of tasks in the zero-shot setting. We identified aggregates of tasks allowing us to: (1) obtain signal (i.e., non zero zero-shot performance) at small scale for\n\nTable 4. Curation is not a silver bullet for zero-shot generalization: small-scale models trained on REFINEDWEB outperform models trained on web data (C4, OSCAR), and on curated corpora ( ▼ The Pile). Average accuracy in zero-shot on the small-agg aggregate. All models trained with identical architectures and pretraining hyperparameters. We find that OSCAR-22.01 underperforms other datasets signficantly, perhaps because deduplication is only optional. C4 is a strong baseline, with OSCAR-21.09 lagging slightly behind, but we find that RefinedWeb outperforms both web datasets and the most popular curated dataset, The Pile.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4.1. Setting",
        "chunkIndex": 45,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-46",
      "content": "plication is only optional. C4 is a strong baseline, with OSCAR-21.09 lagging slightly behind, but we find that RefinedWeb outperforms both web datasets and the most popular curated dataset, The Pile. Both filtering and deduplication contribute significantly to improving zero-shot performance.\n\n| MASSIVE WEB DATASETS   | MASSIVE WEB DATASETS   | MASSIVE WEB DATASETS   |       | CURATED    | OURS   |             |            |\n|------------------------|------------------------|------------------------|-------|------------|--------|-------------|------------|\n|                        | OSCAR-21.09            | OSCAR-22.01            | C4    | ▼ The Pile | RW-Raw | RW-Filtered | REFINEDWEB |\n| 1B@27GT                | 55.0%                  | 52.7%                  | 55.7% | 53.4%      | 52.7%  | 54.3%       | 56.2%      |\n| 3B@60GT                | 59.1%                  | 55.9%                  | 59.6% | 57.9%      | 57.4%  | 58.2%       | 59.8%      |",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4.1. Setting",
        "chunkIndex": 46,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-47",
      "content": "| 55.7% | 53.4%      | 52.7%  | 54.3%       | 56.2%      |\n| 3B@60GT                | 59.1%                  | 55.9%                  | 59.6% | 57.9%      | 57.4%  | 58.2%       | 59.8%      |\n\nablations; (2) compare with results reported by other models. We outline these four aggregates small (for ablations), and core , main , ext (for comparisons) in Table 3.\n\nComparisons across models trained and evaluated in different settings are difficult to untangle, as many externalities may influence the 1 987results (e.g., numerical precision of training vs inference, prompts used). We distinguish three levels of comparisons: (1) internal comparisons, with models trained and evaluated within our codebase, for which only the pretraining datasets differ; (2) benchmark-level comparisons, with models trained with a different codebase but evaluated with the Eleuther AI harness, taking results from Scao et al. (2022b); Black et al. (2022); Aleph Alpha (2023); Dey et al.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4.1. Setting",
        "chunkIndex": 47,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-48",
      "content": "evel comparisons, with models trained with a different codebase but evaluated with the Eleuther AI harness, taking results from Scao et al. (2022b); Black et al. (2022); Aleph Alpha (2023); Dey et al. (2023), thereafter flagged with a ∗ ; (3) external comparisons with Brown et al. (2020); Chowdhery et al. (2022), thereafter flagged with a † . For further details on evaluation, see Appendix F.1.\n\nModels. We train 1B, 3B, and 7B parameters autoregressive decoder-only models, based on configurations and hyperparameters similar to GPT-3 (Brown et al., 2020), diverging mostly on our use of ALiBi (Press et al., 2021). We use FlashAttention (Dao et al., 2022) in a custom codebase. We train internal models on both The Pile and RefinedWeb to control for deviations caused by our pretraining setup-we found The Pile models to perform in-line with others.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4.1. Setting",
        "chunkIndex": 48,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-49",
      "content": "2022) in a custom codebase. We train internal models on both The Pile and RefinedWeb to control for deviations caused by our pretraining setup-we found The Pile models to perform in-line with others. For small-scale and ablation studies (first half of Section 4.2; Section 4.3), we train models to optimality according to the scaling laws of Hoffmann et al. (2022): on 27B and 60B tokens respectively for our 1B and 3B parameters models. For the main experiments demonstrating our approach (FalconRWmodels in Section 4.2), we train the models to 350GT, in line with popular public models (Brown et al., 2020; Wang &amp;Komatsuzaki, 2021; Scao et al., 2022a). Note that we do not compare against the recently introduced LLaMA models (Touvron et al., 2023), as the smallest of them is trained on x2.5 more compute than our largest model, preventing a meaningful comparison from being made dataset-wise.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4.1. Setting",
        "chunkIndex": 49,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-50",
      "content": "ecently introduced LLaMA models (Touvron et al., 2023), as the smallest of them is trained on x2.5 more compute than our largest model, preventing a meaningful comparison from being made dataset-wise. For a more in-depth overview of the models and pretraining datasets with which we compare, see Appendix F.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4.1. Setting",
        "chunkIndex": 50,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-51",
      "content": "We endeavour to demonstrate that web data alone can result in models outperforming other models trained on curated corpora. To do so, we first perform a small-scale study with 1B and 3B parameters models trained to optimality (27GT and 60GT) on popular web and curated datasets. Then, we scale up to 1B and 7B models trained on 350GT, and compare zero-shot generalization to state-of-the-art models.\n\nSmall-scale study. We first consider popular public web datasets (OSCAR-2019 (Ortiz Su´ arez et al., 2019), OSCAR2022 (Abadji et al., 2021), C4 (Raffel et al., 2020)), The Pile (Gao et al., 2020) as the most popular publicly available curated dataset, and variations of RefinedWeb (RW-Raw, RW-Filtered, and RW as described in Section 3). For this first study, all models are trained with the same architecture and the same internal codebase; they are also all evaluated within the same framework-only pretraining datasets differ.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4.2. Can web data alone outperform curated corpora?",
        "chunkIndex": 51,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-52",
      "content": "tion 3). For this first study, all models are trained with the same architecture and the same internal codebase; they are also all evaluated within the same framework-only pretraining datasets differ.\n\nResults averaged on the small-=+ aggregate of 6 tasks are presented in Table 4. We observe relatively strong performance of all web datasets compared to The Pile, showcasing that curation is not a silver bullet for performant language models. We find C4 to be a strong pretraining dataset, in line with the findings of Scao et al. (2022b)-however, The Pile comparatively underperforms more in our benchmarks. The relatively disappointing results on OSCAR-22.01 may be due to the main version of the dataset being distributed without deduplication. Regarding RefinedWeb, both filtering and deduplication significantly improve performance.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4.2. Can web data alone outperform curated corpora?",
        "chunkIndex": 52,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-53",
      "content": "results on OSCAR-22.01 may be due to the main version of the dataset being distributed without deduplication. Regarding RefinedWeb, both filtering and deduplication significantly improve performance.\n\nFull-scale models. We now validate these results with comparisons with state-of-the-art models. We scale our previous experiments by training 1B and 7B models on 350GT; we also train a 1B model on 350GT on The Pile, as a control for the influence of our pretraining setup. We compare with the following models: the GPT-3 series (Brown et al., 2020), the FairSeq series (Artetxe et al., 2021), the GPT-Neo(X)/J models (Black et al., 2021; Wang &amp; Komatsuzaki, 2021; Black et al., 2022), the OPT series (Zhang et al., 2022),\n\nthe BigScience Architecture and Scaling Pile model (Scao et al., 2022b), PaLM-8B (Chowdhery et al., 2022), Aleph Alpha Luminous 13B (Aleph Alpha, 2023), the Pythia series (Biderman et al., 2023), and the Cerebras-GPT series (Dey et al., 2023).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4.2. Can web data alone outperform curated corpora?",
        "chunkIndex": 53,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-54",
      "content": "e model (Scao et al., 2022b), PaLM-8B (Chowdhery et al., 2022), Aleph Alpha Luminous 13B (Aleph Alpha, 2023), the Pythia series (Biderman et al., 2023), and the Cerebras-GPT series (Dey et al., 2023). For GPT-3, we distinguish between results obtained through the API ( babbage and curie ) with the the EleutherAI LM evaluation harness (Gao et al., 2021) (*), and results reported in their paper, with a different evaluation setup ( † ). Note that for PaLM and OPT, results were also obtained with a different evaluation suite ( † ), while for other models they were obtained with the evaluation harness as well (*), allowing for more direct comparisons.\n\nResults on main-agg are presented in Figure 1, and in Figure 3 for core-agg and ext-agg . We find that open models consistently underperform models trained on private curated corpora, such as GPT-3-even when using a similar evaluation setup.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4.2. Can web data alone outperform curated corpora?",
        "chunkIndex": 54,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-55",
      "content": "re 1, and in Figure 3 for core-agg and ext-agg . We find that open models consistently underperform models trained on private curated corpora, such as GPT-3-even when using a similar evaluation setup. Conversely, models trained on RefinedWeb are able to match the performance of the GPT-3 series using web data alone, even though common high-quality sources used in The Pile are excluded from RefinedWeb (see Table 14 in Appendix). Finally, we note that our internal model trained on The Pile performs in line with the BigScience Architecture and Scaling model; this highlights that our pretraining setup is unlikely to be the main source of increased performance for models trained on RefinedWeb.\n\nFinding. Challenging existing beliefs on data quality and LLMs, models trained on adequately filtered and deduplicated web data alone can match the performance of models trained on curated data.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4.2. Can web data alone outperform curated corpora?",
        "chunkIndex": 55,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-56",
      "content": "Ablating the contributions and evaluating the performance of individual components in the MDR pipeline is difficult: for most heuristics, there is no agreed-upon ground truth, and changes may be too insignificant to result in sufficient zero-shot signal after pretraining. In the first half of Section 4.2, we identified that subsequent stages of RefinedWeb (raw, filtered, final) led to improvements in performance. In this section, we propose to apply independently the filtering and deduplication stages of MDR to popular pretraining datasets, studying whether they generalize widely.\n\nWe report results on the small-agg in Table 5. First, we find that improvements from filtering are not systematic. On The Pile, we had to adjust our line length and characters ratio heuristics to avoid expunging books and code.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4.3. Do other corpora benefit from MDR?",
        "chunkIndex": 56,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-57",
      "content": "all-agg in Table 5. First, we find that improvements from filtering are not systematic. On The Pile, we had to adjust our line length and characters ratio heuristics to avoid expunging books and code. Despite improvements on OSCAR-21.09, C4, and The Pile, our filters worsen performance on OSCAR-22.01; generally, removal rates from filtering do not seem strongly correlated with downstream accuracy. Conversely, deduplication delivers a steady boost across all datasets, and removal rates are better correlated with changes in performance. We find OSCAR21.09 and C4 to be already well deduplicated, while The Pile and OSCAR-22.01 exhibit 40-60% duplicates. The base version of OSCAR-22.01 is distributed without deduplication; for The Pile, this is consistent with the findings of Zhang et al. (2022).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4.3. Do other corpora benefit from MDR?",
        "chunkIndex": 57,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-58",
      "content": "ile The Pile and OSCAR-22.01 exhibit 40-60% duplicates. The base version of OSCAR-22.01 is distributed without deduplication; for The Pile, this is consistent with the findings of Zhang et al. (2022). Finally, combining filtering and deduplication results in further improvements; interestingly, although performance is now more uniform across datasets, differences remain, suggesting that flaws in the original text extraction and processing can't be fully compensated for.\n\n55\n\nFigure 3. Models trained on REFINEDWEB alone outperform models trained on curated corpora. Zero-shot performance averaged on our core-agg (left) and ext-agg (right) task aggregates (see Section 4.1 for details, and Figure 1 for results on main-agg ). Existing open models fail to match the performance of the original GPT-3 series (left); however, models trained on RefinedWeb significantly outperform models trained on ▼ The Pile: including our direct comparison model (right), ruling out our pretraining setup as the m",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4.3. Do other corpora benefit from MDR?",
        "chunkIndex": 58,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-59",
      "content": "T-3 series (left); however, models trained on RefinedWeb significantly outperform models trained on ▼ The Pile: including our direct comparison model (right), ruling out our pretraining setup as the main source of increased performance. In fact, our RefinedWeb models even match the performance of the ■ GPT-3 models.\n\n<!-- image -->\n\nTable 5. Although improvements from filtering are not systematic across datasets, deduplication brings a steady performance boost across the board. Zero-shot accuracy averaged on our small-agg aggregate; [+x.x] reports absolute gains compared to base, removal rates reported against base. Due to limitations in our pipeline, we cannot apply the deduplication stage independently for RefinedWeb.\n\n|              | MASSIVE WEB DATASETS   | MASSIVE WEB DATASETS   |             | CURATED      | OURS         |\n|--------------|------------------------|------------------------|-------------|--------------|--------------|\n|              | OSCAR-21.09            | OSCAR",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4.3. Do other corpora benefit from MDR?",
        "chunkIndex": 59,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-60",
      "content": "| CURATED      | OURS         |\n|--------------|------------------------|------------------------|-------------|--------------|--------------|\n|              | OSCAR-21.09            | OSCAR-22.01            | C4          | ▼ Pile       | RefinedWeb   |\n| Base         | 55.0%                  | 52.7%                  | 55.7%       | 53.4%        | 52.7%        |\n| Filtered     | 55.4% [+.4]            | 52.3% [-.4]            | 56.2% [+.5] | 54.2% [+.8]  | 54.3% [+1.6] |\n| removal rate | -25.0%                 | -39.8%                 | -16.4%      | -27.1%       | -50.8%       |\n| Deduplicated | 55.6% [+.6]            | 55.6% [+2.9]           | 55.9% [+.2] | 54.5% [+1.1] |              |\n| removal rate | -10.8%                 | -60.8%                 | -7.59%      | -45.3%       |              |\n| Filt.+Dedup.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4.3. Do other corpora benefit from MDR?",
        "chunkIndex": 60,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-61",
      "content": "| 55.6% [+2.9]           | 55.9% [+.2] | 54.5% [+1.1] |              |\n| removal rate | -10.8%                 | -60.8%                 | -7.59%      | -45.3%       |              |\n| Filt.+Dedup. | 55.5% [+.5]            | 55.4% [+2.7]           | 56.4% [+.7] | 55.2% [+1.8] | 56.2% [+3.5] |\n| removal rate | -28.2%                 | -62.2%                 | -17.9%      | -66.0%       | -75.4%       |\n\nBy processing C4 through MDR, we are able to obtain subsets of data which might slightly outperform RefinedWeb; this combines both the stringent filtering of C4 (e.g., strict NSFW word blocklist, 3-sentence span deduplication) with our own filters and deduplication. While such a combination results in rejection rates that would be unacceptable for our target of 3-6 trillions tokens, this represents an interesting perspective for shorter runs, which may be able to extract extremely high-quality subsets from large web datasets.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4.3. Do other corpora benefit from MDR?",
        "chunkIndex": 61,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-62",
      "content": "e unacceptable for our target of 3-6 trillions tokens, this represents an interesting perspective for shorter runs, which may be able to extract extremely high-quality subsets from large web datasets.\n\nFinding. While filtering heuristics may require sourcedependent tuning, stringent deduplication improves zero-shot performance across datasets consistently.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "4.3. Do other corpora benefit from MDR?",
        "chunkIndex": 62,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-63",
      "content": "Biases. We conduct a basic analysis of the toxicity of RefinedWeb in Figure 4. We find RW to be about as toxic as The Pile, based on the definition of toxicity provided by the Perspective API: 'content that is rude or disrespectful'. Notably, this definition does not cover issues with social biases or harmfulness. Although it is unlikely that our pipeline introduces further issues on this side than is already documented for popular datasets, we encourage further quantitative work on the public extract of RefinedWeb.\n\nMultiple epochs. Instead of looking for 'unique' tokens to make up a trillion-scale pretraining dataset, one could simply repeat data over multiple epochs. Popular models like OPT and NeoX-20B do this for up to 2 epochs, and most curated datasets upsample corpora 2-5 times. However, Hernandez et al. (2022) has recently shown that models with 100B+ parameters may be sensitive to even just a few epochs.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "5. Limitations",
        "chunkIndex": 63,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-64",
      "content": "up to 2 epochs, and most curated datasets upsample corpora 2-5 times. However, Hernandez et al. (2022) has recently shown that models with 100B+ parameters may be sensitive to even just a few epochs. Orthogonal to our work lies a line of research exploring tradeoffs in the data-constrained regime: can deduplication help sustain more epochs? Are multiple epochs on higher quality data better than a one epoch on lower quality data? See Appendix E.3 for a more in-depth discussion.\n\nOther results on deduplication. Biderman et al. (2023) found a limited impact on zero-shot performance from deduplicating The Pile; we discuss further in Appendix F.2, but encourage further deduplication research on curated corpora, and studying deduplication in the data-constrained regime, where multiple epochs have to be performed to compensate for the reduction in tokens incurred by deduplication.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "5. Limitations",
        "chunkIndex": 64,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-65",
      "content": "As LLMs are widely adopted, models trained past the recommendations of scaling laws are bound to become increasingly common to amortize inference costs (Touvron et al., 2023). This will further drive the need for pretraining datasets with trillions of tokens, an order of magnitude beyond publicly available corpora. We have demonstrated that stringent filtering and deduplication could result in a five trillion tokens web only dataset suitable to produce models competitive with the state-of-the-art, even outperforming LLMs trained on curated corpora. We publicly release a 600GT extract of RefinedWeb, and note that RefinedWeb has already been used to train state-of-the-art language models, such as Falcon-40B (Almazrouei et al., 2023).\n\nFigure 4. Toxic content in RefinedWeb is distributed similarly to The Pile. Cumulative proportion of documents below a given toxicity score, as evaluated by the Pespective API.\n\n<!-- image -->",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "6. Conclusion",
        "chunkIndex": 65,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-66",
      "content": "- Abadji, J., Su´ arez, P. J. O., Romary, L., and Sagot, B. Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus. Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event), pp. 1 - 9, Mannheim, 2021. Leibniz-Institut f¨ ur Deutsche Sprache. doi: 10.14618/ ids-pub-10468. URL https://nbn-resolving. org/urn:nbn:de:bsz:mh39-104688 .\n- Abadji, J., Ortiz Suarez, P., Romary, L., and Sagot, B. Towards a Cleaner Document-Oriented Multilingual Crawled Corpus. arXiv e-prints , art. arXiv:2201.06642, January 2022.\n- Abbas, A. K. M., Tirumala, K., Simig, D., Ganguli, S., and Morcos, A. S. Semdedup: Data-efficient learning at web-scale through semantic deduplication. In ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models , 2023.\n- Adiwardana, D., Luong, M.-T., So, D.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 66,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-67",
      "content": "ta-efficient learning at web-scale through semantic deduplication. In ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models , 2023.\n- Adiwardana, D., Luong, M.-T., So, D. R., Hall, J., Fiedel, N., Thoppilan, R., Yang, Z., Kulshreshtha, A., Nemade, G., Lu, Y., et al. Towards a human-like open-domain chatbot. arXiv preprint arXiv:2001.09977 , 2020.\n- Aleph Alpha. Luminous: performance benchmarks. arXiv preprint arXiv:1810.12885 , 2023. URL https://www.aleph-alpha.com/pdf/2023\\_ 02\\_AA\\_Benchmarks\\_doc.pdf .\n- Allamanis, M. The adverse effects of code duplication in machine learning models of code. In Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software , pp. 143-153, 2019.\n- Almazrouei, E., Cappelli, A., Cojocaru, R., Debbah, M., Goffinet, E., Heslow, D., Launay, J., Malartic, Q., Noune, B., Pannier, B., and Penedo, G.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 67,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-68",
      "content": "ns on Programming and Software , pp. 143-153, 2019.\n- Almazrouei, E., Cappelli, A., Cojocaru, R., Debbah, M., Goffinet, E., Heslow, D., Launay, J., Malartic, Q., Noune, B., Pannier, B., and Penedo, G. Falcon-40b: an open large language model with state-of-the-art performance. 2023.\n- Amini, A., Gabriel, S., Lin, S., Koncel-Kedziorski, R., Choi, Y., and Hajishirzi, H. Mathqa: Towards interpretable math word problem solving with operation-based formalisms. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) , pp. 2357-2367, 2019.\n- Aroca-Ouellette, S., Paik, C., Roncone, A., and Kann, K. Prost: Physical reasoning about objects through space and time. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021 , pp. 4597-4608, 2021.\n- Artetxe, M., Bhosale, S., Goyal, N., Mihaylov, T., Ott, M., Shleifer, S., Lin, X.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 68,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-69",
      "content": "space and time. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021 , pp. 4597-4608, 2021.\n- Artetxe, M., Bhosale, S., Goyal, N., Mihaylov, T., Ott, M., Shleifer, S., Lin, X. V ., Du, J., Iyer, S., Pasunuru, R., et al. Efficient large scale language modeling with mixtures of experts. arXiv preprint arXiv:2112.10684 , 2021.\n- Barbaresi, A. Trafilatura: A Web Scraping Library and Command-Line Tool for Text Discovery and Extraction. In Proceedings of the Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations , pp. 122-131. Association for Computational Linguistics, 2021. URL https://aclanthology.org/2021. acl-demo.15 .\n- Beltagy, I., Lo, K., and Cohan, A. Scibert: A pretrained language model for scientific text.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 69,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-70",
      "content": "22-131. Association for Computational Linguistics, 2021. URL https://aclanthology.org/2021. acl-demo.15 .\n- Beltagy, I., Lo, K., and Cohan, A. Scibert: A pretrained language model for scientific text. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLPIJCNLP) , pp. 3615-3620, 2019.\n- Biderman, S., Schoelkopf, H., Anthony, Q., Bradley, H., O'Brien, K., Hallahan, E., Khan, M. A., Purohit, S., Prashanth, U. S., Raff, E., et al. Pythia: A suite for analyzing large language models across training and scaling. arXiv preprint arXiv:2304.01373 , 2023.\n- Bisk, Y., Zellers, R., Gao, J., Choi, Y ., et al. Piqa: Reasoning about physical commonsense in natural language. In Proceedings of the AAAI conference on artificial intelligence , volume 34, pp. 7432-7439, 2020.\n- Black, S., Leo, G., Wang, P., Leahy, C., and Biderman, S.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 70,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-71",
      "content": "physical commonsense in natural language. In Proceedings of the AAAI conference on artificial intelligence , volume 34, pp. 7432-7439, 2020.\n- Black, S., Leo, G., Wang, P., Leahy, C., and Biderman, S. GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow, March 2021. URL https: //doi.org/10.5281/zenodo.5297715 . If you use this software, please cite it using these metadata.\n- Black, S., Biderman, S., Hallahan, E., Anthony, Q., Gao, L., Golding, L., He, H., Leahy, C., McDonell, K., Phang, J., et al. Gpt-neox-20b: An open-source autoregressive language model. Challenges &amp; Perspectives in Creating Large Language Models , pp. 95, 2022.\n- Broder, A. Z. On the resemblance and containment of documents. In Proceedings. Compression and Complexity of Sequences 1997 , pp. 21-29. IEEE, 1997.\n- Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 71,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-72",
      "content": "7 , pp. 21-29. IEEE, 1997.\n- Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. Advances in neural information processing systems , 33: 1877-1901, 2020.\n- Carlini, N., Tramer, F., Wallace, E., Jagielski, M., HerbertVoss, A., Lee, K., Roberts, A., Brown, T., Song, D.,\n\n- Erlingsson, U., et al. Extracting training data from large language models. In 30th USENIX Security Symposium (USENIX Security 21) , pp. 2633-2650, 2021.\n- Carlini, N., Ippolito, D., Jagielski, M., Lee, K., Tramer, F., and Zhang, C. Quantifying memorization across neural language models. arXiv preprint arXiv:2202.07646 , 2022.\n- Charikar, M. S. Similarity estimation techniques from rounding algorithms. In Proceedings of the thiry-fourth annual ACM symposium on Theory of computing , pp. 380-388, 2002.\n- Chelba, C., Mikolov, T., Schuster, M., Ge, Q., Brants, T., Koehn, P., and Robinson, T.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 72,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-73",
      "content": "algorithms. In Proceedings of the thiry-fourth annual ACM symposium on Theory of computing , pp. 380-388, 2002.\n- Chelba, C., Mikolov, T., Schuster, M., Ge, Q., Brants, T., Koehn, P., and Robinson, T. One billion word benchmark for measuring progress in statistical language modeling. arXiv preprint arXiv:1312.3005 , 2013.\n- Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311 , 2022.\n- Clark, C., Lee, K., Chang, M.-W., Kwiatkowski, T., Collins, M., and Toutanova, K. Boolq: Exploring the surprising difficulty of natural yes/no questions. In Proceedings of NAACL-HLT , pp. 2924-2936, 2019.\n- Clark, P., Cowhey, I., Etzioni, O., Khot, T., Sabharwal, A., Schoenick, C., and Tafjord, O. Think you have solved question answering? try arc, the ai2 reasoning challenge.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 73,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-74",
      "content": "HLT , pp. 2924-2936, 2019.\n- Clark, P., Cowhey, I., Etzioni, O., Khot, T., Sabharwal, A., Schoenick, C., and Tafjord, O. Think you have solved question answering? try arc, the ai2 reasoning challenge. arXiv preprint arXiv:1803.05457 , 2018.\n- Dagan, I., Dolan, B., Magnini, B., and Roth, D. Recognizing textual entailment: Rational, evaluation and approacheserratum. Natural Language Engineering , 16(1):105-105, 2010.\n- Dao, T., Fu, D. Y., Ermon, S., Rudra, A., and Re, C. Flashattention: Fast and memory-efficient exact attention with io-awareness. In Advances in Neural Information Processing Systems , 2022.\n- De Marneffe, M.-C., Simons, M., and Tonhauser, J. The commitmentbank: Investigating projection in naturally occurring discourse. In proceedings of Sinn und Bedeutung , volume 23, pp. 107-124, 2019.\n- Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. Bert: Pre-training of deep bidirectional transformers for language understanding.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 74,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-75",
      "content": "oceedings of Sinn und Bedeutung , volume 23, pp. 107-124, 2019.\n- Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) , pp. 4171-4186, 2019.\n- Dey, N., Gosal, G., Khachane, H., Marshall, W., Pathria, R., Tom, M., Hestness, J., et al. Cerebras-gpt: Open computeoptimal language models trained on the cerebras waferscale cluster. arXiv preprint arXiv:2304.03208 , 2023.\n- Dodge, J., Sap, M., Marasovi´ c, A., Agnew, W., Ilharco, G., Groeneveld, D., Mitchell, M., and Gardner, M. Documenting large webtext corpora: A case study on the colossal clean crawled corpus. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing , pp. 1286-1305, 2021.\n- Eberhard, D. M., Simons, G. F., and Fennig, C. D.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 75,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-76",
      "content": "the colossal clean crawled corpus. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing , pp. 1286-1305, 2021.\n- Eberhard, D. M., Simons, G. F., and Fennig, C. D. Ethnologue: Languages of the World . SIL International, Dallas, TX, USA, twenty-sixth edition, 2023.\n- Gao, L., Biderman, S., Black, S., Golding, L., Hoppe, T., Foster, C., Phang, J., He, H., Thite, A., Nabeshima, N., et al. The pile: An 800gb dataset of diverse text for language modeling. arXiv preprint arXiv:2101.00027 , 2020.\n- Gao, L., Tow, J., Biderman, S., Black, S., DiPofi, A., Foster, C., Golding, L., Hsu, J., McDonell, K., Muennighoff, N., Phang, J., Reynolds, L., Tang, E., Thite, A., Wang, B., Wang, K., and Zou, A. A framework for few-shot language model evaluation, September 2021. URL https: //doi.org/10.5281/zenodo.5371628 .\n- Gebru, T., Morgenstern, J., Vecchione, B., Vaughan, J. W., Wallach, H., Iii, H. D., and Crawford, K. Datasheets for datasets.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 76,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-77",
      "content": "valuation, September 2021. URL https: //doi.org/10.5281/zenodo.5371628 .\n- Gebru, T., Morgenstern, J., Vecchione, B., Vaughan, J. W., Wallach, H., Iii, H. D., and Crawford, K. Datasheets for datasets. Communications of the ACM , 64(12):86-92, 2021.\n- Gokaslan, A., Cohen, V., Pavlick, E., and Tellex, S. Openwebtext corpus. http://Skylion007.github. io/OpenWebTextCorpus , 2019.\n- Gordon, A., Kozareva, Z., and Roemmele, M. Semeval2012 task 7: Choice of plausible alternatives: An evaluation of commonsense causal reasoning. In * SEM 2012: The First Joint Conference on Lexical and Computational Semantics-Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval 2012) , pp. 394-398, 2012.\n- Grave, ´ E., Bojanowski, P., Gupta, P., Joulin, A., and Mikolov, T. Learning word vectors for 157 languages.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 77,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-78",
      "content": "e Sixth International Workshop on Semantic Evaluation (SemEval 2012) , pp. 394-398, 2012.\n- Grave, ´ E., Bojanowski, P., Gupta, P., Joulin, A., and Mikolov, T. Learning word vectors for 157 languages. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018) , 2018.\n- Hanu, L. and Unitary team. Detoxify. Github. https://github.com/unitaryai/detoxify, 2020.\n- Hernandez, D., Brown, T., Conerly, T., DasSarma, N., Drain, D., El-Showk, S., Elhage, N., Hatfield-Dodds,\n\n- Z., Henighan, T., Hume, T., et al. Scaling laws and interpretability of learning from repeated data. arXiv preprint arXiv:2205.10487 , 2022.\n- Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Casas, D. d. L., Hendricks, L. A., Welbl, J., Clark, A., et al. Training compute-optimal large language models. arXiv preprint arXiv:2203.15556 , 2022.\n- Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. The curious case of neural text degeneration.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 78,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-79",
      "content": "et al. Training compute-optimal large language models. arXiv preprint arXiv:2203.15556 , 2022.\n- Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. The curious case of neural text degeneration. In International Conference on Learning Representations , 2019.\n- Jaccard, P. The distribution of the flora in the alpine zone.1. New Phytologist , 11:37-50, 1912.\n- Jin, Q., Dhingra, B., Liu, Z., Cohen, W., and Lu, X. Pubmedqa: A dataset for biomedical research question answering. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) , pp. 2567-2577, 2019.\n- Joulin, A., Grave, E., Bojanowski, P., Douze, M., J´ egou, H., and Mikolov, T. Fasttext. zip: Compressing text classification models. arXiv preprint arXiv:1612.03651 , 2016.\n- Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., Gray, S., Radford, A., Wu, J., and Amodei, D.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 79,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-80",
      "content": "essing text classification models. arXiv preprint arXiv:1612.03651 , 2016.\n- Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., Gray, S., Radford, A., Wu, J., and Amodei, D. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361 , 2020.\n- Kreutzer, J., Caswell, I., Wang, L., Wahab, A., van Esch, D., Ulzii-Orshikh, N., Tapo, A. A., Subramani, N., Sokolov, A., Sikasote, C., et al. Quality at a glance: An audit of web-crawled multilingual datasets. Transactions of the Association for Computational Linguistics , 10:50-72, 2022.\n- Laurenc ¸on, H., Saulnier, L., Wang, T., Akiki, C., del Moral, A. V., Le Scao, T., Von Werra, L., Mou, C., Ponferrada, E. G., Nguyen, H., et al. The bigscience roots corpus: A 1.6 tb composite multilingual dataset. In Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track , 2022.\n- Lee, K., Ippolito, D., Nystrom, A., Zhang, C., Eck, D., Callison-Burch, C., and Carlini, N.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 80,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-81",
      "content": "In Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track , 2022.\n- Lee, K., Ippolito, D., Nystrom, A., Zhang, C., Eck, D., Callison-Burch, C., and Carlini, N. Deduplicating training data makes language models better. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pp. 84248445, 2022.\n- Liu, J., Cui, L., Liu, H., Huang, D., Wang, Y., and Zhang, Y. Logiqa: a challenge dataset for machine reading comprehension with logical reasoning. In Proceedings of\n- the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence , pp. 3622-3628, 2021.\n- Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., and Stoyanov, V. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692 , 2019.\n- Lopukhin, K.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 81,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-82",
      "content": "N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., and Stoyanov, V. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692 , 2019.\n- Lopukhin, K. Evaluating quality of article body extraction for commercial services and open-source libraries. https://github.com/scrapinghub/ article-extraction-benchmark , 2019.\n- Manber, U. and Myers, G. Suffix arrays: a new method for on-line string searches. Journal on Computing , 22(5): 935-948, 1993.\n- Mihaylov, T., Clark, P., Khot, T., and Sabharwal, A. Can a suit of armor conduct electricity? a new dataset for open book question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , pp. 2381-2391, 2018.\n- Mitchell, M., Wu, S., Zaldivar, A., Barnes, P., Vasserman, L., Hutchinson, B., Spitzer, E., Raji, I. D., and Gebru, T. Model cards for model reporting. In Proceedings of the conference on fairness, accountability, and transparency , pp.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 82,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-83",
      "content": "Barnes, P., Vasserman, L., Hutchinson, B., Spitzer, E., Raji, I. D., and Gebru, T. Model cards for model reporting. In Proceedings of the conference on fairness, accountability, and transparency , pp. 220-229, 2019.\n- Nie, Y., Williams, A., Dinan, E., Bansal, M., Weston, J., and Kiela, D. Adversarial nli: A new benchmark for natural language understanding. arXiv preprint arXiv:1910.14599 , 2019.\n- Ortiz Su´ arez, P. J., Sagot, B., and Romary, L. Asynchronous pipelines for processing huge corpora on medium to low resource infrastructures. Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-7) 2019. Cardiff, 22nd July 2019, pp. 9 -16, Mannheim, 2019. Leibniz-Institut f¨ ur Deutsche Sprache. doi: 10.14618/ ids-pub-9021. URL http://nbn-resolving.de/ urn:nbn:de:bsz:mh39-90215 .\n- Paperno, D., Kruszewski, G., Lazaridou, A., Pham, N.-Q., Bernardi, R., Pezzelle, S., Baroni, M., Boleda, G., and Fern´ andez, R.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 83,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-84",
      "content": "ds-pub-9021. URL http://nbn-resolving.de/ urn:nbn:de:bsz:mh39-90215 .\n- Paperno, D., Kruszewski, G., Lazaridou, A., Pham, N.-Q., Bernardi, R., Pezzelle, S., Baroni, M., Boleda, G., and Fern´ andez, R. The lambada dataset: Word prediction requiring a broad discourse context. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pp. 15251534, 2016.\n\nPomik´ alek, J. Justext. 2011.\n\n- Press, O., Smith, N., and Lewis, M. Train short, test long: Attention with linear biases enables input length extrapolation. In International Conference on Learning Representations , 2021.\n\n- Radford, A., Narasimhan, K., Salimans, T., Sutskever, I., et al. Improving language understanding by generative pre-training. 2018.\n- Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et al. Language models are unsupervised multitask learners. 2019.\n- Rae, J.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 84,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-85",
      "content": "guage understanding by generative pre-training. 2018.\n- Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et al. Language models are unsupervised multitask learners. 2019.\n- Rae, J. W., Borgeaud, S., Cai, T., Millican, K., Hoffmann, J., Song, F., Aslanides, J., Henderson, S., Ring, R., Young, S., Rutherford, E., Hennigan, T., Menick, J., Cassirer, A., Powell, R., Driessche, G. v. d., Hendricks, L. A., Rauh, M., Huang, P.-S., Glaese, A., Welbl, J., Dathathri, S., Huang, S., Uesato, J., Mellor, J., Higgins, I., Creswell, A., McAleese, N., Wu, A., Elsen, E., Jayakumar, S., Buchatskaya, E., Budden, D., Sutherland, E., Simonyan, K., Paganini, M., Sifre, L., Martens, L., Li, X. L., Kuncoro, A., Nematzadeh, A., Gribovskaya, E., Donato, D., Lazaridou, A., Mensch, A., Lespiau, J.-B., Tsimpoukelli, M., Grigorev, N., Fritz, D., Sottiaux, T., Pajarskas, M., Pohlen, T., Gong, Z., Toyama, D., d'Autume, C. d. M., Li, Y., Terzi, T., Mikulik, V., Babuschkin, I., Clark, A., Casas, D.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 85,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-86",
      "content": ".-B., Tsimpoukelli, M., Grigorev, N., Fritz, D., Sottiaux, T., Pajarskas, M., Pohlen, T., Gong, Z., Toyama, D., d'Autume, C. d. M., Li, Y., Terzi, T., Mikulik, V., Babuschkin, I., Clark, A., Casas, D. d. L., Guy, A., Jones, C., Bradbury, J., Johnson, M., Hechtman, B., Weidinger, L., Gabriel, I., Isaac, W., Lockhart, E., Osindero, S., Rimell, L., Dyer, C., Vinyals, O., Ayoub, K., Stanway, J., Bennett, L., Hassabis, D., Kavukcuoglu, K., and Irving, G. Scaling language models: Methods, analysis &amp; insights from training gopher. 2021. doi: 10.48550/ARXIV.2112.11446. URL https://arxiv.org/abs/2112.11446 .\n- Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research , 21(140):1-67, 2020. URL http://jmlr. org/papers/v21/20-074.html .\n- Sakaguchi, K., Bras, R. L., Bhagavatula, C., and Choi, Y.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 86,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-87",
      "content": "a unified text-to-text transformer. Journal of Machine Learning Research , 21(140):1-67, 2020. URL http://jmlr. org/papers/v21/20-074.html .\n- Sakaguchi, K., Bras, R. L., Bhagavatula, C., and Choi, Y. Winogrande: An adversarial winograd schema challenge at scale. Communications of the ACM , 64(9):99-106, 2021.\n- Scao, T. L., Fan, A., Akiki, C., Pavlick, E., Ili´ c, S., Hesslow, D., Castagn´ e, R., Luccioni, A. S., Yvon, F., Gall´ e, M., et al. Bloom: A 176b-parameter open-access multilingual language model. arXiv preprint arXiv:2211.05100 , 2022a.\n- Scao, T. L., Wang, T., Hesslow, D., Saulnier, L., Bekman, S., Bari, M. S., Bideman, S., Elsahar, H., Muennighoff, N., Phang, J., et al. What language model to train if you have one million gpu hours? arXiv preprint arXiv:2210.15424 , 2022b.\n- Sevilla, J., Heim, L., Ho, A., Besiroglu, T., Hobbhahn, M., and Villalobos, P. Compute trends across three eras\n- of machine learning. arXiv preprint arXiv:2202.05924 , 2022.\n- Sites, D.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 87,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-88",
      "content": "24 , 2022b.\n- Sevilla, J., Heim, L., Ho, A., Besiroglu, T., Hobbhahn, M., and Villalobos, P. Compute trends across three eras\n- of machine learning. arXiv preprint arXiv:2202.05924 , 2022.\n- Sites, D. Compact language detector 2. Software available at https://github. com/CLD2Owners/cld2 (last updated on August 2015) , 2013.\n- Tay, Y., Dehghani, M., Rao, J., Fedus, W., Abnar, S., Chung, H. W., Narang, S., Yogatama, D., Vaswani, A., and Metzler, D. Scale efficiently: Insights from pretraining and finetuning transformers. In International Conference on Learning Representations , 2021.\n- Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.-T., Jin, A., Bos, T., Baker, L., Du, Y., et al. Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239 , 2022.\n- Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozi` ere, B., Goyal, N., Hambro, E., Azhar, F., et al.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 88,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-89",
      "content": "dialog applications. arXiv preprint arXiv:2201.08239 , 2022.\n- Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozi` ere, B., Goyal, N., Hambro, E., Azhar, F., et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 , 2023.\n- Trinh, T. H. and Le, Q. V. A simple method for commonsense reasoning. arXiv preprint arXiv:1806.02847 , 2018.\n- Vilares, D. and G´ omez-Rodr´ ıguez, C. Head-qa: A healthcare dataset for complex reasoning. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , pp. 960-966, 2019.\n- Villalobos, P., Sevilla, J., Heim, L., Besiroglu, T., Hobbhahn, M., and Ho, A. Will we run out of data? an analysis of the limits of scaling datasets in machine learning. arXiv preprint arXiv:2211.04325 , 2022.\n- Wang, B. and Komatsuzaki, A. GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 89,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-90",
      "content": "an analysis of the limits of scaling datasets in machine learning. arXiv preprint arXiv:2211.04325 , 2022.\n- Wang, B. and Komatsuzaki, A. GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/kingoflolz/ mesh-transformer-jax , May 2021.\n- Wang, T., Roberts, A., Hesslow, D., Scao, T. L., Chung, H. W., Beltagy, I., Launay, J., and Raffel, C. What language model architecture and pretraining objective work best for zero-shot generalization? In International Conference on Machine Learning , 2022.\n- Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Metzler, D., et al. Emergent abilities of large language models. Transactions on Machine Learning Research , 2022.\n- Welbl, J., Liu, N. F., and Gardner, M. Crowdsourcing multiple choice science questions. In Proceedings of the 3rd Workshop on Noisy User-generated Text , pp. 94-106, 2017.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 90,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-91",
      "content": "Learning Research , 2022.\n- Welbl, J., Liu, N. F., and Gardner, M. Crowdsourcing multiple choice science questions. In Proceedings of the 3rd Workshop on Noisy User-generated Text , pp. 94-106, 2017.\n\n- Welbl, J., Glaese, A., Uesato, J., Dathathri, S., Mellor, J., Hendricks, L. A., Anderson, K., Kohli, P., Coppin, B., and Huang, P.-S. Challenges in detoxifying language models. In Findings of the Association for Computational Linguistics: EMNLP 2021 , pp. 2447-2469, 2021.\n- Wenzek, G., Lachaux, M.-A., Conneau, A., Chaudhary, V., Guzm´ an, F., Joulin, A., and Grave, ´ E. Ccnet: Extracting high quality monolingual datasets from web crawl data. In Proceedings of the 12th Language Resources and Evaluation Conference , pp. 4003-4012, 2020.\n- Xue, L., Constant, N., Roberts, A., Kale, M., Al-Rfou, R., Siddhant, A., Barua, A., and Raffel, C. mt5: A massively multilingual pre-trained text-to-text transformer.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 91,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-92",
      "content": "nference , pp. 4003-4012, 2020.\n- Xue, L., Constant, N., Roberts, A., Kale, M., Al-Rfou, R., Siddhant, A., Barua, A., and Raffel, C. mt5: A massively multilingual pre-trained text-to-text transformer. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies , pp. 483-498, 2021.\n- Yang, G., Hu, E., Babuschkin, I., Sidor, S., Liu, X., Farhi, D., Ryder, N., Pachocki, J., Chen, W., and Gao, J. Tuning large neural networks via zero-shot hyperparameter transfer. Advances in Neural Information Processing Systems , 34:17084-17097, 2021.\n- Zellers, R., Holtzman, A., Bisk, Y., Farhadi, A., and Choi, Y. Hellaswag: Can a machine really finish your sentence? In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , pp. 4791-4800, 2019.\n- Zeng, W., Ren, X., Su, T., Wang, H., Liao, Y., Wang, Z., Jiang, X., Yang, Z., Wang, K., Zhang, X., et al.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 92,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-93",
      "content": "57th Annual Meeting of the Association for Computational Linguistics , pp. 4791-4800, 2019.\n- Zeng, W., Ren, X., Su, T., Wang, H., Liao, Y., Wang, Z., Jiang, X., Yang, Z., Wang, K., Zhang, X., et al. Pangualpha: Large-scale autoregressive pretrained chinese language models with auto-parallel computation. arXiv preprint arXiv:2104.12369 , 2021.\n- Zhang, S., Liu, X., Liu, J., Gao, J., Duh, K., and Van Durme, B. Record: Bridging the gap between human and machine commonsense reading comprehension. arXiv preprint arXiv:1810.12885 , 2018.\n- Zhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M., Chen, S., Dewan, C., Diab, M., Li, X., Lin, X. V., et al. Opt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068 , 2022.\n- Zhu, Y., Kiros, R., Zemel, R., Salakhutdinov, R., Urtasun, R., Torralba, A., and Fidler, S. Aligning books and movies: Towards story-like visual explanations by watching movies and reading books.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 93,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-94",
      "content": "2.\n- Zhu, Y., Kiros, R., Zemel, R., Salakhutdinov, R., Urtasun, R., Torralba, A., and Fidler, S. Aligning books and movies: Towards story-like visual explanations by watching movies and reading books. In Proceedings of the IEEE international conference on computer vision , pp. 19-27, 2015.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "References",
        "chunkIndex": 94,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-95",
      "content": "| MOTIVATION                                                                                                                   | MOTIVATION",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 95,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-96",
      "content": "|\n|------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 96,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-97",
      "content": "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 97,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-98",
      "content": "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| For what purpose was the dataset cre- ated?                                                                                  | RefinedWeb was created to serve as a large-scale dataset for the pretrain- ing of large language models. It may be used on its own, or augmented with curated sources (e.g., Wikipedia, StackOverflow).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 98,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-99",
      "content": "|\n| Who created the dataset and on behalf of which entity?                                                                       | The dataset was created by the Technology Innovation Institute.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 99,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-100",
      "content": "|\n| Who created the dataset and on behalf of which entity?                                                                       | The dataset was created by the Technology Innovation Institute.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 100,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-101",
      "content": "|\n| Who funded the creation of the dataset?                                                                                      | The creation of the dataset was privately funded by the Technology Innovation Institute.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 101,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-102",
      "content": "|\n| Any other comment?                                                                                                           | RefinedWeb is built on-top of CommonCrawl, using the Macrodata Re- finement Pipeline, which combines content extraction, filtering heuristics, and deduplication. In designing RefinedWeb, we abided to the following philosophy: (1) Scale first. We intend MDR to produce datasets to be used to train 40-200B parameters models, thus requiring trillions of tokens (Hoffmann et al., 2022). For English-only RefinedWeb, we target a size of 3-6 trillion tokens.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 102,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-103",
      "content": "MDR to produce datasets to be used to train 40-200B parameters models, thus requiring trillions of tokens (Hoffmann et al., 2022). For English-only RefinedWeb, we target a size of 3-6 trillion tokens. Specifically, we eschew any labour inten- sive human curation process, and focus on CommonCrawl instead of disparate single-domain sources. (2) Strict deduplication. Inspired by the work of Lee et al. (2022), which demonstrated the value of deduplica- tion for large language models, we implement a rigorous deduplication pipeline. We combine both exact and fuzzy deduplication, and use strict settings leading to removal rates far higher than others have reported. (3) Neutral filtering. To avoid introducing further undesirable biases into the model (Dodge et al., 2021; Welbl et al., 2021), we avoid using ML-based filtering outside of language identification. We stick to simple rules and heuristics, and use only URL filtering for adult content.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 103,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-104",
      "content": "l (Dodge et al., 2021; Welbl et al., 2021), we avoid using ML-based filtering outside of language identification. We stick to simple rules and heuristics, and use only URL filtering for adult content. |\n| COMPOSITION                                                                                                                  | COMPOSITION",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 104,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-105",
      "content": "|\n| What do the instances that comprise the dataset represent?                                                                   | Instances are text-only documents, corresponding to single web pages.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 105,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-106",
      "content": "|\n| What do the instances that comprise the dataset represent?                                                                   | Instances are text-only documents, corresponding to single web pages.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 106,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-107",
      "content": "|\n| How many instances are there in total?                                                                                       | RefinedWeb contains ∼ 10 billion documents, or around 5 trillion tokens. The public version is a subset representing a tenth of the full version.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 107,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-108",
      "content": "| RefinedWeb contains ∼ 10 billion documents, or around 5 trillion tokens. The public version is a subset representing a tenth of the full version.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 108,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-109",
      "content": "|\n| Does the dataset contain all possible in- stances or is it a sample (not necessarily random) of instances from a larger set? | RefinedWeb is built using all CommonCrawl dumps until the 2023-06 one; it could be updated with additional dumps as they are released. The public release of RefinedWeb is a 600GT random extract of the 5,000GT of the full dataset. For all experiments, we randomly sampled from the public extract, or earlier development versions of it.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 109,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-110",
      "content": "The public release of RefinedWeb is a 600GT random extract of the 5,000GT of the full dataset. For all experiments, we randomly sampled from the public extract, or earlier development versions of it.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 110,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-111",
      "content": "|\n| What data does each instance consist of?                                                                                     | Each instance is a text-only document, with metadata about its origin in CommonCrawl and source page URL. We also distribute a multimodal version of RefinedWeb, containing interlaced links to images.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 111,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-112",
      "content": "|\n| Is there a label or target associated with each instance?                                                                    | No.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 112,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-113",
      "content": "|\n| Is there a label or target associated with each instance?                                                                    | No.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 113,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-114",
      "content": "|\n| Is any information missing from individ- ual instances?                                                                      | No.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 114,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-115",
      "content": "|\n| Are relationships between individual in- stances made explicit?                                                              | No.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 115,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-116",
      "content": "|\n| Are there recommended data splits?                                                                                           | No.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 116,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-117",
      "content": "|\n\n| Are there any errors, sources of noise, or redundancies in the dataset?                                                                 | Despite our best efforts to filter content that does not qualify as natural language, and to deduplicate documents, our pipeline may let through documents that may be considered as errors or redundant.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 117,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-118",
      "content": "espite our best efforts to filter content that does not qualify as natural language, and to deduplicate documents, our pipeline may let through documents that may be considered as errors or redundant.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n|-----------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 118,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-119",
      "content": "-----------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Is the dataset self-contained, or does it link to or otherwise rely on external re- sources?",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 119,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-120",
      "content": "-----------------------------------------------------------------------------|\n| Is the dataset self-contained, or does it link to or otherwise rely on external re- sources?                                            | The base version of the dataset is self-contained, but the multimodal version is interlaced with links to images-these are not distributed as part of the dataset, and constitute an external source.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n| Does the",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 120,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-121",
      "content": "|\n| Does the dataset contain data that might be considered confidential?                                                                    | All documents in RefinedWeb have been publicly available online.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 121,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-122",
      "content": "|\n| Does the dataset contain data that, if viewed directly, might be offensive, in- sulting, threatening, or might otherwise cause anxiety? | Yes, as this type of data is prevalent on the internet, it is likely our dataset contains such content. Notably, we estimate the prevalence of toxic content in the dataset to be similar to The Pile (Figure 4).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 122,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-123",
      "content": "|\n| COLLECTION                                                                                                                              | COLLECTION",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 123,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-124",
      "content": "|\n| How was the data associated with each instance acquired?                                                                                | We downloaded with warcio publicly available .WET files from the CommonCrawl foundation.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 124,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-125",
      "content": "|\n| What mechanisms or procedures were used to collect the data?                                                                            | We refer to the CommonCrawl website ( commoncrawl.org ) for de- tails on how they collect data.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 125,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-126",
      "content": "e used to collect the data?                                                                            | We refer to the CommonCrawl website ( commoncrawl.org ) for de- tails on how they collect data.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n| If the dataset is a sample from a larger set, what was the sampling strategy?",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 126,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-127",
      "content": "|\n| If the dataset is a sample from a larger set, what was the sampling strategy?                                                           | Whenever we use subsets, we randomly sample from the original data.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| Who was invol",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 127,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-128",
      "content": "|\n| Who was involved in the data collec- tion process and how were they compen- sated?                                                      | The original data collection was performed by CommonCrawl; authors from this paper were involved in retrieving it and preparing it.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 128,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-129",
      "content": "|\n| Over what timeframe was the data col- lected?                                                                                           | We use all CommonCrawl dumps from 2008 to January/February 2023.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 129,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-130",
      "content": "|\n| Were any ethical review processes con- ducted?                                                                                          | No.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 130,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-131",
      "content": "|\n| PREPROCESSING                                                                                                                           | PREPROCESSING",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 131,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-132",
      "content": "|\n| Was any preprocessing/cleaning/labeling of the data done?                                                                               | Yes, we applied extensive preprocessing and cleaning of the data.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 132,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-133",
      "content": "any preprocessing/cleaning/labeling of the data done?                                                                               | Yes, we applied extensive preprocessing and cleaning of the data. We first filter URLs to remove adult content using a blocklist and a score sys- tem (Appendix G.1), we then use trafilatura (Barbaresi, 2021) to extract content from pages, and perform language identification with the fastText classifier from CCNet (Wenzek et al., 2020). Af- ter this first preprocessing stage, we filter data using heuristics from MassiveWeb (Rae et al., 2021) and our own line-wise corrections (Ap- pendix G.2). Finally, we run extensive deduplication, removing URLs revisited across dumps (Section 3.3) and performing subsequently fuzzy and exact substring deduplication, with each stage drawing from Lee et al. (2022). See Section 3 for further details and Table 2 for an outline.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 133,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-134",
      "content": "s dumps (Section 3.3) and performing subsequently fuzzy and exact substring deduplication, with each stage drawing from Lee et al. (2022). See Section 3 for further details and Table 2 for an outline. |\n| Was the 'raw' data saved in addition to the preprocessed/cleaned/labeled data?                                                          | During development, we saved intermediary outputs from our pipeline for investigations and for ablations-intermediary outputs exist for about 5% of RefinedWeb. We did not keep intermediary outputs for the final production version of the dataset due to storage and resource constraints.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 134,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-135",
      "content": "|\n| Is the software that was used to prepro- cess/clean/label the data available?                                                           | No.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 135,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-136",
      "content": "|\n| USES                                                                                                                                    | USES",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 136,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-137",
      "content": "|\n| Has the dataset been used for any tasks already?                                                                                        | Yes, this data has been used to develop large language models: both for scientific experiments (e.g., this paper) and production use.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 137,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-138",
      "content": "| Yes, this data has been used to develop large language models: both for scientific experiments (e.g., this paper) and production use.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n\nTable 6: Datasheet for RefinedWeb , following the framework introduced by Gebru et al. (2021).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 138,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-139",
      "content": "|\n\nTable 6: Datasheet for RefinedWeb , following the framework introduced by Gebru et al. (2021).\n\n| Is there a repository that links to any or all papers or systems that use the dataset?                                                               | No.                                                                                                                                                        |\n|------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| What (other) tasks could the dataset be used for?                                                                                                    | RefinedWeb was built as a",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 139,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-140",
      "content": "--------------------|\n| What (other) tasks could the dataset be used for?                                                                                                    | RefinedWeb was built as a large-scale corpora representative of the web, and as such may see many downstream uses which are difficult to predict.          |\n| Is there anything about the composition of the dataset or the way it was col- lected and preprocessed/cleaned/labeled that might impact future uses? | For the public extract of RefinedWeb, we chose to only draw from the English version of the dataset, preventing multilingual applications.                 |\n| Are there tasks for which the dataset should not be used?                                                                                            | Any tasks which may considered irresponsible or harmful.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 140,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-141",
      "content": "re tasks for which the dataset should not be used?                                                                                            | Any tasks which may considered irresponsible or harmful.                                                                                                   |\n| DISTRIBUTION                                                                                                                                         | DISTRIBUTION                                                                                                                                               |\n| Will the dataset be distributed to third parties outside of the entity on behalf of which the dataset was created?                                   | Yes, we make a 600GT extract publicly available for NLP practitioners. We currently don't plan to share the full version of the dataset.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 141,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-142",
      "content": "ch the dataset was created?                                   | Yes, we make a 600GT extract publicly available for NLP practitioners. We currently don't plan to share the full version of the dataset.                   |\n| How will the dataset will be distributed?                                                                                                            | The dataset will be made available through the HuggingFace Hub.                                                                                            |\n| When will the dataset be distributed?                                                                                                                | The dataset is available immediately.                                                                                                                      |\n| Will the dataset be distributed under a copyright or other intellectual prop- erty (IP) license, and/or under applicable terms of use (ToU)?         | The pu",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 142,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-143",
      "content": "|\n| Will the dataset be distributed under a copyright or other intellectual prop- erty (IP) license, and/or under applicable terms of use (ToU)?         | The public extract is made available under an ODC-By 1.0 license; users should also abide to the CommonCrawl ToU: https:// commoncrawl.org/terms-of-use/ . |\n| Have any third parties imposed IP-based or other restrictions on the data associ- ated with the instances?                                           | Not to our knowledge.                                                                                                                                      |\n| Do any export controls or other regula- tory restrictions apply to the dataset or to individual instances?                                           | Not to our knowledge.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 143,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-144",
      "content": "|\n| Do any export controls or other regula- tory restrictions apply to the dataset or to individual instances?                                           | Not to our knowledge.                                                                                                                                      |\n| MAINTENANCE                                                                                                                                          | MAINTENANCE                                                                                                                                                |\n| Who will be support- ing/hosting/maintaining the dataset?                                                                                            | The dataset will be hosted on the HuggingFace Hub, we have no plans to further support or maintain it once it is released.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 144,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-145",
      "content": "| The dataset will be hosted on the HuggingFace Hub, we have no plans to further support or maintain it once it is released.                                 |\n| How can the owner/curator/manager of the dataset be contacted?                                                                                       | falconllm@tii.ae                                                                                                                                           |\n| Is there an erratum?                                                                                                                                 | No.                                                                                                                                                        |\n| Will the dataset be updated?",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 145,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-146",
      "content": "|\n| Will the dataset be updated?                                                                                                                         | No.                                                                                                                                                        |\n| If others want to extend/augment/build on/contribute to the dataset, is there a mechanism for them to do so?                                         | No.                                                                                                                                                        |",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "A. RefinedWeb Datasheet",
        "chunkIndex": 146,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-147",
      "content": "| MODEL DETAILS                                 | MODEL DETAILS                                 | MODEL DETAILS                                 | MODEL DETAILS                                                                                                                                                                                                                                                                                                                                                                |\n|-----------------------------------------------|-----------------------------------------------|-----------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "B. Falcon-RW Model Cards",
        "chunkIndex": 147,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-148",
      "content": "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Person/organization model                     | developing                                    | the                                           | The models were created by the Technology Innovation Institute.                                                                                                                                                                                                                                                                                                              |\n| Model date                                    | Model date                                    | Model date                                    | Falcon-RW models were trained in December 2022/January 2023.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "B. Falcon-RW Model Cards",
        "chunkIndex": 148,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-149",
      "content": "l date                                    | Model date                                    | Model date                                    | Falcon-RW models were trained in December 2022/January 2023.                                                                                                                                                                                                                                                                                                                 |\n| Model type and information about train- ing   | Model type and information about train- ing   | Model type and information about train- ing   | Falcon-RW are autoregressive Transformer models trained with a causal language modeling objective. Architecture based on GPT-3 (Brown et al., 2020), with ALiBi positional encodings (Press et al., 2021) and FlashAt- tention (Dao et al., 2022). See Section 4.1 for details.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "B. Falcon-RW Model Cards",
        "chunkIndex": 149,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-150",
      "content": "anguage modeling objective. Architecture based on GPT-3 (Brown et al., 2020), with ALiBi positional encodings (Press et al., 2021) and FlashAt- tention (Dao et al., 2022). See Section 4.1 for details.                                                                                              |\n| Licence                                       | Licence                                       | Licence                                       | Apache 2.0: https://www.apache.org/licenses/ LICENSE-2.0 .                                                                                                                                                                                                                                                                                                                   |\n| Point of contact                              | Point of contact                              | Point of contact                              | falconllm@tii.ae",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "B. Falcon-RW Model Cards",
        "chunkIndex": 150,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-151",
      "content": "|\n| Point of contact                              | Point of contact                              | Point of contact                              | falconllm@tii.ae                                                                                                                                                                                                                                                                                                                                                             |\n| INTENDED USE                                  | INTENDED USE                                  | INTENDED USE                                  | INTENDED USE",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "B. Falcon-RW Model Cards",
        "chunkIndex": 151,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-152",
      "content": "|\n| Primary intended uses                         | Primary intended uses                         | Primary intended uses                         | Research on large language models, and the influence of adequately filtered and deduplicated web data on the properties of large language models (fairness, safety, limitations, capabilities, etc.).                                                                                                                                                                        |\n| Primary intended users                        | Primary intended users                        | Primary intended users                        | NLP researchers.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "B. Falcon-RW Model Cards",
        "chunkIndex": 152,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-153",
      "content": "|\n| Primary intended users                        | Primary intended users                        | Primary intended users                        | NLP researchers.                                                                                                                                                                                                                                                                                                                                                             |\n| Out-of-scope use cases                        | Out-of-scope use cases                        | Out-of-scope use cases                        | Production use without adequate assessment of risks and mitigation; any use cases which may be considered irresponsible or harmful.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "B. Falcon-RW Model Cards",
        "chunkIndex": 153,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-154",
      "content": "| Out-of-scope use cases                        | Production use without adequate assessment of risks and mitigation; any use cases which may be considered irresponsible or harmful.                                                                                                                                                                                                                                          |\n| FACTORS                                       | FACTORS                                       | FACTORS                                       | FACTORS                                                                                                                                                                                                                                                                                                                                                                      |\n| Relevant factors                              | R",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "B. Falcon-RW Model Cards",
        "chunkIndex": 154,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-155",
      "content": "|\n| Relevant factors                              | Relevant factors                              | Relevant factors                              | Falcon-RW models are trained on English data only, and will not gener- alize appropriately to other languages. Furthermore, as they are trained on a large-scale corpora representative of the web, they will carry the stereotypes and biases commonly encountered online.                                                                                                  |\n| Evaluation factors                            | Evaluation factors                            | Evaluation factors                            | We evaluated the toxicity of the underlying pretraining dataset and found it to be in line with common curated pretraining datasets such as The Pile (see Figure 4).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "B. Falcon-RW Model Cards",
        "chunkIndex": 155,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-156",
      "content": "actors                            | We evaluated the toxicity of the underlying pretraining dataset and found it to be in line with common curated pretraining datasets such as The Pile (see Figure 4). Note that this only accounts for toxicity under the definition of Perspective API: 'content that is rude or disrespectful'. Notably, this fails to include concerns about social biases or harmfulness. |\n| METRICS                                       | METRICS                                       | METRICS                                       | METRICS                                                                                                                                                                                                                                                                                                                                                                      |\n| Model performance measures                    | Model performance measures",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "B. Falcon-RW Model Cards",
        "chunkIndex": 156,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-157",
      "content": "|\n| Model performance measures                    | Model performance measures                    | Model performance measures                    | We focus our evaluation on measuring the zero-shot generalization ca- pabilities of our models across a wide range of tasks, leveraging the Eleuther AI language model evaluation harness (Gao et al., 2021).                                                                                                                                                                |\n| Variation approaches                          | Variation approaches                          | Variation approaches                          | Due to the costs associated with training Falcon-RW we cannot train the models multiple times and measure variability across training runs.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "B. Falcon-RW Model Cards",
        "chunkIndex": 157,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-158",
      "content": "| Variation approaches                          | Due to the costs associated with training Falcon-RW we cannot train the models multiple times and measure variability across training runs.                                                                                                                                                                                                                                  |\n| EVALUATION DATA                               | EVALUATION DATA                               | EVALUATION DATA                               | EVALUATION DATA                                                                                                                                                                                                                                                                                                                                                              |\n| Datasets                                      | Datasets",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "B. Falcon-RW Model Cards",
        "chunkIndex": 158,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-159",
      "content": "|\n| Datasets                                      | Datasets                                      | Datasets                                      | We evaluate zero-shot accuracy on 18 varied tasks, detailed in Table 3.                                                                                                                                                                                                                                                                                                      |\n| Motivation                                    | Motivation                                    | Motivation                                    | Weselected and aggregated tasks to build comparisons with other models in the literature (see Section 4.1; Appendix F.1 for details).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "B. Falcon-RW Model Cards",
        "chunkIndex": 159,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-160",
      "content": "| Motivation                                    | Weselected and aggregated tasks to build comparisons with other models in the literature (see Section 4.1; Appendix F.1 for details).                                                                                                                                                                                                                                        |\n| Preprocessing                                 | Preprocessing                                 | Preprocessing                                 | We use the default prompts and setup of Gao et al. (2021).                                                                                                                                                                                                                                                                                                                   |\n| TRAINING DATA dedicated datasheet in Table 6.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "B. Falcon-RW Model Cards",
        "chunkIndex": 160,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-161",
      "content": "|\n| TRAINING DATA dedicated datasheet in Table 6. | TRAINING DATA dedicated datasheet in Table 6. | TRAINING DATA dedicated datasheet in Table 6. | TRAINING DATA dedicated datasheet in Table 6.                                                                                                                                                                                                                                                                                                                                |",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "B. Falcon-RW Model Cards",
        "chunkIndex": 161,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-162",
      "content": "The large-scale and diverse nature of web corpora make them difficult to document and analyse as a whole; we provide some key metrics in the section, focusing on document lengths in Figure 5(a), and a breakdown of the top domain names in Figure 5(b). We also refer to the analysis of the distribution of toxic content presented in Figure 4.\n\nFigure 5. Make-up of RefinedWeb in document lengths (left) and top domains (right). (a) We find the OSCAR datasets and RW-Raw to have similar document length distributions; following filtering, most of the short documents are discarded from RW-Filtered. As deduplication removes spans, it reintroduces shorter documents to RefinedWeb. We note the make-up of C4 and RefinedWeb to be relatively similar, with a longer tail of short documents for RefinedWeb. Finally, The Pile exhibit a unique make-up, with a long tail of both long (books, etc.) and short documents.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "C. Dataset analysis",
        "chunkIndex": 162,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-163",
      "content": "RefinedWeb to be relatively similar, with a longer tail of short documents for RefinedWeb. Finally, The Pile exhibit a unique make-up, with a long tail of both long (books, etc.) and short documents. (b) Top domains in RefinedWeb span from popular content platforms (Blogspot, WordPress, Tumblr, etc.), to news websites (CNN, New York Times, etc.), and include also technical content such as BioMed Central or Springer.\n\n<!-- image -->",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "C. Dataset analysis",
        "chunkIndex": 163,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-164",
      "content": "Multilingual data. Using the language identification filter, we classify processed CommonCrawl data into 176 languages. Figure 6 shows the top 20 languages present in the data excluding English , based on their relative contribution in descending order. 58.20% of all documents in the processed CommonCrawl data were identified as English. We find the distribution of languages in CommonCrawl to only be partially aligned with the worldwide distribution of language speakers (Eberhard et al., 2023): Russian is over-represented (2nd in CC but only 8th worldwide), Mandarin Chinese is under-represented (6-7th in CC but 2nd worldwide), and Hindi does not show-up in the top 20 despite being the 3rd most spoken.\n\nFigure 6. Top 20 languages (excluding English) from processed CommonCrawl based on number of documents and disk size.\n\n<!-- image -->",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "D. Multilingual RefinedWeb",
        "chunkIndex": 164,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-165",
      "content": "does not show-up in the top 20 despite being the 3rd most spoken.\n\nFigure 6. Top 20 languages (excluding English) from processed CommonCrawl based on number of documents and disk size.\n\n<!-- image -->\n\nProcessing multilingual data. The MDR pipeline can be used to process all languages: features such as text extraction are language-agnostic, whereas specific filters such as line-wise corrections need to typically be tuned for each individual language. We also found tuning deduplication parameters for individual languages to be beneficial.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "D. Multilingual RefinedWeb",
        "chunkIndex": 165,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-166",
      "content": "In this section, we present additional results obtained during the development of the Macrodata Refinement pipeline. For Appendix E.1 and Appendix E.3, these were obtained using earlier development versions of the dataset, so results are not directly comparable with the main text. For Appendix E.2, this is based on the Falcon-RW models.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "E. Additional results",
        "chunkIndex": 166,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-167",
      "content": "We present results in Table 8-the setup is similar to our earlier ablations, training 1B models for 30GT. We observe that:\n\n- MinHash alone is insufficient , as it doesn't match the zero-shot performance of exact deduplication. Conversely, combining it with exact deduplication doesn't improve performance further.\n- Masking spanned duplicates degrades performance , systematically underperforming other approaches. Dropping and cutting spans perform similarly, although it's likely that dropping documents slightly outperforms cutting.\n\nFinally, we chose to apply MinHash before exact deduplication, as it is easier to scale: approximate deduplication acts as a pruning phase, enabling us to scale deduplication further. Finally, we choose the common option of cutting spans, as dropping resulted in even more stringent rejection rates which would have compromised our ability to collect 5 trillion tokens.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "E.1. Small-scale ablations on deduplication approaches",
        "chunkIndex": 167,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-168",
      "content": "ation further. Finally, we choose the common option of cutting spans, as dropping resulted in even more stringent rejection rates which would have compromised our ability to collect 5 trillion tokens.\n\nTable 8. MinHash alone is insufficient to match the performance of exact substring deduplication, and combining the two does not significantly improve performance. Of all of the exact substring approaches, masking duplicated spans underperform, but all others exhibit similar performance. ✓ Minhash + Exact substring-Cut corresponds to our final deduplication setup. Perplexity in bits-per-bytes on The Pile ( pile-bpb , lower is better), zero-shot performance aggregated over LAMBADA, PIQA, and HellaSwag ( agg-dev ). Best results in bold , best results with minhash in underline, table sorted by increasing agg-dev-1 .",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "E.1. Small-scale ablations on deduplication approaches",
        "chunkIndex": 168,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-169",
      "content": "lower is better), zero-shot performance aggregated over LAMBADA, PIQA, and HellaSwag ( agg-dev ). Best results in bold , best results with minhash in underline, table sorted by increasing agg-dev-1 .\n\n| Minhash             | Exact substring     |   pile-bpb ↓ |   agg-dev-1 ↑ |\n|---------------------|---------------------|--------------|---------------|\n| RefinedWeb-Filtered | RefinedWeb-Filtered |         1.11 |         43.51 |\n| ✓ ✓ ✓ ✓ ✓           | Mask                |         1.08 |         45.84 |\n| ✓ ✓ ✓ ✓ ✓           | Mask                |         1.07 |         46.28 |\n| ✓ ✓ ✓ ✓ ✓           |                     |         1.07 |         46.57 |\n| ✓ ✓ ✓ ✓ ✓           | Cut                 |         1.05 |         47.11 |\n| ✓ ✓ ✓ ✓ ✓           | Cut                 |         1.06 |         47.24 |\n| ✓ ✓ ✓ ✓ ✓           | Drop partial        |         1.05 |         47.25 |\n| ✓ ✓ ✓ ✓ ✓           | Drop any            |         1.07 |         47.77 |\n| ✓ ✓ ✓ ✓ ✓           | Drop",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "E.1. Small-scale ablations on deduplication approaches",
        "chunkIndex": 169,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-170",
      "content": "|         47.24 |\n| ✓ ✓ ✓ ✓ ✓           | Drop partial        |         1.05 |         47.25 |\n| ✓ ✓ ✓ ✓ ✓           | Drop any            |         1.07 |         47.77 |\n| ✓ ✓ ✓ ✓ ✓           | Drop any            |         1.07 |         47.86 |\n| ✓ ✓ ✓ ✓ ✓           | Drop partial        |         1.06 |         47.97 |\n|                     | Pile                |         0.88 |         43.7  |",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "E.1. Small-scale ablations on deduplication approaches",
        "chunkIndex": 170,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-171",
      "content": "Along with our aggregates, we also evaluated perplexity on Wikitext (Table 9). We found that models trained on RefinedWeb achieve performance close to that of models trained on The Pile. Importantly, we note that RefinedWeb does not contain any content from Wikipedia - it is explicitly filtered out at the URL level. We believe this accounts for most of the difference in perplexity, as RW models may not be familiar with the idiosyncrasies of Wikitext (e.g., layout of an article, etc.)\n\nTable 9. Models trained on RefinedWeb achieve performance close to models trained on The Pile on Wikitext, despite not having seen any content from Wikipedia. Perplexity in bits-per-bytes on Wikitext ( wiki-bpb , lower is better.)\n\n| Model size Dataset   |   1B The Pile |   RW |   7B RW |\n|----------------------|---------------|------|---------|\n| wiki-bpb ↓           |          0.64 | 0.66 |     0.6 |",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "E.2. Language modeling evaluation",
        "chunkIndex": 171,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-172",
      "content": "Earlier in this work, we outlined that to scale pretraining data, practitioners had two choices: (1) improve data collection, which is the avenue we chose to pursue; (2) train models on multiple epochs of the same data. Due to current uncertainties in the ability of larger models to sustain multiple epochs without adverse effects (Hernandez et al., 2022), we focused on (1). A fairly rational question regarding (2) is whether deduplication may improve the situation, and whether deduplicated data may be able to sustain more epochs without compromising model quality.\n\nWe train 1B parameters models on 30GT of RW and RW-Filtered. We keep the number of pretraining tokens fixed, but train for 1, 5, 25, and 100 epochs. This is a small-scale, limited set-up, which would have to be improved to obtain definitive results. We plot the degradation in performance compared to a single epoch in Figure 7(a) and the gap between RW and RW-F in Figure 7(b).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "E.3. Does deduplication help with multiple epochs?",
        "chunkIndex": 172,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-173",
      "content": "d set-up, which would have to be improved to obtain definitive results. We plot the degradation in performance compared to a single epoch in Figure 7(a) and the gap between RW and RW-F in Figure 7(b). We find that the absolute degradation is less important for RefinedWeb than for RefinedWeb-Filtered; furthermore, the gap widens with increasing number of epochs. However, we observe significant variability across tasks.\n\nFigure 7. Deduplication may reduce the degradation in performance incurred by multiple epochs. However, our experiments were only performed at small-scale (1B models trained on 30GT), and we see high variability in outcomes across tasks. Zero-shot performance measured on the agg-dev-2 aggregate (HellaSwag, PIQA, ARC, BoolQ, COPA, MRPC, SciQ). Individual curves for per-task results and 1σ standard deviation across all tasks in the aggregate in transparent.\n\n<!-- image -->",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "E.3. Does deduplication help with multiple epochs?",
        "chunkIndex": 173,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-174",
      "content": "To evaluate models, we average zero-shot performance over diverse task aggregates Our aggregates are outlined in Table 3:\n\n- small : small-scale ablation studies, taskswith non-zero performance for 1B parameters models trained on 30GT;\n- core : comparisons with a wide range of models, notably based on the tasks reported in (Dey et al., 2023);\n- main : tasks available in the GPT-3 and PaLM papers (Brown et al., 2020; Chowdhery et al., 2022);\n- ext : tasks available in the work of the BigScience Architecture and Scaling group (Scao et al., 2022b).\n\nWhen comparing with models from the state-of-the-art, we source results from a few different papers, detailed in Table 10.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.1. Task aggregates",
        "chunkIndex": 174,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-175",
      "content": "We compare against nearly 50 models across 10 series trained on a variety of curated corpora, presented in Table 11.\n\nCerebras-GPT with µ -parametrization. The Cerebras-GPT series (Dey et al., 2023) also comes in a smaller series, up to 2.7B parameters, following the recommendations of µ -parametrization (Yang et al., 2021). As we found the performance of this smaller series to be close to the main series of models (see Figure 8), and as it does not include models of a similar compute scale as the ones we compare to, we chose not to report it in our main figures.\n\nTable 10. We source evaluation results from a variety of papers across the literature, maximizing task coverage. Although most results come from the EAI Evaluation Harness (Gao et al., 2021), results from PaLM and GPT-3 are sourced from their respective papers. Note in Figure 1 that the results from the GPT-3 paper are still ahead of results obtained through the API with the EAI evaluation harness.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.2. Models",
        "chunkIndex": 175,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-176",
      "content": "rom PaLM and GPT-3 are sourced from their respective papers. Note in Figure 1 that the results from the GPT-3 paper are still ahead of results obtained through the API with the EAI evaluation harness.\n\n| Models                                                                                                                                  | Aggregates reported                                                                                | Source of results                                                                                                                                                                                                                                       | EAI eval harness?     |\n|-----------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|-------------------------------------------",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.2. Models",
        "chunkIndex": 176,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-177",
      "content": "-------------------------------------------------------|----------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------|\n| Ours BS-A&S ∗ GPT-Neo ∗ PaLM † GPT-3 API ∗ GPT-3 † Aleph Alpha ∗ Cerebras-GPT ∗ FairSeq ∗ Pythia(-Dedup) ∗ OPT ∗ GPT-J ∗ GPT-NeoX 20B ∗ | main , core , ext main , core main , core main main , core main core core core core core core core | This paper Scao et al. (2022b) Scao et al. (2022b) Chowdhery et al. (2022) Scao et al. (2022b) Brown et al. (2020) Aleph Alpha (2023) Dey et al. (2023) Black et al. (2022) Dey et al. (2023) Dey et al. (2023) Black et al. (2022) Black et al. (2022) | ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ |",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.2. Models",
        "chunkIndex": 177,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-178",
      "content": ") Scao et al. (2022b) Brown et al. (2020) Aleph Alpha (2023) Dey et al. (2023) Black et al. (2022) Dey et al. (2023) Dey et al. (2023) Black et al. (2022) Black et al. (2022) | ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ |\n\nPythia and deduplication. The Pythia series of models is available in two flavours: one trained on the vanilla version of The Pile, and another trained on a version deduplicated with MinHash. Performance between these two flavours was noted to minimally differ (Biderman et al., 2023); in Figure 9, we find the deduplicated version may be slightly ahead of the non-deduplicated one under our aggregate. The higher end of this improvement is broadly in line with our findings in Table 5. Nevertheless, a difference in our findings and theirs remain. We posit a few possible hypotheses:\n\n- Differences between curated and web data. It is possible that web data is more sensitive to duplicates.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.2. Models",
        "chunkIndex": 178,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-179",
      "content": "rtheless, a difference in our findings and theirs remain. We posit a few possible hypotheses:\n\n- Differences between curated and web data. It is possible that web data is more sensitive to duplicates. For instance, the most common duplicates in web data (e.g., spam) may be more detrimental than the most common duplicates in curated data. This suggests a qualitative component to deduplication that we have not studied in this work.\n- Differences in deduplication pipeline. Because Biderman et al. (2023) uses the MinHash settings from Lee et al. (2022), they are mostly identical to ours. However, we also apply exact deduplication: while their deduplication incurs a 30% reduction in size, our deduplication is more aggressive, resulting in a 45% reduction in size. This may explain why our results in Table 5 show a stronger gain from deduplication than theirs in Figure 9.\n- Differences in pretraining. Finally, we note that Biderman et al.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.2. Models",
        "chunkIndex": 179,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-180",
      "content": "45% reduction in size. This may explain why our results in Table 5 show a stronger gain from deduplication than theirs in Figure 9.\n- Differences in pretraining. Finally, we note that Biderman et al. (2023) chooses to perform a partial extra epoch on the deduplicated data to reach 300GT, while we always perform a single epoch. Their setting corresponds to a data-constrained scenario, which is more realistic for the curated data they study; for us, web data is plentiful, so deduplication never truly limits the size of the datasets we can use.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.2. Models",
        "chunkIndex": 180,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-181",
      "content": "We extend on Table 1 in Table 12, providing details on the filtering and deduplication strategies used across the litterature.\n\nFigure 8. µ -parametrization (Yang et al., 2021) slightly improves performance in the Cerebras-GPT series (Dey et al., 2023). Zero-shot performance on our core aggregate, gap between Cerebras-GPT with µ -param and without. Individual curves for per-task results and 1σ standard deviation across all tasks in the aggregate in transparent.\n\n<!-- image -->\n\nFigure 9. In our core aggregate, deduplication brings a small improvement to the Pythia suite (Biderman et al., 2023). Zero-shot performance on our core aggregate, gap between Pythia trained on the deduplicated and vanilla Pile. Individual curves for per-task results and 1σ standard deviation across all tasks in the aggregate in transparent.\n\n<!-- image -->",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.3. Datasets",
        "chunkIndex": 181,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-182",
      "content": "ate, gap between Pythia trained on the deduplicated and vanilla Pile. Individual curves for per-task results and 1σ standard deviation across all tasks in the aggregate in transparent.\n\n<!-- image -->\n\nTable 11. Full-scale models trained on RefinedWeb (Falcon-RW) and other models from the state-of-the-art. Across models trained on The Pile, the Pythia models are the closest to our achitecture: they use FlashAttention with rotary embeddings-with for only notably exception the use of parallel attention and feedforward for their models. Training budget C in PF-days calculated using C = 6 ND , with N the number of parameters, and D the pretraining dataset size (Kaplan et al., 2020).\n\n| Series      | GPT-3 (paper) †   | GPT-3 (paper) †     | GPT-3 (API) ∗       | GPT-3 (API) ∗   | BigScience ∗        | PaLM †                  | Ours        | Ours       | Ours      |\n|-------------|-------------------|---------------------|---------------------|-----------------|---------------------|-------",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.3. Datasets",
        "chunkIndex": 182,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-183",
      "content": "| PaLM †                  | Ours        | Ours       | Ours      |\n|-------------|-------------------|---------------------|---------------------|-----------------|---------------------|-------------------------|-------------|------------|-----------|\n| Model       | XL                | XXL                 | babbage             | curie           | BS-A&S              | PaLM-8B                 | Ours (Pile) | Falcon-RW  | Falcon-RW |\n| Dataset     | GPT-3             | GPT-3               | GPT-3               | GPT-3           | Pile                | PaLM                    | Pile        | RW         | RW        |\n| Params.     | 1.3B              | 6.7B                | 1.3B                | 6.7B            | 1.3B                | 8.6B                    | 1.3B        | 1.3B       | 7.5B      |\n| Pretraining | 300GT             | 300GT               | 300GT               | 300GT           | 300GT               | 780GT                   | 350GT       | 350GT      | 350GT     |\n|",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.3. Datasets",
        "chunkIndex": 183,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-184",
      "content": "| 7.5B      |\n| Pretraining | 300GT             | 300GT               | 300GT               | 300GT           | 300GT               | 780GT                   | 350GT       | 350GT      | 350GT     |\n| PF-days     | 27                | 140                 | 27                  | 140             | 27                  | 466                     | 32          | 32         | 182       |\n| Citation    |                   | Brown et al. (2020) | Brown et al. (2020) |                 | Scao et al. (2022b) | Chowdhery et al. (2022) |             | This paper |           |\n\n| Series                                 | EleutherAI                 | ∗                                      |                                              | Pythia ∗                                                   |\n|----------------------------------------|----------------------------|----------------------------------------|----------------------------------------------|--------------------------------------------------",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.3. Datasets",
        "chunkIndex": 184,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-185",
      "content": "--------------------------------|----------------------------|----------------------------------------|----------------------------------------------|------------------------------------------------------------|\n| Model Dataset Params. PF-days Citation | GPT-Neo Pile 1.3B 380GT 34 | GPT-J Pile 6.7B 402GT 187 &Komatsuzaki | GPT-NeoX 20B Pile 20B 472GT 656 Black et al. | Pythia(-Dedup) Pile (dedup) 70M-12B 300GT 1.5 - 250 et al. |\n| Pretraining                            |                            |                                        |                                              |                                                            |\n|                                        | Black et al. (2021)        | Wang (2021)                            | (2022)                                       | Biderman (2023)                                            |",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.3. Datasets",
        "chunkIndex": 185,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-186",
      "content": "| Black et al. (2021)        | Wang (2021)                            | (2022)                                       | Biderman (2023)                                            |\n\n| Series                                             | Aleph Alpha ∗                                         | Cerebras-GPT ∗                                                    | OPT ∗                                                                      | FairSeq ∗                                                      |\n|----------------------------------------------------|-------------------------------------------------------|-------------------------------------------------------------------|----------------------------------------------------------------------------|----------------------------------------------------------------|\n| Model Dataset Params.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.3. Datasets",
        "chunkIndex": 186,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-187",
      "content": "---------------------------------|----------------------------------------------------------------------------|----------------------------------------------------------------|\n| Model Dataset Params. Pretraining PF-days Citation | Luminous undisclosed 13B 400GT 361 Aleph Alpha (2023) | Cerebras-GPT Pile 111M-13B 2 - 257GT 0.02 - 232 Dey et al. (2023) | OPT Pile (subset) + curated 125M - 175B 300GT 3 - 3646 Zhang et al. (2022) | FairSeq curated 1.3 - 13B 300GT 27 - 271 Artetxe et al. (2021) |\n\nTable 12. Common massive web-scrape and LLM English datasets. Datasets such as OSCAR and C4 also have significant multilingual versions, which have enjoyed wide adoption (Xue et al., 2021). For OSCAR, the size corresponds to the non-deduplicated version, and is estimated from the number of words x0,75 (average number of words per tokens).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.3. Datasets",
        "chunkIndex": 187,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-188",
      "content": "ch have enjoyed wide adoption (Xue et al., 2021). For OSCAR, the size corresponds to the non-deduplicated version, and is estimated from the number of words x0,75 (average number of words per tokens).\n\n| Deduplication                                                                                                                                                     | Exact : three sentences span (optional) Exact : per line ( ∼ 55% removed) NSFW (optional) Ex- act : per line   | Fuzzy : min- hash with 10 hashes ( ∼ 10% removed) Fuzzy : min- hash with 10 hashes, sim. treshold 0.5 ( ∼ 26% re- moved)                        | Exact &fuzzy : exact docu- ments, minhash w/ sim. treshold 0.8 Unknown   |\n|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|--------------------",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.3. Datasets",
        "chunkIndex": 188,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-189",
      "content": "------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------|\n| Content filtering Rules-based: code, NSFW None                                                                                                                    | Optional blocklist fastText trained on HQ-data fastText on cu- rated crawl                                     | SafeSearch                                                                                                                                      | ML-based filter on HQ data                                               |\n| Heuristics Document and line-level Line < 100 characters Line-level, optional document-level",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.3. Datasets",
        "chunkIndex": 189,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-190",
      "content": "| ML-based filter on HQ data                                               |\n| Heuristics Document and line-level Line < 100 characters Line-level, optional document-level                                                                      | Unknown                                                                                                        | None Document- level                                                                                                                            | Document- level                                                          |\n| Language ID Document- level w/ langdetect Line-level w/ fastText (Joulin et al., 2016) Document- level w/ fast- Text (Joulin et al., 2016)                        | Unknown Document- level w/ pycld2 (Sites, 2013)                                                                | Unknown",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.3. Datasets",
        "chunkIndex": 190,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-191",
      "content": "2 (Sites, 2013)                                                                | Unknown                                                                                                                                         | Unknown                                                                  |\n| data HTML extraction MASSIVE WEB DATASETS % .WET files % .WET files % .WET files                                                                                  | CURATED DATASETS Unknown jusText (Pomik´ alek, 2011)                                                           | Custom                                                                                                                                          | Unknown OURS                                                             |\n| Web Web 100 100                                                                                                                                                   | 100 60 %",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.3. Datasets",
        "chunkIndex": 191,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-192",
      "content": "|\n| Web Web 100 100                                                                                                                                                   | 100 60 %                                                                                                       | 18 % 48 %                                                                                                                                       | 27 %                                                                     |\n| Availability Public Public Public                                                                                                                                 | Private                                                                                                        | Public Private                                                                                                                                  | Private",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.3. Datasets",
        "chunkIndex": 192,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-193",
      "content": "| Private                                                                  |\n| models Size ∼ 360 GT ∼ 370 GT ∼ 283 GT                                                                                                                            | 300 GT ∼ 340 GT                                                                                                | Pythia 1 , 400 GT                                                                                                                               | 780 GT                                                                   |\n| General information Dataset Notable C4 (Raffel et al., 2020) T5 (Raffel et al., 2020) OSCAR 21.09 (Ortiz Su´ arez et al., 2019) OSCAR 22.01 (Abadji et al., 2022) | ■ GPT-3 (Brown et al., 2020) The Pile et al., GPT-J (Wang& Komatsuzaki, 2021), GPT- NeoX-20B (Black et al.,    | ▼ (Gao 2020) 2022),",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.3. Datasets",
        "chunkIndex": 193,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-194",
      "content": "9 (Ortiz Su´ arez et al., 2019) OSCAR 22.01 (Abadji et al., 2022) | ■ GPT-3 (Brown et al., 2020) The Pile et al., GPT-J (Wang& Komatsuzaki, 2021), GPT- NeoX-20B (Black et al.,    | ▼ (Gao 2020) 2022), (Biderman et al., 2023), Cerebras-GPT (Dey et al., 2023) al., Gopher (Rae et al., 2021), Chinchilla (Hoffmann et al., 2022) | MassiveWeb (Rae et 2021) ⋆ PaLM (Chowdhery et al., 2022)                 |",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "F.3. Datasets",
        "chunkIndex": 194,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-195",
      "content": "As discussed in Section 3.1, we base our filtering of adult documents only on the URL itself, and not on the content of the documents. This design choice was motivated by: (1) challenges in avoiding overfiltering content from minorities when using ML-based classifiers on the content of documents (Welbl et al., 2021); (2) NSFW words block-list applied on content (such as the one used in C4) also resulting in overfiltering of legal and medical content (Dodge et al., 2021).\n\nOur URL filtering focuses on finding domains that are related to adult content, that may be harmful to users, or that are very likely to contain mostly unstructured text/spam (e.g., file hosting websites). First, we aggregated a list of 4.6M domains, detailed in Appendix G.1.1, that we explicitly ban; then, we built a simple URL scoring system, based on matching subwords in the URL against a list of words we curated (see Appendix G.1.2).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.1. URL filtering",
        "chunkIndex": 195,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-196",
      "content": "domains, detailed in Appendix G.1.1, that we explicitly ban; then, we built a simple URL scoring system, based on matching subwords in the URL against a list of words we curated (see Appendix G.1.2). We curated this list of words based on manual inspection, cross-referencing results with pages surfaced by ToxicBERT as being outliers in toxicity (Hanu &amp; Unitary team, 2020).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.1. URL filtering",
        "chunkIndex": 196,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-197",
      "content": "Origin of the list. We use an aggregated list † of about 4.6M URLs that we explicitly ban. This list is broken in categories (e.g. pornography, gambling); we outline the categories we selected in Table 13. The list is regularly updated, with an original intended usage as a blocklist for universities.\n\nCuration. We noticed the list blocked a number of domains inappropriately; while these domains were few ( &lt; 100), they accounted for a significant portion of the data filtered by the list, as these were rather prolific domains, with thousands of pages of content. To identify these false positive domains, we applied the blocklist to a subset of 832M pages. 6.04M ( 0 . 73% ) pages matched with the blocklist, and the number of occurrences per URL ranged from 1 to 79k. We manually inspected all URLs matched more than 4k times, which represented an appreciable portion of the dataset.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.1.1. URL BLOCKLIST",
        "chunkIndex": 197,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-198",
      "content": "ched with the blocklist, and the number of occurrences per URL ranged from 1 to 79k. We manually inspected all URLs matched more than 4k times, which represented an appreciable portion of the dataset. We found a number of benign domains, such as pop culture news websites, or blogging platforms, which we removed from the list.\n\nTable 13. We select categories likely to contain adult or malicious content, as well as spam or unstructured text.\n\n| Category    | Description                                        |   Number of links |\n|-------------|----------------------------------------------------|-------------------|\n| adult       | adult websites: from eroticism to hard pornography |           4516478 |\n| phishing    | phishing websites, malwares, etc.                  |             42445 |\n| dating      | dating websites                                    |              3829 |\n| gambling    | online casino                                      |              1365 |\n| filehosting | websi",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.1.1. URL BLOCKLIST",
        "chunkIndex": 198,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-199",
      "content": "| dating      | dating websites                                    |              3829 |\n| gambling    | online casino                                      |              1365 |\n| filehosting | websites hosting files, videos, pictures, music    |               909 |\n| ddos        | websites related to ddos attacks                   |               421 |\n| agressif    | hate, racism, etc                                  |               390 |\n| chat        | online chat websites                               |               244 |\n| mixed adult | websites with some adult content                   |               153 |\n| arjel       | French regulated gambling websites                 |                69 |",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.1.1. URL BLOCKLIST",
        "chunkIndex": 199,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-200",
      "content": "To score URLs, we used three matching patterns based on a soft, hard, and strict violation word-list:\n\n- Strict subword matching : http://foobann.edsub-wo.rdbar.com/any/bar, matching words such as xvideos , groupsex ;\n- Hard whole word matching : http://www.foo.bannedword-bar.com, with words such as porn , xxx , orgy ;\n- Soft words matching : http://www.foo.soft1-bar-soft2.com, with 'softer' words such as sex , webcam , escort .\n\nEach list is associated with a different level of severity: for the strictest one (strict subword matching), we ban any URL matching a banned word in its substrings (as fraudulent websites may attempt to escape similar recognition schemes by breaking-up adult keywords); for the hard whole word matching, we ban URLs with a whole word matching in the list; finally, a minimum of two matches are required with the soft word matching.\n\n† https://dsi.ut-capitole.fr/blacklists/",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.1.2. URL SCORING WITH A WORD-LIST",
        "chunkIndex": 200,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-201",
      "content": "the hard whole word matching, we ban URLs with a whole word matching in the list; finally, a minimum of two matches are required with the soft word matching.\n\n† https://dsi.ut-capitole.fr/blacklists/\n\nWe curated the lists based on manual inspection of the data, informed by top hits reported by ToxicBERT. For the strict subword matching, we included words that were unequivocally related to adult content (e.g., groupsex ). We avoided partial unclear matches (e.g., ass ), that may be part of neutral words (e.g., massachusetts ). In the soft word list, we included words that do not constitute a sufficient reason to discard the document on their own, but which are suspicious when multiple words from the list result in a match. This helped with keeping medical or legal content unaffected (e.g., a single match of dick ).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.1.2. URL SCORING WITH A WORD-LIST",
        "chunkIndex": 201,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-202",
      "content": "Since our paper focuses on the study of RefinedWeb alone, we chose to exclude common online sources of curated data from it. This serves two objectives: (1) it strengthens our results, by ensuring that RefinedWeb doesn't end-up actually being made mostly of known high-quality sources (e.g., Wikipedia represents a significant portion of C4); (2) future works may be interested in combining RefinedWeb with existing curated copora, which would require further deduplication if they are included in RefinedWeb. Accordingly, we remove common sources used in The Pile (Gao et al., 2020) from RefinedWeb. The full list of curated data sources domains that we blocked is in Table 14.\n\nTable 14. RefinedWeb is stripped from common so-called high-quality sources to simplify combining it with existing curated corpora . This blocklist is applied at the URL filtering stage, along with the adult content blocklist.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.1.3. EXCLUDED HIGH QUALITY SOURCES",
        "chunkIndex": 202,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-203",
      "content": "ripped from common so-called high-quality sources to simplify combining it with existing curated corpora . This blocklist is applied at the URL filtering stage, along with the adult content blocklist.\n\n| Curated data source   | Domain name blocked                                                |\n|-----------------------|--------------------------------------------------------------------|\n| arxiv                 | arxiv.org                                                          |\n| AskUbuntu             | askubuntu.com                                                      |\n| StackOverflow         | stackoverflow.com stackapps.com stackexchange.com mathoverflow.net |\n| NIH Abstracts         | exporter.nih.gov ncbi.nlm.nih.gov                                  |\n| Github                | github.com                                                         |\n| Ubuntu IRC            | irclogs.ubuntu.com                                                 |\n| HackerNews            | news.ycombin",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.1.3. EXCLUDED HIGH QUALITY SOURCES",
        "chunkIndex": 203,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-204",
      "content": "thub.com                                                         |\n| Ubuntu IRC            | irclogs.ubuntu.com                                                 |\n| HackerNews            | news.ycombinator.com                                               |\n| FreeLaw               | courtlistener.com                                                  |\n| Reddit                | reddit.com                                                         |\n| Europarl              | statmt.org                                                         |\n| United States Patents | uspto.gov                                                          |\n| Wikipedia             | wikipedia.org                                                      |",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.1.3. EXCLUDED HIGH QUALITY SOURCES",
        "chunkIndex": 204,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-205",
      "content": "Despite the improvements brought forth by running text extraction with Trafilatura, we found that a number of irrelevant lines still seeped through. These lines are usually related to navigation menus, call to actions, or social media counters. Following manual inspection of the data, we devised a line-wise filtering strategy. We analyse documents line-by-line, and discard or edit the lines based on the following rules:\n\n- If it is mainly composed of uppercase characters (discard);\n- If it is only composed of numerical characters (discard);\n- If it is a counter (e.g. 3 likes ) (discard);\n- If it only contains one word (discard);\n- If it is short ( ≤ 10 words) and matches a pattern (edit):\n- -At the beginning of the line (e.g. sign-in );\n- -At the end of the line (e.g. Read more... );\n- -Anywhere in the line (e.g. items in cart ).",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.2. Line-wise filtering",
        "chunkIndex": 205,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-206",
      "content": "it is short ( ≤ 10 words) and matches a pattern (edit):\n- -At the beginning of the line (e.g. sign-in );\n- -At the end of the line (e.g. Read more... );\n- -Anywhere in the line (e.g. items in cart ).\n\nFinally, if the words in the flagged lines represent more than 5% of the total document words, the document is discarded. We derived these filters through manual inspection of the data, and note that they require adaptation across languages.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.2. Line-wise filtering",
        "chunkIndex": 206,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-207",
      "content": "We make use of the two deduplication methods described in Lee et al. (2022): EXACTSUBSTR and NEARDEDUP (detailed in Appendix G.3.1 and Appendix G.3.2; see Appendix H for samples of duplicates).\n\nWe start with the most scalable approach, NEARDEDUP. We remove similar documents by applying MinHash (Broder, 1997), whereby a signature/sketch supporting efficient approximate similarity queries is computed for each document in the dataset, and document pairs with a high n -gram overlap are identified.\n\nWe then use EXACTSUBSTR, leveraging the implementation from Lee et al. (2022) ‡ , to identify ranges of exact duplicate text of at least 50 tokens. We experiment with three different approaches for these ranges: EXACTSUBSTR-CUT, where we remove them from the original text, as done in the original implementation; EXACTSUBSTR-MASK, where the dataset is unchanged but we do not compute the loss on the duplicated ranges; and EXACTSUBSTR-DROP, where we simply drop an entire document if the duplicated",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.3. Deduplication",
        "chunkIndex": 207,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-208",
      "content": "mplementation; EXACTSUBSTR-MASK, where the dataset is unchanged but we do not compute the loss on the duplicated ranges; and EXACTSUBSTR-DROP, where we simply drop an entire document if the duplicated ranges make up more than a certain percentage of its content.\n\nWe present small-scale ablations around these different approaches in Appendix E.1.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.3. Deduplication",
        "chunkIndex": 208,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-209",
      "content": "We employ MinHash to find approximate duplicate documents in our web corpora at a very large scale. This technique allows us to identify templated pages or otherwise very similar content where most of the interspersed duplicated sections are small enough to not be identified by exact matching methods (anything smaller than 50 tokens).\n\nSigning. We start by normalizing the content to increase recall: punctuation is removed, text is lowercased, NFD Unicode normalization is applied, accents are removed, and all whitespace is normalized. We tokenize the resulting text using the GPT-2 tokenizer (Radford et al., 2019) and obtain the set of unique n -grams for each document. Hash functions are used to obtain a signature for each document: for each hash function, the smallest value is kept from hashing every unique n -gram in the document.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.3.1. MINHASH APPROXIMATE MATCHING",
        "chunkIndex": 209,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-210",
      "content": "nique n -grams for each document. Hash functions are used to obtain a signature for each document: for each hash function, the smallest value is kept from hashing every unique n -gram in the document. If two documents are similar, then there is a high probability that they will have the same minimum hash (MinHash) for at least some of the hash functions used (Broder, 1997). The ratio of matching hashes between two documents approximates the Jaccard Similarity (Jaccard, 1912) of the sets of their unique n -grams (the sets being d i and d j ):\n\n<!-- formula-not-decoded -->\n\nMatching. Since comparing MinHash signatures between every possible document pair is computationally expensive, we apply a locality sensitive hashing version of MinHash, MinHash LSH. A document signature is split into r buckets, each with b minhashes.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.3.1. MINHASH APPROXIMATE MATCHING",
        "chunkIndex": 210,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-211",
      "content": "n every possible document pair is computationally expensive, we apply a locality sensitive hashing version of MinHash, MinHash LSH. A document signature is split into r buckets, each with b minhashes. Documents are indexed by these b minhashes on each of the r buckets, and we mark two documents as duplicates if their b minhashes are exactly the same on at least one of the buckets. These two parameters, b and r , will determine the probability that similar documents will be detected. For two documents i and j whose ratio of matching hashes between their MinHash signatures is s i,j , the probability that there is a match in a given bucket is s b i,j ; the probability that there isn't a match in any of the buckets is (1 -s b i,j ) r ; and finally that there is a match in at least one of the buckets:\n\n<!-- formula-not-decoded -->",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.3.1. MINHASH APPROXIMATE MATCHING",
        "chunkIndex": 211,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-212",
      "content": "bucket is s b i,j ; the probability that there isn't a match in any of the buckets is (1 -s b i,j ) r ; and finally that there is a match in at least one of the buckets:\n\n<!-- formula-not-decoded -->\n\nWe use the same parameters as Lee et al. (2022): n = 5 ( 5 -grams); b = 20 and r = 450 . This means that for each document, we compute a total of 9000 minhashes, and that the probability that a document pair with similarity 0.75 or 0.8 will be marked as duplicates will be 76% and 99 . 4% (respectively), diminishing rapidly for smaller similarity values.\n\nFinally, we cluster documents across all buckets - if documents A and B match in one bucket and B and C in another, A-B-C becomes a cluster. We randomly remove all but one of the documents in each cluster.\n\nLee et al. (2022) also proposed filtering down on false positives by computing the real Jaccard similarity, or other metrics such as the edit similarity between identified document pairs.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.3.1. MINHASH APPROXIMATE MATCHING",
        "chunkIndex": 212,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-213",
      "content": "ch cluster.\n\nLee et al. (2022) also proposed filtering down on false positives by computing the real Jaccard similarity, or other metrics such as the edit similarity between identified document pairs. Given the large amount of data we have available across all of CommonCrawl, and that our main concern is improving recall, we decided to skip this additional step.\n\n‡ https://github.com/google-research/deduplicate-text-datasets",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.3.1. MINHASH APPROXIMATE MATCHING",
        "chunkIndex": 213,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-214",
      "content": "We make use of the EXACTSUBSTR implementation publicly released by Lee et al. (2022) for exact text matching. We apply exact substring deduplication to data that has already been deduplicated by MinHash, reducing by nearly 40% size of the dataset on which we have to operate. EXACTSUBSTR will find long strings of text that are present, character for character, across multiple documents. Some of these may have escaped the earlier stage of approximate deduplication: they might not constitute a big enough portion of the document; one document might have repeated sections sourced across many different documents; or they may simply not have been found due to the approximate nature of MinHash.\n\nFinding duplicates. EXACTSUBSTR concatenates all the documents in the dataset to create a single long text sequence; then, it builds a suffix array (Manber &amp; Myers, 1993) in linear time-an array of the indexes to a lexicographical ordering of all the suffixes in the sequence.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.3.2. EXACT SUBSTRING DEDUPLICATION",
        "chunkIndex": 214,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-215",
      "content": "create a single long text sequence; then, it builds a suffix array (Manber &amp; Myers, 1993) in linear time-an array of the indexes to a lexicographical ordering of all the suffixes in the sequence. Finally, duplicate sequences can also be found in linear time using the suffix array, by simply traversing the ordered list of suffixes and comparing the beginning of each pair of two consecutive suffixes.\n\nWe apply the same normalization and tokenization as for MinHash to the content of our documents before concatenating them. One important difference is that reversibility is important: for MinHash, we were discarding entire documents, and thus never relying on the normalized+tokenized representation for downstream use. Here, once we have identified duplicate normalized+tokenized spans, we need to revert to the original span to remove it. Accordingly, we include normalization in the tokenization process, and validate that the process is reversible.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.3.2. EXACT SUBSTRING DEDUPLICATION",
        "chunkIndex": 215,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-216",
      "content": "plicate normalized+tokenized spans, we need to revert to the original span to remove it. Accordingly, we include normalization in the tokenization process, and validate that the process is reversible.\n\nIf a match is longer than 50 tokens, there will be multiple overlapping duplicated ranges. These overlapping duplicated ranges in the concatenated dataset sequence are merged before we save them to a file. We then take these ranges and retrieve the original document that produced them, obtaining the character substrings corresponding to the duplicated token ranges.\n\nRemoving duplicates. We considered applying the following transformations to the duplicate spans:\n\n- EXACTSUBSTR-CUT: we remove the duplicated spans, and discard documents where there are fewer than 20 nonduplicated characters left-this is the vanilla setting used by Lee et al.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.3.2. EXACT SUBSTRING DEDUPLICATION",
        "chunkIndex": 216,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-217",
      "content": "he duplicate spans:\n\n- EXACTSUBSTR-CUT: we remove the duplicated spans, and discard documents where there are fewer than 20 nonduplicated characters left-this is the vanilla setting used by Lee et al. (2022);\n- EXACTSUBSTR-MASK: we loss-mask the duplicated spans, preventing a loss from being computed on the duplicated text during pretraining, and discard documents where there are fewer than 20 non-masked characters left.\n- EXACTSUBSTR-DROPPARTIAL: if more than 20% of the document is duplicated, we remove the entire document;\n- EXACTSUBSTR-DROPANY: we drop any document with a duplicated span in it.\n\nBroadly speaking, EXACTSUBSTR-CUT might remove text mid-sentence resulting in disconnected text; EXACTSUBSTRMASK does not have this issue, but might be less efficient as a significant portion of the training tokens will not directly contribute to updating the model's weights; EXACTSUBSTR-DROP might still keep considerable duplicated sections in its PARTIAL version, especially on larger docum",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.3.2. EXACT SUBSTRING DEDUPLICATION",
        "chunkIndex": 217,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-218",
      "content": "the training tokens will not directly contribute to updating the model's weights; EXACTSUBSTR-DROP might still keep considerable duplicated sections in its PARTIAL version, especially on larger documents, while the ANY version might be overly aggressive. Following ablations in Appendix E.1, we choose to stick with the vanilla approach, EXACTSUBSTR-CUT.\n\nNote that in all cases, while MinHash keeps one copy of the duplicated documents, our exact deduplication removes all copies of the duplicated span.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.3.2. EXACT SUBSTRING DEDUPLICATION",
        "chunkIndex": 218,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-219",
      "content": "Most data processing took place in large CPU clusters, with 100-250 AWS c5.18xlarge instances; each instance has 72 vCPUs and 144 GiB of memory. We usually run with 10,000-20,000 vCPUs in the cluster, enabling rapid parallel processing.\n\nFor EXACTSUBSTR, the entire dataset being deduplicated needs to be loaded onto memory: we leveraged the AWS x2iedn instances, which come with up to 2 TiB of memory in a single instance.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "G.4. Execution environment",
        "chunkIndex": 219,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-220",
      "content": "We report the 8 largest duplicate clusters found by MinHash in Table 15 - each spanning hundreds of thousands of documents. We also found a large number of duplicate document pairs to be due to different URL GET parameters not resulting in significantly different content. An example of this behaviour can be seen in the URLs presented in Table 16.\n\nTable 15. Top-8 largest MinHash clusters found when building RefinedWeb. We cut some of the longest samples in the interest of readability, only keeping a brief description.\n\n| Description                                                                                | Example document",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "H.1. MinHash clusters",
        "chunkIndex": 220,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-221",
      "content": "|\n|--------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "H.1. MinHash clusters",
        "chunkIndex": 221,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-222",
      "content": "----------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "H.1. MinHash clusters",
        "chunkIndex": 222,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-223",
      "content": "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Wordpress sitemap notice generated by the Google Sitemap Generator Plugin                  | This is a XML Sitemap which is supposed to be processed by search engines which follow the XML Sitemap standard like Ask.com, Bing, Google and Yahoo. It was generated using the WordPress content management system and the Google Sitemap Generator Plugin by Arne Brachhold. You can find more information about XMLsitemaps on sitemaps.org and Google's list of sitemap programs. This file contains links to sub-sitemaps, follow them to see the actual sitemap content.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "H.1. MinHash clusters",
        "chunkIndex": 223,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-224",
      "content": "|\n| Templated disability notice, with different phone numbers across pages                     | Welcome to our website! As we have the ability to list over one million items on our website (our selection changes all of the time), it is not feasible for a company our s",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "H.1. MinHash clusters",
        "chunkIndex": 224,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-225",
      "content": "pages                     | Welcome to our website! As we have the ability to list over one million items on our website (our selection changes all of the time), it is not feasible for a company our size to record and playback the descriptions on every item on our website. However, if you are an American with a disability we are here to help you. Please call our disability services phone line at [redacted] or [redacted] during regular business hours and one of our kind and friendly personal shoppers will help you navigate through our website, help conduct advanced searches, help you choose the item you are looking for with the specifications you are seeking, read you the specifications of any item and consult with you about the products themselves. There is no charge for the help of this personal shopper for any American with a disability. Finally, your personal shopper will explain our Privacy Policy and Terms of Service, and help you place an order if you so desire.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "H.1. MinHash clusters",
        "chunkIndex": 225,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-226",
      "content": "the help of this personal shopper for any American with a disability. Finally, your personal shopper will explain our Privacy Policy and Terms of Service, and help you place an order if you so desire. |\n| Templated cookies notice                                                                   |",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "H.1. MinHash clusters",
        "chunkIndex": 226,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-227",
      "content": "|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n| Different pages across more than 80 dif",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "H.1. MinHash clusters",
        "chunkIndex": 227,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-228",
      "content": "|\n| Different pages across more than 80 different domain names but with a common section       | DC Customers also liked: Special event items are produced by man- ufacturers only after the outcome of a game or event. These are advanced sale items and will ship immediately after they are received in our warehouse. Manufacturer direct items are shipped directly from the manufacturer. These items are not available for international or expedited shipping. Customized items can be personalized with options such as your name, your favorite number, and/or designs. Some options may be limited by league rules.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "H.1. MinHash clusters",
        "chunkIndex": 228,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-229",
      "content": "| http://gamesandbiz.blogspot.com/2010/ 07/bad-reviews-can-hurt-game-sales.ht ml?showComment=1278486430242                                                                                                                                                                                | http://gamesandbiz.blogspot.com/2010/ 07/bad-reviews-can-hurt-game-sales.ht ml?showComment=1278499674195                                                                                                                                   |\n|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "Table 16. URL with different GET parameters don't always result in significantly different page content.",
        "chunkIndex": 229,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-230",
      "content": "---|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| https://www.ocean-oxygen.org/home;jse ssionid=1E3290E84F668552FAC643D0A8F81 BEC?p_p_id=122_INSTANCE_Zy6zjkRLAg7v& p_p_lifecycle=0&p_p_state=normal&p_p_ mode=view&p_p_col_id=column-2&p_p_col _pos=1&p_p_col_count=6&p_r_p_56423352 4_resetCur=true&p_r_p_564233524_categ oryId=1346016 | https://www.ocean-oxygen.org/home?p_p _id=122_INSTANCE_Zy6zjkRLAg7v&p_p_lif ecycle=0&p_p_state=normal&p_p_mode=vi ew&p_p_col_id=column-2&p_p_col_pos=1& p_p_col_count=6&p_r_p_564233524_reset Cur=true&p_r_p_564233524_categoryId=1 346016 |",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "Table 16. URL with different GET parameters don't always result in significantly different page content.",
        "chunkIndex": 230,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-231",
      "content": "Examples of exact matches found by exact substring deduplication can be seen in Table 17.\n\nTable 17. Matches found by exact substring deduplication (in italics ).\n\n| it appears there is a transfer of ranking signals in this rela- tionship. Supporting this finding is a quote from Google's guidelines: Using JavaScript to redirect users can be a legitimate practice. For example, if you redirect users to an internal page once they're logged in, you can use JavaScript to do so. When examining JavaScript or other redirect meth- ods to ensure your site adheres to our guidelines, consider the intent. Keep in mind that 301 redirects are best when moving your site, but you could use a JavaScript redirect for this purpose if you don't have access to your website's server. NOTE: Their experiment is based on a live page with status code 200 and NOT an inactive page.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "H.2. Exact substring matches",
        "chunkIndex": 231,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-232",
      "content": "ut you could use a JavaScript redirect for this purpose if you don't have access to your website's server. NOTE: Their experiment is based on a live page with status code 200 and NOT an inactive page. So if you want to implement this for legacy   | Some examples of sneaky redirects include: - Search en- gines shown one type of content while users are redirected to something significantly different. - Desktop users receive a normal page, while mobile users are redirected to a com- pletely different spam domain. Using JavaScript to redirect users can be a legitimate practice. For example, if you redi- rect users to an internal page once they're logged in, you can use JavaScript to do so. When examining JavaScript or other redirect methods to ensure your site adheres to our guidelines, consider the intent. Keep in mind that 301 redirects are best when moving your site, but you could use a JavaScript redirect for this purpose if you don't have access to your website's server.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "H.2. Exact substring matches",
        "chunkIndex": 232,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-233",
      "content": "elines, consider the intent. Keep in mind that 301 redirects are best when moving your site, but you could use a JavaScript redirect for this purpose if you don't have access to your website's server.   |\n|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "H.2. Exact substring matches",
        "chunkIndex": 233,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-234",
      "content": "---------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Find Palm Beache FL homes for sale and other Palm Beach real estate on homesofthepalmbeaches.com.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "H.2. Exact substring matches",
        "chunkIndex": 234,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-235",
      "content": "---------------------------------------------------------------------------------------------------|\n| Find Palm Beache FL homes for sale and other Palm Beach real estate on homesofthepalmbeaches.com. Browse and search Palm Beach houses, condos, townhomes and single- family homes by community , building, or location. Our extensive database of real estate listings provide the most comprehensive property details including home values, fea- tures and local school and neighborhood info so you can be sure that you have nearly all the facts you need upfront. Search homesofthepalmbeaches.com today! Want a closer look at what other Palm Beach properties are available?                                                                                                                                                                                     | Search Stuart houses, condos, townhomes and single-family homes by price and location.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "H.2. Exact substring matches",
        "chunkIndex": 235,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-236",
      "content": "| Search Stuart houses, condos, townhomes and single-family homes by price and location. Our extensive database of real estate listings provide the most comprehensive property details including home values, features and local school and neighborhood info so you can be sure that you have nearly all the facts you need upfront. Search Stuart Listings today! Want a closer look at what other Stuart properties are available? Also search our listings for the Newest Stuart Listings and Stuart Homes with Price Reductions now. Stu- art FL Homes for Sale - Stuart Real Estate Listings FREE to search Stuart Property                                                                                                                                    |\n| To find the correct size you should measure your foot from the heel to the toe point.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "H.2. Exact substring matches",
        "chunkIndex": 236,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-237",
      "content": "|\n| To find the correct size you should measure your foot from the heel to the toe point. Add approximately 1 - 1,5cm to get the actual inner sole length. Measure both feet and fit shoes to the larger foot. Measure feet at the end of the day, when your feet are at their largest. Lente shoes are women's easy slip-on leisure shoes for everyday use. These lightweight shoes have a breathable textile mesh upper made of recycled PET bottles and cool Lycra lining.                                                                                                                                                                                                                                                                                                 | To find the correct size you should measure your foot from the heel to the toe point.",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "H.2. Exact substring matches",
        "chunkIndex": 237,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-238",
      "content": "| To find the correct size you should measure your foot from the heel to the toe point. Add approximately 1 - 1,5cm to get the actual inner sole length. Measure both feet and fit shoes to the larger foot. Measure feet at the end of the day, when your feet are at their largest. Enjoy your summer days with Masera leisure sneakers. These low-cut women's sneakers are extremely lightweight thanks to phylon midsole and breathable textile mesh upper                                                                                                                                                                                                                                                                                                        |\n| This bandana makes the perfect addition to every fur babies birthday collection! With its sparkly crown pattern, your pup will be ready for e",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "H.2. Exact substring matches",
        "chunkIndex": 238,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-239",
      "content": "|\n| This bandana makes the perfect addition to every fur babies birthday collection! With its sparkly crown pattern, your pup will be ready for every birthday celebration! With snaps for security, this bandana is made with love, down to the very last stitch ! Fabric: cotton Care Instructions: Hand wash only, iron as needed, on low heat Always supervise your pup while wearing Faithful Paws Co. accessories, as it could become a choking hazard if consumed.                                                                                                                                                                                                                                                                                                     | This bandana makes the perfect addition to every fur babies summer collection! With its vibrant watercolor popsicle pattern, your pup will be ready for every summer cook- out! With snaps for se",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "H.2. Exact substring matches",
        "chunkIndex": 239,
        "totalChunks": 241
      }
    },
    {
      "id": "2306.01116v1-chunk-240",
      "content": "| This bandana makes the perfect addition to every fur babies summer collection! With its vibrant watercolor popsicle pattern, your pup will be ready for every summer cook- out! With snaps for security, this bandana is made with love, down to the very last stitch ! Fabric: cotton Care Instructions: Hand wash only, iron as needed, on low heat Always supervise your pup while wearing Faithful Paws Co. accessories, as it could become a choking hazard if consumed.                                                                                                                                                                                                                                                                                       |",
      "metadata": {
        "source": "arxiv:2306.01116v1",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "authors": [
          "Guilherme Penedo",
          "Quentin Malartic",
          "Daniel Hesslow",
          "Ruxandra Cojocaru",
          "Alessandro Cappelli",
          "Hamza Alobeidli",
          "Baptiste Pannier",
          "Ebtesam Almazrouei",
          "Julien Launay"
        ],
        "section": "H.2. Exact substring matches",
        "chunkIndex": 240,
        "totalChunks": 241
      }
    }
  ],
  "fullText": "## The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only\n\n## The Falcon LLM team\n\nGuilherme Penedo 1 Quentin Malartic 2\n\nDaniel Hesslow 1 Ruxandra Cojocaru 2 Alessandro Cappelli 1 Hamza Alobeidli 2 Baptiste Pannier 2 1 3\n\nEbtesam Almazrouei Julien Launay https://huggingface.co/datasets/tiiuae/falcon-refinedweb\n\n## Abstract\n\nLarge language models are commonly trained on a mixture of filtered web data and curated 'high-quality' corpora, such as social media conversations, books, or technical papers. This curation process is believed to be necessary to produce performant models with broad zero-shot generalization abilities. However, as larger models requiring pretraining on trillions of tokens are considered, it is unclear how scalable is curation and whether we will run out of unique high-quality data soon. At variance with previous beliefs, we show that properly filtered and deduplicated web data alone can lead to powerful models; even significantly outperforming models from the state-of-the-art trained on The Pile. Despite extensive filtering, the high-quality data we extract from the web is still plentiful, and we are able to obtain five trillion tokens from CommonCrawl. We publicly release an extract of 600 billion tokens from our REFINEDWEB dataset, and 1.3/7.5B parameters language models trained on it * .\n\nFigure 1. Models trained on REFINEDWEB alone outperform models trained on curated corpora. Zero-shot performance on our main-agg task aggregate (see Section 4.1 for details). At equivalent compute budgets, our models significantly outperform publicly available models trained on ▼ The Pile, and match the performance of the ■ GPT-3 models when tested within our evaluation setup.\n\n<!-- image -->\n\n1 LightOn 2 Technology Innovation Institute, 9639 Masdar City, Abu Dhabi, United Arab Emirates 3 LPENS, ´ Ecole normale sup´ erieure. Contact: &lt; falconllm@tii.ae &gt; .\n\n* Details about how to access Falcon LLM open source is available on falconllm.tii.ae\n\n1\n\nTable 1. REFINEDWEB improves on existing English pretraining datasets for large language models by combining extensive filtering with stringent deduplication at unprecedented scale. For additional details, see the full version in Table 12 of Appendix F.3.\n\n| Dataset                    | Size                       | Availability         | Web                  | CC Processing                                                                                             | Deduplication                                                                                                                 |\n|----------------------------|----------------------------|----------------------|----------------------|-----------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------|\n| MASSIVE WEB DATASETS       | MASSIVE WEB DATASETS       | MASSIVE WEB DATASETS | MASSIVE WEB DATASETS | MASSIVE WEB DATASETS                                                                                      | MASSIVE WEB DATASETS                                                                                                          |\n| C4 OSCAR-21.09 OSCAR-22.01 | ∼ 360 GT ∼ 370 GT ∼ 283 GT | Public Public Public | 100 % 100 % 100 %    | Rules + NSFW words blocklist Built at the line-level Line-level rules + optional rules &NSFWURL blocklist | Exact: spans of 3 sentences Exact : per line ( ∼ 55% removed) Exact : per line (optional, not used for results in this paper) |\n| CURATED DATASETS           | CURATED DATASETS           | CURATED DATASETS     | CURATED DATASETS     | CURATED DATASETS                                                                                          | CURATED DATASETS                                                                                                              |\n| ■ GPT-3                    | 300 GT                     | Private              | 60 %                 | Content filter trained on known high-quality sources                                                      | Fuzzy : MinHash ( ∼ 10% removed)                                                                                              |\n| ▼ The Pile                 | ∼ 340 GT                   | Public               | 18 %                 | jusText for extraction, con- tent filter trained on curated data                                          | Fuzzy : MinHash ( ∼ 26% removed)                                                                                              |\n| ⋆ PaLM                     | 780 GT                     | Private              | 27 %                 | Filter trained on HQ data                                                                                 | Unknown                                                                                                                       |\n| OURS                       | OURS                       | OURS                 | OURS                 | OURS                                                                                                      | OURS                                                                                                                          |\n| REFINEDWEB                 | ∼ 5 , 000 GT               | Public (600GT)       | 100%                 | trafilatura for text extrac- tion, document and line-level rules, NSFW URL blocklist                      | Exact & fuzzy : exact sub- string+MinHash ( ∼ 50% removed)                                                                    |\n\n## 1. Introduction\n\nProgress in natural language processing is increasingly driven by sheer compute scale alone (Sevilla et al., 2022): as more compute is expended to train large language models (LLM), they gain and exhibit powerful emergent capabilities (Brown et al., 2020; Wei et al., 2022). To best benefit from scaling, recent scaling laws dictate that both model size and dataset size should jointly be increased (Hoffmann et al., 2022). This is at variance with earlier findings, which had argued that scaling should focus on model size first and foremost, with minimal data scaling (Kaplan et al., 2020).\n\nThis joint scaling paradigm raises significant challenges: although plentiful, text data is not infinite, especially so when considerations on data quality and licensing are taken into account-leading some researchers to argue scaling may soon be bottlenecked by data availability (Villalobos et al., 2022). Concretely, optimally training a GPT-3 sized model (175B parameters) would require no less than 3,500 billion tokens of text according to Hoffmann et al. (2022). This is twice as much as the largest pretraining datasets ever demonstrated (Hoffmann et al., 2022; Touvron et al., 2023), and ten times more than the largest publicly available English datasets such as OSCAR (Ortiz Su´ arez et al., 2019), C4 (Raffel et al., 2020), or The Pile (Gao et al., 2020).\n\nMassively scaling-up pretraining data is made even more challenging by the fact LLMs are commonly trained using a mixture of web crawls and so-called 'high-quality' data (Brown et al., 2020; Gao et al., 2020). Typical highquality corpora include curated sources of books, technical documents, human-selected web pages, or social media conversations. The increased diversity and quality brought forth by these curated corpora is believed to be a key component of performant models (Scao et al., 2022b). Unfortunately, curation is labour intensive: typically, each source requires specialized processing, while yielding a limited amount of data. Furthermore, licensed sources raise legal challenges.\n\nNevertheless, most pretraining data is still sourced from massive web crawls which can be scaled up to trillions of tokens with limited human intervention. However, the quality of this data has traditionally been seen as (much) inferior to that of the manually curated data sources. Even finely processed sources of web data, such as C4 (Raffel et al., 2020) or OSCAR (Ortiz Su´ arez et al., 2019), are regarded as inferior to curated corpora for LLMs (Rae et al., 2021; Scao et al., 2022b), producing less performant models.\n\nTo sustain the ever-increasing data needs of larger and larger LLMs, and to streamline data pipelines and reduce the need for human-intensive curation, we propose to explore how web data can be better processed to significantly improve its quality, resulting in models as capable, if not more capable, than models trained on curated corpora.\n\nContributions. We make the following contributions:\n\n- We introduce REFINEDWEB , a high-quality five trillion tokens web-only English pretraining dataset;\n- We demonstrate that web data alone can result in models outperforming both public and private curated corpora , as captured by zero-shot benchmarks, challenging current views about data quality;\n- We publicly release a 600B tokens extract of RefinedWeb, and 1/7B parameters LLMs trained on it , to serve as a new baseline high-quality web dataset for the natural language processing community.\n\n## 2. Related works\n\nPretraining data for large language models. Early large language models identified the importance of datasets with long, coherent documents (Radford et al., 2018; Devlin et al., 2019). Moving on from the previously used sentencewise datasets (Chelba et al., 2013), they instead leveraged document-focused, single-domain corpora like Wikipedia or BookCorpus (Zhu et al., 2015). As models increased in scale, datasets based on massive web-scrape gained prevalence (Ortiz Su´ arez et al., 2019; Raffel et al., 2020). However, further work argued that these untargeted web scrape fell short of human-curated data (Radford et al., 2019), leading to the wide adoption of curated datasets such as The Pile (Gao et al., 2020), which combine web data with books, technical articles, and social media conversations. At scale, it has been proposed to emulate the human curation process by leveraging weak signals: for instance, by crawling the top links of a forum (Gokaslan et al., 2019). Targeted corpora can also produce domain-specific models (Beltagy et al., 2019), or broaden the expressiveness of models (e.g., for conversational modalities Adiwardana et al. (2020); Thoppilan et al. (2022)). Latest large language models (Brown et al., 2020; Rae et al., 2021; Chowdhery et al., 2022; Scao et al., 2022a) are trained on giant aggregated corpora, combining both massive web-scrape and so-called 'high-quality' curated single-domain sources (e.g., news, books, technical papers, social media conversations). These targeted sources are often upsampled-from one to five times is most common-to increase their representation in the final dataset. The diversity and 'higher-quality' brought fourth by these aggregated datasets is thought to be central to model quality; web data alone is considered insufficient to train powerful large language models (Liu et al., 2019; Scao et al., 2022b).\n\nPipelines for web data. Massive web datasets are typically built upon CommonCrawl, a publicly available scrape of the internet, which has now been running for 12 years and has collected petabytes of data. Working with data scraped from all over the internet presents unique challenges: notably, a significant portion is low-quality machine-generated spam or pornographic content (Trinh &amp; Le, 2018; Kreutzer et al., 2022). Accordingly, training on unfiltered web data is undesirable, resulting in poorly performing models (Raffel et al., 2020). Modern pipelines focus on filtering out this undesirable content (Wenzek et al., 2020). Broadly speaking, these pipelines usually combine a variety of stages: (1) language identification , leveraging inexpensive n-gram models (e.g., fastText Joulin et al. (2016)); (2) filtering rules and heuristics , such as only keeping lines with valid punctuation, discarding lines with too many symbols, or removing documents containing banned words (Grave et al., 2018; Raffel et al., 2020); (3) ML-based quality filtering , using lightweight models trained on known gold data to identify similar high-quality web documents (Wenzek et al., 2020; Brown et al., 2020); (4) deduplication , removing either exact duplicate spans or similar documents (Lee et al., 2022). While some filtering is necessary, excessive filtering can introduce undesirable biases in the model. This can overly impact minorities (Dodge et al., 2021), motivating the adoption of practices such as pseudo-crawling, wherein allowed URLs are manually curated (Laurenc ¸on et al., 2022).\n\nDeduplication. Deduplication removes repeated extracts and documents from a dataset: these could either be exact matches, identical in every character, or approximate matches, based on some similarity metric. For exact duplicates, it is common to match exact substrings of a minimum length using suffix arrays (Manber &amp; Myers, 1993). For fuzzy duplicates, methods based on locally-sensitive hashes such as MinHash (Broder, 1997) or SimHash (Charikar, 2002) have been adopted for the pretraining data of large language models (Brown et al., 2020; Zeng et al., 2021; Rae et al., 2021). Recently, Abbas et al. (2023) has proposed to leverage embeddings from pretrained models to imbue semantic understanding in approximate matching algorithms. Deduplication has been identified as playing a significant role in improving language models (Allamanis, 2019; Lee et al., 2022). Notably, it reduces memorization (Carlini et al., 2022), which is especially problematic in large models (Carlini et al., 2021). Furthermore, repeated data has been shown to be increasingly harmful to model quality as parameter count increases (Hernandez et al., 2022): for a 1B parameters model, a hundred duplicates are harmful; at 175B, even a few duplicates could have a disproportionate effect. Concurrently to this work, the Pythia suite of models found that deduplicating The Pile had a limited impact on zero-shot performance (Biderman et al., 2023), questioning whether deduplication is as relevant for curated corpora as it for predominantly web-based datasets.\n\nWe provide an overview of some widely adopted existing pretraining English datasets for LLMs in Table 1, with additional information in Table 12 of Appendix F.3. We also note that recent popular open models (Zhang et al., 2022; Touvron et al., 2023) often indirectly leverage The Pile (Gao et al., 2020) by doing a mix-and-match of its components.\n\nFocusing on building a large-scale high-quality web pretraining dataset, we extend upon the state-of-the-art in three ways: (1) we aggregate and combine best-practices for document preparation and filtering across multiple pipelines, and introduce line-wise corrections; (2) we combine both exact and fuzzy deduplication at very large-scale; (3) the scale of our final dataset is unique, with a total 5,000 billion tokens, and a 600 billion tokens extract available for public use with permissive licensing. Training large models on RefinedWeb also lead us to challenge the commonly held belief that web data is strictly worse than curated corpora.\n\n## 3. Macrodata Refinement and RefinedWeb\n\nWe introduce MDR (MacroData Refinement), a pipeline for filtering and deduplicating web data from CommonCrawl at very large scale. Using MDR, we produce REFINEDWEB , an English pretraining dataset of five trillion tokens based on web data only. We leverage strict filtering and stringent deduplication to uplift the quality of web data, distilling it down to a corpus matching the quality of aggregated corpora used to train state-of-the-art models.\n\nDesign principles. We abide by the following guidelines:\n\n- Scale first. We intend MDR to produce datasets to be used to train 40-200B parameters models, thus requiring trillions of tokens (Hoffmann et al., 2022). For English-only RefinedWeb, we target a size of 3-6 trillion tokens. Specifically, we eschew any labour intensive human curation process, and focus on CommonCrawl instead of disparate single-domain sources.\n- Strict deduplication. Inspired by the work of Lee et al. (2022), which demonstrated the value of deduplication for large language models, we implement a rigorous deduplication pipeline. We combine both exact and fuzzy deduplication, and use strict settings leading to removal rates far higher than others have reported.\n- Neutral filtering. To avoid introducing further undesirable biases into the model (Dodge et al., 2021; Welbl et al., 2021), we avoid using ML-based filtering outside of language identification. We stick to simple rules and heuristics, and use only URL filtering for adult content.\n\nTable 2 and Figure 2 outline the full MDR pipeline.\n\n## 3.1. Document preparation: reading data, filtering URLs, extracting text, and language identification\n\nReading the data. CommonCrawl is available in either WARC (raw HTML response), or WET files (preprocessed to only include plain text). Individual files correspond to a page at a given URL; these constitute single documents/samples. Working with WET files would spare us from running our own HTML extraction; however, in line with previous works (Gao et al., 2020; Rae et al., 2021), we found WET files to include undesirable navigation menus, ads, and other irrelevant texts. Accordingly, our pipeline starts from raw WARC files, read with the warcio library.\n\nURL filtering. Before undertaking any compute-heavy processing, we perform a first filtering based on the URL alone. This targets fraudulent and/or adult websites (e.g., predominantly pornographic, violent, related to gambling, etc.). We base our filtering on two rules: (1) an aggregated blocklist of 4.6M domains; (2) a URL score, based on the presence of words from a list we curated and weighed by severity. We found that commonly used blocklists include many false positives, such as popular blogging platforms or even pop culture websites. Furthermore, word-based rules (like the one used in C4, Raffel et al. (2020)) can easily result in medical and legal pages being blocked. Our final detailed rules based on this investigation are shared in Appendix G.1. Since we intend RefinedWeb to be used as part of an aggregate dataset along with curated corpora, we also filtered common sources of high-quality data: Wikipedia, arXiv, etc. The detailed list is available in Appendix G.1.3.\n\nLoading [MathJax]/e t nsions/MathMenu.js Figure 2. Subsequent stages of Macrodata Refinement remove nearly 90% of the documents originally in CommonCrawl. Notably, filtering and deduplication each result in a halving of the data available: around 50% of documents are discarded for not being English, 24% of remaining for being of insufficient quality, and 12% for being duplicates. We report removal rate (grey) with respect to each previous stage, and kept rate (shade) overall. Rates measured in % of documents in the document preparation phase, then in tokens.\n\n<!-- image -->\n\nTable 2. Macrodata Refinement aggregates best practices from the state-of-the-art and novel approaches (URL scoring, line-wise filtering, etc.) to produce high-quality web data. On deduplication, we note that MDR is unique in both the scale at which it is performed, and in applying subsequently fuzzy and exact substring methods to improve coverage and scalability.\n\n| DOCUMENT PREPARATION                                                        | DOCUMENT PREPARATION                                                 | FILTERING                                                                                 | FILTERING                                                                                 | FILTERING                                                                                          | DEDUPLICATION                                                                                       | DEDUPLICATION                                                  |\n|-----------------------------------------------------------------------------|----------------------------------------------------------------------|-------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------|----------------------------------------------------------------|\n| URL filtering                                                               | Text extraction                                                      | Language identification                                                                   | Document-wise filtering                                                                   | Line-wise filtering                                                                                | Deduplication                                                                                       | URL deduplication                                              |\n| Aggregated block- list, URL scoring, common HQ sources blocked Appendix G.1 | From WARC using warcio , trafilatura for extraction Barbaresi (2021) | fastText classi- fier from CCNet, thresholding on top language score Wenzek et al. (2020) | In-document repe- tition removal and quality heuristics from MassiveWeb Rae et al. (2021) | Remove undesirable lines (call to actions, navigation buttons, social counters, etc.) Appendix G.2 | Fuzzy deduplication w/ MinHash + exact substring deduplica- tion w/ suffix arrays Lee et al. (2022) | Remove URLs revis- ited across Common- Crawl dumps Section 3.3 |\n\nText extraction. We want to extract only the main content of the page, ignoring menus, headers, footers, and ads among others: Lopukhin (2019) found that trafilatura (Barbaresi, 2021) was the best non-commercial library for retrieving content from blog posts and news articles. Although this is only a narrow subset of the kind of pages making up CommonCrawl, we found this finding to hold more broadly. We use trafilatura for text extraction, and apply extra formatting via regular expressions: we limit new lines to two consecutive ones, and remove all URLs.\n\nLanguage identification. We use the fastText language classifier of CCNet (Wenzek et al., 2020) at the documentlevel: it uses characters n-gram and was trained on Wikipedia, supporting 176 languages. We remove documents for which the top language scores below 0.65: this usually corresponds to pages without any natural text. For this paper, we focus on English; RefinedWeb can also be derived for other languages, see Appendix D for details.\n\nThe data we retrieve at this stage, called RW-RAW , corresponds to what we can extract with the minimal amount of filtering. At this stage, only 48% of the original documents are left, mostly filtered out by language identification.\n\n## 3.2. Filtering: document-wise and line-wise\n\nRepetition removal. Due to crawling errors and lowquality sources, many documents contain repeated sequences: this may cause pathological behavior in the final model (Holtzman et al., 2019). We could catch this content at the later deduplication stage, but it is cheaper and easier to catch it document-wise early on. We implement the heuristics of Rae et al. (2021), and remove any document with excessive line, paragraph, or n-gram repetitions.\n\nDocument-wise filtering. A significant fraction of pages are machine-generated spam, made predominantly of lists of keywords, boilerplate text, or sequences of special characters. Such documents are not suitable for language modeling; to filter them out, we adopt the quality filtering heuristics of Rae et al. (2021). These focus on removing outliers in terms of overall length, symbol-to-word ratio, and other criteria ensuring the document is actual natural language. We note that these filters have to be adapted on a per language basis, as they may result in overfiltering if naively transferred from English to other languages.\n\nLine-wise corrections. Despite the improvements brought forth by using trafilatura instead of relying on preprocessed files, many documents remain interlaced with undesirable lines (e.g., social media counters 3 likes , navigation buttons). Accordingly, we devised a line-correction filter, targeting these undesirable items. If these corrections remove more than 5% of a document, we remove it entirely. See Appendix G.2 for details.\n\nThe data we retrieve at this stage has gone through all of the filtering heuristics in the MDR pipeline. We refer to this dataset as RW-FILTERED . Only 23% of the documents of CommonCrawl are left, with around 50% of the documents of RW-Raw removed by the filtering.\n\n## 3.3. Deduplication: fuzzy, exact, and across dumps\n\nAfter filtering, although data quality has improved, a large fraction of the content is repeated across documents. This may be due to the crawler indirectly hitting the same page multiple times, to boilerplate content being repeated (e.g., licences), or even to plagiarism. These duplicates can strongly impact models, favoring memorization instead of generalization (Lee et al., 2022; Hernandez et al., 2022). Since deduplication is expensive, it has seen limited adoption in public datasets (Ortiz Su´ arez et al., 2019; Raffel et al., 2020). We adopt an aggressive deduplication strategy, combining both fuzzy document matches and exact sequences removal.\n\nFuzzy deduplication. We remove similar documents by applying MinHash (Broder, 1997): for each document, we compute a sketch and measure its approximate similarity with other documents, eventually removing pairs with high overlap. MinHash excels at finding templated documents: licenses with only specific entities differing, placeholder SEO text repeated across websites-see examples of the\n\nTable 3. To evaluate models trained on RefinedWeb and compare to the state-of-the-art, we build four aggregates across 18 tasks on which to measure zero-shot performance. small was built for internal ablations, based on tasks with consistent performance at small scale, core is based on tasks commonly reported for public suites of models (Dey et al., 2023; Biderman et al., 2023), main is based on tasks from the GPT-3 and PaLM paper (Brown et al., 2020; Chowdhery et al., 2022), and ext is based on tasks used by the BigScience Architecture and Scaling group (Scao et al., 2022b). For all results reported, we flag with † results obtained in an arbitrary evaluation setup, and with ∗ results obtained with the EAI Harness (Gao et al., 2021), which we also employ for all our models.\n\n| Tasks                                       | Type                               |   Random | small   | core   | main   | ext   |\n|---------------------------------------------|------------------------------------|----------|---------|--------|--------|-------|\n| HellaSwag (Zellers et al., 2019)            | Sentence completion                |     25   | ✓       | ✓      | ✓      | ✓     |\n| LAMBADA (Paperno et al., 2016)              | Sentence completion                |      0   |         | ✓      | ✓      | ✓     |\n| Winogrande (Sakaguchi et al., 2021)         | Coreference resolution             |     50   | ✓       | ✓      | ✓      | ✓     |\n| PIQA (Bisk et al., 2020)                    | Multiple-choice question answering |     50   | ✓       | ✓      | ✓      | ✓     |\n| ARC (Clark et al., 2018)                    | Natural language inference         |     25   | ✓       | ✓      | ✓      | ✓     |\n| OpenBookQA (Mihaylov et al., 2018)          | Multiple-choice question answering |     25   |         | ✓      | ✓      | ✓     |\n| BoolQ (Clark et al., 2019)                  | Multiple-choice question answering |     50   | ✓       |        | ✓      | ✓     |\n| COPA (Gordon et al., 2012)                  | Sentence completion                |     50   |         |        | ✓      | ✓     |\n| CB (De Marneffe et al., 2019)               | Natural language inference         |     33.3 |         |        | ✓      | ✓     |\n| RTE (Dagan et al., 2010)                    | Natural language inference         |     50   |         |        | ✓      | ✓     |\n| ReCoRD (Zhang et al., 2018)                 | Question answering                 |      0   |         |        | ✓      |       |\n| ANLI (Nie et al., 2019)                     | Natural language inference         |     33.3 |         |        | ✓      |       |\n| LogiQA (Liu et al., 2021)                   | Multiple-choice question answering |     25   |         |        |        | ✓     |\n| HeadQA (Vilares &G´ omez-Rodr´ ıguez, 2019) | Multiple-choice question answering |     20   |         |        |        | ✓     |\n| MathQA (Amini et al., 2019)                 | Multiple-choice question answering |     20   |         |        |        | ✓     |\n| PROST (Aroca-Ouellette et al., 2021)        | Paraphrase identification          |     50   |         |        |        | ✓     |\n| PubMedQA (Jin et al., 2019)                 | Multiple-choice question answering |     50   |         |        |        | ✓     |\n| SciQ (Welbl et al., 2017)                   | Multiple-choice question answering |     25   | ✓       |        |        | ✓     |\n\nbiggest clusters in Appendix H.1. We perform MinHash deduplication using 9,000 hashes per document, calculated over 5-grams and divided into 20 buckets of 450 hashes. We found that using less aggressive settings, such as the 10 hashes of The Pile (Gao et al., 2020), resulted in lower deduplication rates and worsened model performance. See Appendix G.3.1 for more details about our MinHash setup.\n\nExact deduplication. Exact substring operates at the sequence-level instead of the document-level, finding matches between strings that are exact token-by-token matches by using a suffix array (Manber &amp; Myers, 1993) (e.g., specific disclaimers or notices, which may not compromise the entire document as showcased in Appendix H.2). We remove any match of more than 50 consecutive tokens, using the implementation of Lee et al. (2022). We note that exact substring alters documents, by removing specific spans: we also experimented with dropping entire documents or loss-masking the duplicated strings instead of cutting them, but this didn't result in significant changes in zero-shot performance-see Appendix G.3.2.\n\nURL deduplication. Because of computational constraints, it is impossible for us to perform deduplication directly on RW-Filtered. Instead, we split CommonCrawl into 100 parts, where each part contains a hundredth of each dump, and perform deduplication on individual parts. Most of the larger duplicate clusters (e.g., licences, common spams) will be shared across parts, and effectively removed. However, we found that CommonCrawl dumps had significant overlap, with URLs being revisited across dumps despite no change in content. Accordingly, we keep a list of the URLs of all samples we have kept from each part, and remove them from subsequent parts being processed.\n\n## 4. Experiments\n\nWe now validate that RefinedWeb can be used to train powerful models, matching the zero-shot performance obtained with curated corpora and state-of-the-art language models. We first discuss our evaluation and pretraining setup, and models with which we compare. We perform experiments at small scale to internally compare with other popular datasets, and ablate the three main stages of RefinedWeb (raw, filtered, final). Then, we scale to 1B and 7B models trained on 350GT to compare with state-of-the-art models. Finally, we apply the MDR pipeline to existing pretraining datasets, and show that it can potentially deliver further improvements.\n\n## 4.1. Setting\n\nEvaluation. At variance with previous works studying pretraining datasets (Rae et al., 2021; Lee et al., 2022), we focus our evaluation on zero-shot generalization across many tasks rather than measuring validation loss. Perplexity alone can be at odds with end-task performance (Tay et al., 2021), and modern works on LLMs predominantly report zero-shot performance (Brown et al., 2020; Rae et al., 2021; Chowdhery et al., 2022). Furthermore, zero-shot generalization is the 'natural' setting for autoregressive decoder-only models, in which they perform best (Wang et al., 2022). Our evaluation setup is inspired by the one used by the architecture and scaling group of Big Science (Scao et al., 2022b).\n\nWe base our evaluation on the popular Eleuther AI evaluation harness (Gao et al., 2021), allowing us to evaluate across a wide range of tasks in the zero-shot setting. We identified aggregates of tasks allowing us to: (1) obtain signal (i.e., non zero zero-shot performance) at small scale for\n\nTable 4. Curation is not a silver bullet for zero-shot generalization: small-scale models trained on REFINEDWEB outperform models trained on web data (C4, OSCAR), and on curated corpora ( ▼ The Pile). Average accuracy in zero-shot on the small-agg aggregate. All models trained with identical architectures and pretraining hyperparameters. We find that OSCAR-22.01 underperforms other datasets signficantly, perhaps because deduplication is only optional. C4 is a strong baseline, with OSCAR-21.09 lagging slightly behind, but we find that RefinedWeb outperforms both web datasets and the most popular curated dataset, The Pile. Both filtering and deduplication contribute significantly to improving zero-shot performance.\n\n| MASSIVE WEB DATASETS   | MASSIVE WEB DATASETS   | MASSIVE WEB DATASETS   |       | CURATED    | OURS   |             |            |\n|------------------------|------------------------|------------------------|-------|------------|--------|-------------|------------|\n|                        | OSCAR-21.09            | OSCAR-22.01            | C4    | ▼ The Pile | RW-Raw | RW-Filtered | REFINEDWEB |\n| 1B@27GT                | 55.0%                  | 52.7%                  | 55.7% | 53.4%      | 52.7%  | 54.3%       | 56.2%      |\n| 3B@60GT                | 59.1%                  | 55.9%                  | 59.6% | 57.9%      | 57.4%  | 58.2%       | 59.8%      |\n\nablations; (2) compare with results reported by other models. We outline these four aggregates small (for ablations), and core , main , ext (for comparisons) in Table 3.\n\nComparisons across models trained and evaluated in different settings are difficult to untangle, as many externalities may influence the 1 987results (e.g., numerical precision of training vs inference, prompts used). We distinguish three levels of comparisons: (1) internal comparisons, with models trained and evaluated within our codebase, for which only the pretraining datasets differ; (2) benchmark-level comparisons, with models trained with a different codebase but evaluated with the Eleuther AI harness, taking results from Scao et al. (2022b); Black et al. (2022); Aleph Alpha (2023); Dey et al. (2023), thereafter flagged with a ∗ ; (3) external comparisons with Brown et al. (2020); Chowdhery et al. (2022), thereafter flagged with a † . For further details on evaluation, see Appendix F.1.\n\nModels. We train 1B, 3B, and 7B parameters autoregressive decoder-only models, based on configurations and hyperparameters similar to GPT-3 (Brown et al., 2020), diverging mostly on our use of ALiBi (Press et al., 2021). We use FlashAttention (Dao et al., 2022) in a custom codebase. We train internal models on both The Pile and RefinedWeb to control for deviations caused by our pretraining setup-we found The Pile models to perform in-line with others. For small-scale and ablation studies (first half of Section 4.2; Section 4.3), we train models to optimality according to the scaling laws of Hoffmann et al. (2022): on 27B and 60B tokens respectively for our 1B and 3B parameters models. For the main experiments demonstrating our approach (FalconRWmodels in Section 4.2), we train the models to 350GT, in line with popular public models (Brown et al., 2020; Wang &amp;Komatsuzaki, 2021; Scao et al., 2022a). Note that we do not compare against the recently introduced LLaMA models (Touvron et al., 2023), as the smallest of them is trained on x2.5 more compute than our largest model, preventing a meaningful comparison from being made dataset-wise. For a more in-depth overview of the models and pretraining datasets with which we compare, see Appendix F.\n\n## 4.2. Can web data alone outperform curated corpora?\n\nWe endeavour to demonstrate that web data alone can result in models outperforming other models trained on curated corpora. To do so, we first perform a small-scale study with 1B and 3B parameters models trained to optimality (27GT and 60GT) on popular web and curated datasets. Then, we scale up to 1B and 7B models trained on 350GT, and compare zero-shot generalization to state-of-the-art models.\n\nSmall-scale study. We first consider popular public web datasets (OSCAR-2019 (Ortiz Su´ arez et al., 2019), OSCAR2022 (Abadji et al., 2021), C4 (Raffel et al., 2020)), The Pile (Gao et al., 2020) as the most popular publicly available curated dataset, and variations of RefinedWeb (RW-Raw, RW-Filtered, and RW as described in Section 3). For this first study, all models are trained with the same architecture and the same internal codebase; they are also all evaluated within the same framework-only pretraining datasets differ.\n\nResults averaged on the small-=+ aggregate of 6 tasks are presented in Table 4. We observe relatively strong performance of all web datasets compared to The Pile, showcasing that curation is not a silver bullet for performant language models. We find C4 to be a strong pretraining dataset, in line with the findings of Scao et al. (2022b)-however, The Pile comparatively underperforms more in our benchmarks. The relatively disappointing results on OSCAR-22.01 may be due to the main version of the dataset being distributed without deduplication. Regarding RefinedWeb, both filtering and deduplication significantly improve performance.\n\nFull-scale models. We now validate these results with comparisons with state-of-the-art models. We scale our previous experiments by training 1B and 7B models on 350GT; we also train a 1B model on 350GT on The Pile, as a control for the influence of our pretraining setup. We compare with the following models: the GPT-3 series (Brown et al., 2020), the FairSeq series (Artetxe et al., 2021), the GPT-Neo(X)/J models (Black et al., 2021; Wang &amp; Komatsuzaki, 2021; Black et al., 2022), the OPT series (Zhang et al., 2022),\n\nthe BigScience Architecture and Scaling Pile model (Scao et al., 2022b), PaLM-8B (Chowdhery et al., 2022), Aleph Alpha Luminous 13B (Aleph Alpha, 2023), the Pythia series (Biderman et al., 2023), and the Cerebras-GPT series (Dey et al., 2023). For GPT-3, we distinguish between results obtained through the API ( babbage and curie ) with the the EleutherAI LM evaluation harness (Gao et al., 2021) (*), and results reported in their paper, with a different evaluation setup ( † ). Note that for PaLM and OPT, results were also obtained with a different evaluation suite ( † ), while for other models they were obtained with the evaluation harness as well (*), allowing for more direct comparisons.\n\nResults on main-agg are presented in Figure 1, and in Figure 3 for core-agg and ext-agg . We find that open models consistently underperform models trained on private curated corpora, such as GPT-3-even when using a similar evaluation setup. Conversely, models trained on RefinedWeb are able to match the performance of the GPT-3 series using web data alone, even though common high-quality sources used in The Pile are excluded from RefinedWeb (see Table 14 in Appendix). Finally, we note that our internal model trained on The Pile performs in line with the BigScience Architecture and Scaling model; this highlights that our pretraining setup is unlikely to be the main source of increased performance for models trained on RefinedWeb.\n\nFinding. Challenging existing beliefs on data quality and LLMs, models trained on adequately filtered and deduplicated web data alone can match the performance of models trained on curated data.\n\n## 4.3. Do other corpora benefit from MDR?\n\nAblating the contributions and evaluating the performance of individual components in the MDR pipeline is difficult: for most heuristics, there is no agreed-upon ground truth, and changes may be too insignificant to result in sufficient zero-shot signal after pretraining. In the first half of Section 4.2, we identified that subsequent stages of RefinedWeb (raw, filtered, final) led to improvements in performance. In this section, we propose to apply independently the filtering and deduplication stages of MDR to popular pretraining datasets, studying whether they generalize widely.\n\nWe report results on the small-agg in Table 5. First, we find that improvements from filtering are not systematic. On The Pile, we had to adjust our line length and characters ratio heuristics to avoid expunging books and code. Despite improvements on OSCAR-21.09, C4, and The Pile, our filters worsen performance on OSCAR-22.01; generally, removal rates from filtering do not seem strongly correlated with downstream accuracy. Conversely, deduplication delivers a steady boost across all datasets, and removal rates are better correlated with changes in performance. We find OSCAR21.09 and C4 to be already well deduplicated, while The Pile and OSCAR-22.01 exhibit 40-60% duplicates. The base version of OSCAR-22.01 is distributed without deduplication; for The Pile, this is consistent with the findings of Zhang et al. (2022). Finally, combining filtering and deduplication results in further improvements; interestingly, although performance is now more uniform across datasets, differences remain, suggesting that flaws in the original text extraction and processing can't be fully compensated for.\n\n55\n\nFigure 3. Models trained on REFINEDWEB alone outperform models trained on curated corpora. Zero-shot performance averaged on our core-agg (left) and ext-agg (right) task aggregates (see Section 4.1 for details, and Figure 1 for results on main-agg ). Existing open models fail to match the performance of the original GPT-3 series (left); however, models trained on RefinedWeb significantly outperform models trained on ▼ The Pile: including our direct comparison model (right), ruling out our pretraining setup as the main source of increased performance. In fact, our RefinedWeb models even match the performance of the ■ GPT-3 models.\n\n<!-- image -->\n\nTable 5. Although improvements from filtering are not systematic across datasets, deduplication brings a steady performance boost across the board. Zero-shot accuracy averaged on our small-agg aggregate; [+x.x] reports absolute gains compared to base, removal rates reported against base. Due to limitations in our pipeline, we cannot apply the deduplication stage independently for RefinedWeb.\n\n|              | MASSIVE WEB DATASETS   | MASSIVE WEB DATASETS   |             | CURATED      | OURS         |\n|--------------|------------------------|------------------------|-------------|--------------|--------------|\n|              | OSCAR-21.09            | OSCAR-22.01            | C4          | ▼ Pile       | RefinedWeb   |\n| Base         | 55.0%                  | 52.7%                  | 55.7%       | 53.4%        | 52.7%        |\n| Filtered     | 55.4% [+.4]            | 52.3% [-.4]            | 56.2% [+.5] | 54.2% [+.8]  | 54.3% [+1.6] |\n| removal rate | -25.0%                 | -39.8%                 | -16.4%      | -27.1%       | -50.8%       |\n| Deduplicated | 55.6% [+.6]            | 55.6% [+2.9]           | 55.9% [+.2] | 54.5% [+1.1] |              |\n| removal rate | -10.8%                 | -60.8%                 | -7.59%      | -45.3%       |              |\n| Filt.+Dedup. | 55.5% [+.5]            | 55.4% [+2.7]           | 56.4% [+.7] | 55.2% [+1.8] | 56.2% [+3.5] |\n| removal rate | -28.2%                 | -62.2%                 | -17.9%      | -66.0%       | -75.4%       |\n\nBy processing C4 through MDR, we are able to obtain subsets of data which might slightly outperform RefinedWeb; this combines both the stringent filtering of C4 (e.g., strict NSFW word blocklist, 3-sentence span deduplication) with our own filters and deduplication. While such a combination results in rejection rates that would be unacceptable for our target of 3-6 trillions tokens, this represents an interesting perspective for shorter runs, which may be able to extract extremely high-quality subsets from large web datasets.\n\nFinding. While filtering heuristics may require sourcedependent tuning, stringent deduplication improves zero-shot performance across datasets consistently.\n\n## 5. Limitations\n\nBiases. We conduct a basic analysis of the toxicity of RefinedWeb in Figure 4. We find RW to be about as toxic as The Pile, based on the definition of toxicity provided by the Perspective API: 'content that is rude or disrespectful'. Notably, this definition does not cover issues with social biases or harmfulness. Although it is unlikely that our pipeline introduces further issues on this side than is already documented for popular datasets, we encourage further quantitative work on the public extract of RefinedWeb.\n\nMultiple epochs. Instead of looking for 'unique' tokens to make up a trillion-scale pretraining dataset, one could simply repeat data over multiple epochs. Popular models like OPT and NeoX-20B do this for up to 2 epochs, and most curated datasets upsample corpora 2-5 times. However, Hernandez et al. (2022) has recently shown that models with 100B+ parameters may be sensitive to even just a few epochs. Orthogonal to our work lies a line of research exploring tradeoffs in the data-constrained regime: can deduplication help sustain more epochs? Are multiple epochs on higher quality data better than a one epoch on lower quality data? See Appendix E.3 for a more in-depth discussion.\n\nOther results on deduplication. Biderman et al. (2023) found a limited impact on zero-shot performance from deduplicating The Pile; we discuss further in Appendix F.2, but encourage further deduplication research on curated corpora, and studying deduplication in the data-constrained regime, where multiple epochs have to be performed to compensate for the reduction in tokens incurred by deduplication.\n\n## 6. Conclusion\n\nAs LLMs are widely adopted, models trained past the recommendations of scaling laws are bound to become increasingly common to amortize inference costs (Touvron et al., 2023). This will further drive the need for pretraining datasets with trillions of tokens, an order of magnitude beyond publicly available corpora. We have demonstrated that stringent filtering and deduplication could result in a five trillion tokens web only dataset suitable to produce models competitive with the state-of-the-art, even outperforming LLMs trained on curated corpora. We publicly release a 600GT extract of RefinedWeb, and note that RefinedWeb has already been used to train state-of-the-art language models, such as Falcon-40B (Almazrouei et al., 2023).\n\nFigure 4. Toxic content in RefinedWeb is distributed similarly to The Pile. Cumulative proportion of documents below a given toxicity score, as evaluated by the Pespective API.\n\n<!-- image -->\n\n## References\n\n- Abadji, J., Su´ arez, P. J. O., Romary, L., and Sagot, B. Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus. Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event), pp. 1 - 9, Mannheim, 2021. Leibniz-Institut f¨ ur Deutsche Sprache. doi: 10.14618/ ids-pub-10468. URL https://nbn-resolving. org/urn:nbn:de:bsz:mh39-104688 .\n- Abadji, J., Ortiz Suarez, P., Romary, L., and Sagot, B. Towards a Cleaner Document-Oriented Multilingual Crawled Corpus. arXiv e-prints , art. arXiv:2201.06642, January 2022.\n- Abbas, A. K. M., Tirumala, K., Simig, D., Ganguli, S., and Morcos, A. S. Semdedup: Data-efficient learning at web-scale through semantic deduplication. In ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models , 2023.\n- Adiwardana, D., Luong, M.-T., So, D. R., Hall, J., Fiedel, N., Thoppilan, R., Yang, Z., Kulshreshtha, A., Nemade, G., Lu, Y., et al. Towards a human-like open-domain chatbot. arXiv preprint arXiv:2001.09977 , 2020.\n- Aleph Alpha. Luminous: performance benchmarks. arXiv preprint arXiv:1810.12885 , 2023. URL https://www.aleph-alpha.com/pdf/2023\\_ 02\\_AA\\_Benchmarks\\_doc.pdf .\n- Allamanis, M. The adverse effects of code duplication in machine learning models of code. In Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software , pp. 143-153, 2019.\n- Almazrouei, E., Cappelli, A., Cojocaru, R., Debbah, M., Goffinet, E., Heslow, D., Launay, J., Malartic, Q., Noune, B., Pannier, B., and Penedo, G. Falcon-40b: an open large language model with state-of-the-art performance. 2023.\n- Amini, A., Gabriel, S., Lin, S., Koncel-Kedziorski, R., Choi, Y., and Hajishirzi, H. Mathqa: Towards interpretable math word problem solving with operation-based formalisms. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) , pp. 2357-2367, 2019.\n- Aroca-Ouellette, S., Paik, C., Roncone, A., and Kann, K. Prost: Physical reasoning about objects through space and time. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021 , pp. 4597-4608, 2021.\n- Artetxe, M., Bhosale, S., Goyal, N., Mihaylov, T., Ott, M., Shleifer, S., Lin, X. V ., Du, J., Iyer, S., Pasunuru, R., et al. Efficient large scale language modeling with mixtures of experts. arXiv preprint arXiv:2112.10684 , 2021.\n- Barbaresi, A. Trafilatura: A Web Scraping Library and Command-Line Tool for Text Discovery and Extraction. In Proceedings of the Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations , pp. 122-131. Association for Computational Linguistics, 2021. URL https://aclanthology.org/2021. acl-demo.15 .\n- Beltagy, I., Lo, K., and Cohan, A. Scibert: A pretrained language model for scientific text. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLPIJCNLP) , pp. 3615-3620, 2019.\n- Biderman, S., Schoelkopf, H., Anthony, Q., Bradley, H., O'Brien, K., Hallahan, E., Khan, M. A., Purohit, S., Prashanth, U. S., Raff, E., et al. Pythia: A suite for analyzing large language models across training and scaling. arXiv preprint arXiv:2304.01373 , 2023.\n- Bisk, Y., Zellers, R., Gao, J., Choi, Y ., et al. Piqa: Reasoning about physical commonsense in natural language. In Proceedings of the AAAI conference on artificial intelligence , volume 34, pp. 7432-7439, 2020.\n- Black, S., Leo, G., Wang, P., Leahy, C., and Biderman, S. GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow, March 2021. URL https: //doi.org/10.5281/zenodo.5297715 . If you use this software, please cite it using these metadata.\n- Black, S., Biderman, S., Hallahan, E., Anthony, Q., Gao, L., Golding, L., He, H., Leahy, C., McDonell, K., Phang, J., et al. Gpt-neox-20b: An open-source autoregressive language model. Challenges &amp; Perspectives in Creating Large Language Models , pp. 95, 2022.\n- Broder, A. Z. On the resemblance and containment of documents. In Proceedings. Compression and Complexity of Sequences 1997 , pp. 21-29. IEEE, 1997.\n- Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. Advances in neural information processing systems , 33: 1877-1901, 2020.\n- Carlini, N., Tramer, F., Wallace, E., Jagielski, M., HerbertVoss, A., Lee, K., Roberts, A., Brown, T., Song, D.,\n\n- Erlingsson, U., et al. Extracting training data from large language models. In 30th USENIX Security Symposium (USENIX Security 21) , pp. 2633-2650, 2021.\n- Carlini, N., Ippolito, D., Jagielski, M., Lee, K., Tramer, F., and Zhang, C. Quantifying memorization across neural language models. arXiv preprint arXiv:2202.07646 , 2022.\n- Charikar, M. S. Similarity estimation techniques from rounding algorithms. In Proceedings of the thiry-fourth annual ACM symposium on Theory of computing , pp. 380-388, 2002.\n- Chelba, C., Mikolov, T., Schuster, M., Ge, Q., Brants, T., Koehn, P., and Robinson, T. One billion word benchmark for measuring progress in statistical language modeling. arXiv preprint arXiv:1312.3005 , 2013.\n- Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311 , 2022.\n- Clark, C., Lee, K., Chang, M.-W., Kwiatkowski, T., Collins, M., and Toutanova, K. Boolq: Exploring the surprising difficulty of natural yes/no questions. In Proceedings of NAACL-HLT , pp. 2924-2936, 2019.\n- Clark, P., Cowhey, I., Etzioni, O., Khot, T., Sabharwal, A., Schoenick, C., and Tafjord, O. Think you have solved question answering? try arc, the ai2 reasoning challenge. arXiv preprint arXiv:1803.05457 , 2018.\n- Dagan, I., Dolan, B., Magnini, B., and Roth, D. Recognizing textual entailment: Rational, evaluation and approacheserratum. Natural Language Engineering , 16(1):105-105, 2010.\n- Dao, T., Fu, D. Y., Ermon, S., Rudra, A., and Re, C. Flashattention: Fast and memory-efficient exact attention with io-awareness. In Advances in Neural Information Processing Systems , 2022.\n- De Marneffe, M.-C., Simons, M., and Tonhauser, J. The commitmentbank: Investigating projection in naturally occurring discourse. In proceedings of Sinn und Bedeutung , volume 23, pp. 107-124, 2019.\n- Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) , pp. 4171-4186, 2019.\n- Dey, N., Gosal, G., Khachane, H., Marshall, W., Pathria, R., Tom, M., Hestness, J., et al. Cerebras-gpt: Open computeoptimal language models trained on the cerebras waferscale cluster. arXiv preprint arXiv:2304.03208 , 2023.\n- Dodge, J., Sap, M., Marasovi´ c, A., Agnew, W., Ilharco, G., Groeneveld, D., Mitchell, M., and Gardner, M. Documenting large webtext corpora: A case study on the colossal clean crawled corpus. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing , pp. 1286-1305, 2021.\n- Eberhard, D. M., Simons, G. F., and Fennig, C. D. Ethnologue: Languages of the World . SIL International, Dallas, TX, USA, twenty-sixth edition, 2023.\n- Gao, L., Biderman, S., Black, S., Golding, L., Hoppe, T., Foster, C., Phang, J., He, H., Thite, A., Nabeshima, N., et al. The pile: An 800gb dataset of diverse text for language modeling. arXiv preprint arXiv:2101.00027 , 2020.\n- Gao, L., Tow, J., Biderman, S., Black, S., DiPofi, A., Foster, C., Golding, L., Hsu, J., McDonell, K., Muennighoff, N., Phang, J., Reynolds, L., Tang, E., Thite, A., Wang, B., Wang, K., and Zou, A. A framework for few-shot language model evaluation, September 2021. URL https: //doi.org/10.5281/zenodo.5371628 .\n- Gebru, T., Morgenstern, J., Vecchione, B., Vaughan, J. W., Wallach, H., Iii, H. D., and Crawford, K. Datasheets for datasets. Communications of the ACM , 64(12):86-92, 2021.\n- Gokaslan, A., Cohen, V., Pavlick, E., and Tellex, S. Openwebtext corpus. http://Skylion007.github. io/OpenWebTextCorpus , 2019.\n- Gordon, A., Kozareva, Z., and Roemmele, M. Semeval2012 task 7: Choice of plausible alternatives: An evaluation of commonsense causal reasoning. In * SEM 2012: The First Joint Conference on Lexical and Computational Semantics-Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval 2012) , pp. 394-398, 2012.\n- Grave, ´ E., Bojanowski, P., Gupta, P., Joulin, A., and Mikolov, T. Learning word vectors for 157 languages. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018) , 2018.\n- Hanu, L. and Unitary team. Detoxify. Github. https://github.com/unitaryai/detoxify, 2020.\n- Hernandez, D., Brown, T., Conerly, T., DasSarma, N., Drain, D., El-Showk, S., Elhage, N., Hatfield-Dodds,\n\n- Z., Henighan, T., Hume, T., et al. Scaling laws and interpretability of learning from repeated data. arXiv preprint arXiv:2205.10487 , 2022.\n- Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Casas, D. d. L., Hendricks, L. A., Welbl, J., Clark, A., et al. Training compute-optimal large language models. arXiv preprint arXiv:2203.15556 , 2022.\n- Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. The curious case of neural text degeneration. In International Conference on Learning Representations , 2019.\n- Jaccard, P. The distribution of the flora in the alpine zone.1. New Phytologist , 11:37-50, 1912.\n- Jin, Q., Dhingra, B., Liu, Z., Cohen, W., and Lu, X. Pubmedqa: A dataset for biomedical research question answering. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) , pp. 2567-2577, 2019.\n- Joulin, A., Grave, E., Bojanowski, P., Douze, M., J´ egou, H., and Mikolov, T. Fasttext. zip: Compressing text classification models. arXiv preprint arXiv:1612.03651 , 2016.\n- Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., Gray, S., Radford, A., Wu, J., and Amodei, D. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361 , 2020.\n- Kreutzer, J., Caswell, I., Wang, L., Wahab, A., van Esch, D., Ulzii-Orshikh, N., Tapo, A. A., Subramani, N., Sokolov, A., Sikasote, C., et al. Quality at a glance: An audit of web-crawled multilingual datasets. Transactions of the Association for Computational Linguistics , 10:50-72, 2022.\n- Laurenc ¸on, H., Saulnier, L., Wang, T., Akiki, C., del Moral, A. V., Le Scao, T., Von Werra, L., Mou, C., Ponferrada, E. G., Nguyen, H., et al. The bigscience roots corpus: A 1.6 tb composite multilingual dataset. In Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track , 2022.\n- Lee, K., Ippolito, D., Nystrom, A., Zhang, C., Eck, D., Callison-Burch, C., and Carlini, N. Deduplicating training data makes language models better. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pp. 84248445, 2022.\n- Liu, J., Cui, L., Liu, H., Huang, D., Wang, Y., and Zhang, Y. Logiqa: a challenge dataset for machine reading comprehension with logical reasoning. In Proceedings of\n- the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence , pp. 3622-3628, 2021.\n- Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., and Stoyanov, V. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692 , 2019.\n- Lopukhin, K. Evaluating quality of article body extraction for commercial services and open-source libraries. https://github.com/scrapinghub/ article-extraction-benchmark , 2019.\n- Manber, U. and Myers, G. Suffix arrays: a new method for on-line string searches. Journal on Computing , 22(5): 935-948, 1993.\n- Mihaylov, T., Clark, P., Khot, T., and Sabharwal, A. Can a suit of armor conduct electricity? a new dataset for open book question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing , pp. 2381-2391, 2018.\n- Mitchell, M., Wu, S., Zaldivar, A., Barnes, P., Vasserman, L., Hutchinson, B., Spitzer, E., Raji, I. D., and Gebru, T. Model cards for model reporting. In Proceedings of the conference on fairness, accountability, and transparency , pp. 220-229, 2019.\n- Nie, Y., Williams, A., Dinan, E., Bansal, M., Weston, J., and Kiela, D. Adversarial nli: A new benchmark for natural language understanding. arXiv preprint arXiv:1910.14599 , 2019.\n- Ortiz Su´ arez, P. J., Sagot, B., and Romary, L. Asynchronous pipelines for processing huge corpora on medium to low resource infrastructures. Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-7) 2019. Cardiff, 22nd July 2019, pp. 9 -16, Mannheim, 2019. Leibniz-Institut f¨ ur Deutsche Sprache. doi: 10.14618/ ids-pub-9021. URL http://nbn-resolving.de/ urn:nbn:de:bsz:mh39-90215 .\n- Paperno, D., Kruszewski, G., Lazaridou, A., Pham, N.-Q., Bernardi, R., Pezzelle, S., Baroni, M., Boleda, G., and Fern´ andez, R. The lambada dataset: Word prediction requiring a broad discourse context. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pp. 15251534, 2016.\n\nPomik´ alek, J. Justext. 2011.\n\n- Press, O., Smith, N., and Lewis, M. Train short, test long: Attention with linear biases enables input length extrapolation. In International Conference on Learning Representations , 2021.\n\n- Radford, A., Narasimhan, K., Salimans, T., Sutskever, I., et al. Improving language understanding by generative pre-training. 2018.\n- Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et al. Language models are unsupervised multitask learners. 2019.\n- Rae, J. W., Borgeaud, S., Cai, T., Millican, K., Hoffmann, J., Song, F., Aslanides, J., Henderson, S., Ring, R., Young, S., Rutherford, E., Hennigan, T., Menick, J., Cassirer, A., Powell, R., Driessche, G. v. d., Hendricks, L. A., Rauh, M., Huang, P.-S., Glaese, A., Welbl, J., Dathathri, S., Huang, S., Uesato, J., Mellor, J., Higgins, I., Creswell, A., McAleese, N., Wu, A., Elsen, E., Jayakumar, S., Buchatskaya, E., Budden, D., Sutherland, E., Simonyan, K., Paganini, M., Sifre, L., Martens, L., Li, X. L., Kuncoro, A., Nematzadeh, A., Gribovskaya, E., Donato, D., Lazaridou, A., Mensch, A., Lespiau, J.-B., Tsimpoukelli, M., Grigorev, N., Fritz, D., Sottiaux, T., Pajarskas, M., Pohlen, T., Gong, Z., Toyama, D., d'Autume, C. d. M., Li, Y., Terzi, T., Mikulik, V., Babuschkin, I., Clark, A., Casas, D. d. L., Guy, A., Jones, C., Bradbury, J., Johnson, M., Hechtman, B., Weidinger, L., Gabriel, I., Isaac, W., Lockhart, E., Osindero, S., Rimell, L., Dyer, C., Vinyals, O., Ayoub, K., Stanway, J., Bennett, L., Hassabis, D., Kavukcuoglu, K., and Irving, G. Scaling language models: Methods, analysis &amp; insights from training gopher. 2021. doi: 10.48550/ARXIV.2112.11446. URL https://arxiv.org/abs/2112.11446 .\n- Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research , 21(140):1-67, 2020. URL http://jmlr. org/papers/v21/20-074.html .\n- Sakaguchi, K., Bras, R. L., Bhagavatula, C., and Choi, Y. Winogrande: An adversarial winograd schema challenge at scale. Communications of the ACM , 64(9):99-106, 2021.\n- Scao, T. L., Fan, A., Akiki, C., Pavlick, E., Ili´ c, S., Hesslow, D., Castagn´ e, R., Luccioni, A. S., Yvon, F., Gall´ e, M., et al. Bloom: A 176b-parameter open-access multilingual language model. arXiv preprint arXiv:2211.05100 , 2022a.\n- Scao, T. L., Wang, T., Hesslow, D., Saulnier, L., Bekman, S., Bari, M. S., Bideman, S., Elsahar, H., Muennighoff, N., Phang, J., et al. What language model to train if you have one million gpu hours? arXiv preprint arXiv:2210.15424 , 2022b.\n- Sevilla, J., Heim, L., Ho, A., Besiroglu, T., Hobbhahn, M., and Villalobos, P. Compute trends across three eras\n- of machine learning. arXiv preprint arXiv:2202.05924 , 2022.\n- Sites, D. Compact language detector 2. Software available at https://github. com/CLD2Owners/cld2 (last updated on August 2015) , 2013.\n- Tay, Y., Dehghani, M., Rao, J., Fedus, W., Abnar, S., Chung, H. W., Narang, S., Yogatama, D., Vaswani, A., and Metzler, D. Scale efficiently: Insights from pretraining and finetuning transformers. In International Conference on Learning Representations , 2021.\n- Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.-T., Jin, A., Bos, T., Baker, L., Du, Y., et al. Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239 , 2022.\n- Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozi` ere, B., Goyal, N., Hambro, E., Azhar, F., et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 , 2023.\n- Trinh, T. H. and Le, Q. V. A simple method for commonsense reasoning. arXiv preprint arXiv:1806.02847 , 2018.\n- Vilares, D. and G´ omez-Rodr´ ıguez, C. Head-qa: A healthcare dataset for complex reasoning. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , pp. 960-966, 2019.\n- Villalobos, P., Sevilla, J., Heim, L., Besiroglu, T., Hobbhahn, M., and Ho, A. Will we run out of data? an analysis of the limits of scaling datasets in machine learning. arXiv preprint arXiv:2211.04325 , 2022.\n- Wang, B. and Komatsuzaki, A. GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/kingoflolz/ mesh-transformer-jax , May 2021.\n- Wang, T., Roberts, A., Hesslow, D., Scao, T. L., Chung, H. W., Beltagy, I., Launay, J., and Raffel, C. What language model architecture and pretraining objective work best for zero-shot generalization? In International Conference on Machine Learning , 2022.\n- Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Metzler, D., et al. Emergent abilities of large language models. Transactions on Machine Learning Research , 2022.\n- Welbl, J., Liu, N. F., and Gardner, M. Crowdsourcing multiple choice science questions. In Proceedings of the 3rd Workshop on Noisy User-generated Text , pp. 94-106, 2017.\n\n- Welbl, J., Glaese, A., Uesato, J., Dathathri, S., Mellor, J., Hendricks, L. A., Anderson, K., Kohli, P., Coppin, B., and Huang, P.-S. Challenges in detoxifying language models. In Findings of the Association for Computational Linguistics: EMNLP 2021 , pp. 2447-2469, 2021.\n- Wenzek, G., Lachaux, M.-A., Conneau, A., Chaudhary, V., Guzm´ an, F., Joulin, A., and Grave, ´ E. Ccnet: Extracting high quality monolingual datasets from web crawl data. In Proceedings of the 12th Language Resources and Evaluation Conference , pp. 4003-4012, 2020.\n- Xue, L., Constant, N., Roberts, A., Kale, M., Al-Rfou, R., Siddhant, A., Barua, A., and Raffel, C. mt5: A massively multilingual pre-trained text-to-text transformer. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies , pp. 483-498, 2021.\n- Yang, G., Hu, E., Babuschkin, I., Sidor, S., Liu, X., Farhi, D., Ryder, N., Pachocki, J., Chen, W., and Gao, J. Tuning large neural networks via zero-shot hyperparameter transfer. Advances in Neural Information Processing Systems , 34:17084-17097, 2021.\n- Zellers, R., Holtzman, A., Bisk, Y., Farhadi, A., and Choi, Y. Hellaswag: Can a machine really finish your sentence? In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , pp. 4791-4800, 2019.\n- Zeng, W., Ren, X., Su, T., Wang, H., Liao, Y., Wang, Z., Jiang, X., Yang, Z., Wang, K., Zhang, X., et al. Pangualpha: Large-scale autoregressive pretrained chinese language models with auto-parallel computation. arXiv preprint arXiv:2104.12369 , 2021.\n- Zhang, S., Liu, X., Liu, J., Gao, J., Duh, K., and Van Durme, B. Record: Bridging the gap between human and machine commonsense reading comprehension. arXiv preprint arXiv:1810.12885 , 2018.\n- Zhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M., Chen, S., Dewan, C., Diab, M., Li, X., Lin, X. V., et al. Opt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068 , 2022.\n- Zhu, Y., Kiros, R., Zemel, R., Salakhutdinov, R., Urtasun, R., Torralba, A., and Fidler, S. Aligning books and movies: Towards story-like visual explanations by watching movies and reading books. In Proceedings of the IEEE international conference on computer vision , pp. 19-27, 2015.\n\n## A. RefinedWeb Datasheet\n\n| MOTIVATION                                                                                                                   | MOTIVATION                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n|------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| For what purpose was the dataset cre- ated?                                                                                  | RefinedWeb was created to serve as a large-scale dataset for the pretrain- ing of large language models. It may be used on its own, or augmented with curated sources (e.g., Wikipedia, StackOverflow).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n| Who created the dataset and on behalf of which entity?                                                                       | The dataset was created by the Technology Innovation Institute.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n| Who funded the creation of the dataset?                                                                                      | The creation of the dataset was privately funded by the Technology Innovation Institute.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| Any other comment?                                                                                                           | RefinedWeb is built on-top of CommonCrawl, using the Macrodata Re- finement Pipeline, which combines content extraction, filtering heuristics, and deduplication. In designing RefinedWeb, we abided to the following philosophy: (1) Scale first. We intend MDR to produce datasets to be used to train 40-200B parameters models, thus requiring trillions of tokens (Hoffmann et al., 2022). For English-only RefinedWeb, we target a size of 3-6 trillion tokens. Specifically, we eschew any labour inten- sive human curation process, and focus on CommonCrawl instead of disparate single-domain sources. (2) Strict deduplication. Inspired by the work of Lee et al. (2022), which demonstrated the value of deduplica- tion for large language models, we implement a rigorous deduplication pipeline. We combine both exact and fuzzy deduplication, and use strict settings leading to removal rates far higher than others have reported. (3) Neutral filtering. To avoid introducing further undesirable biases into the model (Dodge et al., 2021; Welbl et al., 2021), we avoid using ML-based filtering outside of language identification. We stick to simple rules and heuristics, and use only URL filtering for adult content. |\n| COMPOSITION                                                                                                                  | COMPOSITION                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n| What do the instances that comprise the dataset represent?                                                                   | Instances are text-only documents, corresponding to single web pages.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n| How many instances are there in total?                                                                                       | RefinedWeb contains ∼ 10 billion documents, or around 5 trillion tokens. The public version is a subset representing a tenth of the full version.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n| Does the dataset contain all possible in- stances or is it a sample (not necessarily random) of instances from a larger set? | RefinedWeb is built using all CommonCrawl dumps until the 2023-06 one; it could be updated with additional dumps as they are released. The public release of RefinedWeb is a 600GT random extract of the 5,000GT of the full dataset. For all experiments, we randomly sampled from the public extract, or earlier development versions of it.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n| What data does each instance consist of?                                                                                     | Each instance is a text-only document, with metadata about its origin in CommonCrawl and source page URL. We also distribute a multimodal version of RefinedWeb, containing interlaced links to images.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n| Is there a label or target associated with each instance?                                                                    | No.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n| Is any information missing from individ- ual instances?                                                                      | No.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n| Are relationships between individual in- stances made explicit?                                                              | No.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n| Are there recommended data splits?                                                                                           | No.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n\n| Are there any errors, sources of noise, or redundancies in the dataset?                                                                 | Despite our best efforts to filter content that does not qualify as natural language, and to deduplicate documents, our pipeline may let through documents that may be considered as errors or redundant.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n|-----------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Is the dataset self-contained, or does it link to or otherwise rely on external re- sources?                                            | The base version of the dataset is self-contained, but the multimodal version is interlaced with links to images-these are not distributed as part of the dataset, and constitute an external source.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n| Does the dataset contain data that might be considered confidential?                                                                    | All documents in RefinedWeb have been publicly available online.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n| Does the dataset contain data that, if viewed directly, might be offensive, in- sulting, threatening, or might otherwise cause anxiety? | Yes, as this type of data is prevalent on the internet, it is likely our dataset contains such content. Notably, we estimate the prevalence of toxic content in the dataset to be similar to The Pile (Figure 4).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n| COLLECTION                                                                                                                              | COLLECTION                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n| How was the data associated with each instance acquired?                                                                                | We downloaded with warcio publicly available .WET files from the CommonCrawl foundation.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n| What mechanisms or procedures were used to collect the data?                                                                            | We refer to the CommonCrawl website ( commoncrawl.org ) for de- tails on how they collect data.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n| If the dataset is a sample from a larger set, what was the sampling strategy?                                                           | Whenever we use subsets, we randomly sample from the original data.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| Who was involved in the data collec- tion process and how were they compen- sated?                                                      | The original data collection was performed by CommonCrawl; authors from this paper were involved in retrieving it and preparing it.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| Over what timeframe was the data col- lected?                                                                                           | We use all CommonCrawl dumps from 2008 to January/February 2023.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n| Were any ethical review processes con- ducted?                                                                                          | No.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| PREPROCESSING                                                                                                                           | PREPROCESSING                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n| Was any preprocessing/cleaning/labeling of the data done?                                                                               | Yes, we applied extensive preprocessing and cleaning of the data. We first filter URLs to remove adult content using a blocklist and a score sys- tem (Appendix G.1), we then use trafilatura (Barbaresi, 2021) to extract content from pages, and perform language identification with the fastText classifier from CCNet (Wenzek et al., 2020). Af- ter this first preprocessing stage, we filter data using heuristics from MassiveWeb (Rae et al., 2021) and our own line-wise corrections (Ap- pendix G.2). Finally, we run extensive deduplication, removing URLs revisited across dumps (Section 3.3) and performing subsequently fuzzy and exact substring deduplication, with each stage drawing from Lee et al. (2022). See Section 3 for further details and Table 2 for an outline. |\n| Was the 'raw' data saved in addition to the preprocessed/cleaned/labeled data?                                                          | During development, we saved intermediary outputs from our pipeline for investigations and for ablations-intermediary outputs exist for about 5% of RefinedWeb. We did not keep intermediary outputs for the final production version of the dataset due to storage and resource constraints.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n| Is the software that was used to prepro- cess/clean/label the data available?                                                           | No.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| USES                                                                                                                                    | USES                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n| Has the dataset been used for any tasks already?                                                                                        | Yes, this data has been used to develop large language models: both for scientific experiments (e.g., this paper) and production use.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n\nTable 6: Datasheet for RefinedWeb , following the framework introduced by Gebru et al. (2021).\n\n| Is there a repository that links to any or all papers or systems that use the dataset?                                                               | No.                                                                                                                                                        |\n|------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| What (other) tasks could the dataset be used for?                                                                                                    | RefinedWeb was built as a large-scale corpora representative of the web, and as such may see many downstream uses which are difficult to predict.          |\n| Is there anything about the composition of the dataset or the way it was col- lected and preprocessed/cleaned/labeled that might impact future uses? | For the public extract of RefinedWeb, we chose to only draw from the English version of the dataset, preventing multilingual applications.                 |\n| Are there tasks for which the dataset should not be used?                                                                                            | Any tasks which may considered irresponsible or harmful.                                                                                                   |\n| DISTRIBUTION                                                                                                                                         | DISTRIBUTION                                                                                                                                               |\n| Will the dataset be distributed to third parties outside of the entity on behalf of which the dataset was created?                                   | Yes, we make a 600GT extract publicly available for NLP practitioners. We currently don't plan to share the full version of the dataset.                   |\n| How will the dataset will be distributed?                                                                                                            | The dataset will be made available through the HuggingFace Hub.                                                                                            |\n| When will the dataset be distributed?                                                                                                                | The dataset is available immediately.                                                                                                                      |\n| Will the dataset be distributed under a copyright or other intellectual prop- erty (IP) license, and/or under applicable terms of use (ToU)?         | The public extract is made available under an ODC-By 1.0 license; users should also abide to the CommonCrawl ToU: https:// commoncrawl.org/terms-of-use/ . |\n| Have any third parties imposed IP-based or other restrictions on the data associ- ated with the instances?                                           | Not to our knowledge.                                                                                                                                      |\n| Do any export controls or other regula- tory restrictions apply to the dataset or to individual instances?                                           | Not to our knowledge.                                                                                                                                      |\n| MAINTENANCE                                                                                                                                          | MAINTENANCE                                                                                                                                                |\n| Who will be support- ing/hosting/maintaining the dataset?                                                                                            | The dataset will be hosted on the HuggingFace Hub, we have no plans to further support or maintain it once it is released.                                 |\n| How can the owner/curator/manager of the dataset be contacted?                                                                                       | falconllm@tii.ae                                                                                                                                           |\n| Is there an erratum?                                                                                                                                 | No.                                                                                                                                                        |\n| Will the dataset be updated?                                                                                                                         | No.                                                                                                                                                        |\n| If others want to extend/augment/build on/contribute to the dataset, is there a mechanism for them to do so?                                         | No.                                                                                                                                                        |\n\n## B. Falcon-RW Model Cards\n\n| MODEL DETAILS                                 | MODEL DETAILS                                 | MODEL DETAILS                                 | MODEL DETAILS                                                                                                                                                                                                                                                                                                                                                                |\n|-----------------------------------------------|-----------------------------------------------|-----------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Person/organization model                     | developing                                    | the                                           | The models were created by the Technology Innovation Institute.                                                                                                                                                                                                                                                                                                              |\n| Model date                                    | Model date                                    | Model date                                    | Falcon-RW models were trained in December 2022/January 2023.                                                                                                                                                                                                                                                                                                                 |\n| Model type and information about train- ing   | Model type and information about train- ing   | Model type and information about train- ing   | Falcon-RW are autoregressive Transformer models trained with a causal language modeling objective. Architecture based on GPT-3 (Brown et al., 2020), with ALiBi positional encodings (Press et al., 2021) and FlashAt- tention (Dao et al., 2022). See Section 4.1 for details.                                                                                              |\n| Licence                                       | Licence                                       | Licence                                       | Apache 2.0: https://www.apache.org/licenses/ LICENSE-2.0 .                                                                                                                                                                                                                                                                                                                   |\n| Point of contact                              | Point of contact                              | Point of contact                              | falconllm@tii.ae                                                                                                                                                                                                                                                                                                                                                             |\n| INTENDED USE                                  | INTENDED USE                                  | INTENDED USE                                  | INTENDED USE                                                                                                                                                                                                                                                                                                                                                                 |\n| Primary intended uses                         | Primary intended uses                         | Primary intended uses                         | Research on large language models, and the influence of adequately filtered and deduplicated web data on the properties of large language models (fairness, safety, limitations, capabilities, etc.).                                                                                                                                                                        |\n| Primary intended users                        | Primary intended users                        | Primary intended users                        | NLP researchers.                                                                                                                                                                                                                                                                                                                                                             |\n| Out-of-scope use cases                        | Out-of-scope use cases                        | Out-of-scope use cases                        | Production use without adequate assessment of risks and mitigation; any use cases which may be considered irresponsible or harmful.                                                                                                                                                                                                                                          |\n| FACTORS                                       | FACTORS                                       | FACTORS                                       | FACTORS                                                                                                                                                                                                                                                                                                                                                                      |\n| Relevant factors                              | Relevant factors                              | Relevant factors                              | Falcon-RW models are trained on English data only, and will not gener- alize appropriately to other languages. Furthermore, as they are trained on a large-scale corpora representative of the web, they will carry the stereotypes and biases commonly encountered online.                                                                                                  |\n| Evaluation factors                            | Evaluation factors                            | Evaluation factors                            | We evaluated the toxicity of the underlying pretraining dataset and found it to be in line with common curated pretraining datasets such as The Pile (see Figure 4). Note that this only accounts for toxicity under the definition of Perspective API: 'content that is rude or disrespectful'. Notably, this fails to include concerns about social biases or harmfulness. |\n| METRICS                                       | METRICS                                       | METRICS                                       | METRICS                                                                                                                                                                                                                                                                                                                                                                      |\n| Model performance measures                    | Model performance measures                    | Model performance measures                    | We focus our evaluation on measuring the zero-shot generalization ca- pabilities of our models across a wide range of tasks, leveraging the Eleuther AI language model evaluation harness (Gao et al., 2021).                                                                                                                                                                |\n| Variation approaches                          | Variation approaches                          | Variation approaches                          | Due to the costs associated with training Falcon-RW we cannot train the models multiple times and measure variability across training runs.                                                                                                                                                                                                                                  |\n| EVALUATION DATA                               | EVALUATION DATA                               | EVALUATION DATA                               | EVALUATION DATA                                                                                                                                                                                                                                                                                                                                                              |\n| Datasets                                      | Datasets                                      | Datasets                                      | We evaluate zero-shot accuracy on 18 varied tasks, detailed in Table 3.                                                                                                                                                                                                                                                                                                      |\n| Motivation                                    | Motivation                                    | Motivation                                    | Weselected and aggregated tasks to build comparisons with other models in the literature (see Section 4.1; Appendix F.1 for details).                                                                                                                                                                                                                                        |\n| Preprocessing                                 | Preprocessing                                 | Preprocessing                                 | We use the default prompts and setup of Gao et al. (2021).                                                                                                                                                                                                                                                                                                                   |\n| TRAINING DATA dedicated datasheet in Table 6. | TRAINING DATA dedicated datasheet in Table 6. | TRAINING DATA dedicated datasheet in Table 6. | TRAINING DATA dedicated datasheet in Table 6.                                                                                                                                                                                                                                                                                                                                |\n\n## C. Dataset analysis\n\nThe large-scale and diverse nature of web corpora make them difficult to document and analyse as a whole; we provide some key metrics in the section, focusing on document lengths in Figure 5(a), and a breakdown of the top domain names in Figure 5(b). We also refer to the analysis of the distribution of toxic content presented in Figure 4.\n\nFigure 5. Make-up of RefinedWeb in document lengths (left) and top domains (right). (a) We find the OSCAR datasets and RW-Raw to have similar document length distributions; following filtering, most of the short documents are discarded from RW-Filtered. As deduplication removes spans, it reintroduces shorter documents to RefinedWeb. We note the make-up of C4 and RefinedWeb to be relatively similar, with a longer tail of short documents for RefinedWeb. Finally, The Pile exhibit a unique make-up, with a long tail of both long (books, etc.) and short documents. (b) Top domains in RefinedWeb span from popular content platforms (Blogspot, WordPress, Tumblr, etc.), to news websites (CNN, New York Times, etc.), and include also technical content such as BioMed Central or Springer.\n\n<!-- image -->\n\n## D. Multilingual RefinedWeb\n\nMultilingual data. Using the language identification filter, we classify processed CommonCrawl data into 176 languages. Figure 6 shows the top 20 languages present in the data excluding English , based on their relative contribution in descending order. 58.20% of all documents in the processed CommonCrawl data were identified as English. We find the distribution of languages in CommonCrawl to only be partially aligned with the worldwide distribution of language speakers (Eberhard et al., 2023): Russian is over-represented (2nd in CC but only 8th worldwide), Mandarin Chinese is under-represented (6-7th in CC but 2nd worldwide), and Hindi does not show-up in the top 20 despite being the 3rd most spoken.\n\nFigure 6. Top 20 languages (excluding English) from processed CommonCrawl based on number of documents and disk size.\n\n<!-- image -->\n\nProcessing multilingual data. The MDR pipeline can be used to process all languages: features such as text extraction are language-agnostic, whereas specific filters such as line-wise corrections need to typically be tuned for each individual language. We also found tuning deduplication parameters for individual languages to be beneficial.\n\n## E. Additional results\n\nIn this section, we present additional results obtained during the development of the Macrodata Refinement pipeline. For Appendix E.1 and Appendix E.3, these were obtained using earlier development versions of the dataset, so results are not directly comparable with the main text. For Appendix E.2, this is based on the Falcon-RW models.\n\n## E.1. Small-scale ablations on deduplication approaches\n\nWe present results in Table 8-the setup is similar to our earlier ablations, training 1B models for 30GT. We observe that:\n\n- MinHash alone is insufficient , as it doesn't match the zero-shot performance of exact deduplication. Conversely, combining it with exact deduplication doesn't improve performance further.\n- Masking spanned duplicates degrades performance , systematically underperforming other approaches. Dropping and cutting spans perform similarly, although it's likely that dropping documents slightly outperforms cutting.\n\nFinally, we chose to apply MinHash before exact deduplication, as it is easier to scale: approximate deduplication acts as a pruning phase, enabling us to scale deduplication further. Finally, we choose the common option of cutting spans, as dropping resulted in even more stringent rejection rates which would have compromised our ability to collect 5 trillion tokens.\n\nTable 8. MinHash alone is insufficient to match the performance of exact substring deduplication, and combining the two does not significantly improve performance. Of all of the exact substring approaches, masking duplicated spans underperform, but all others exhibit similar performance. ✓ Minhash + Exact substring-Cut corresponds to our final deduplication setup. Perplexity in bits-per-bytes on The Pile ( pile-bpb , lower is better), zero-shot performance aggregated over LAMBADA, PIQA, and HellaSwag ( agg-dev ). Best results in bold , best results with minhash in underline, table sorted by increasing agg-dev-1 .\n\n| Minhash             | Exact substring     |   pile-bpb ↓ |   agg-dev-1 ↑ |\n|---------------------|---------------------|--------------|---------------|\n| RefinedWeb-Filtered | RefinedWeb-Filtered |         1.11 |         43.51 |\n| ✓ ✓ ✓ ✓ ✓           | Mask                |         1.08 |         45.84 |\n| ✓ ✓ ✓ ✓ ✓           | Mask                |         1.07 |         46.28 |\n| ✓ ✓ ✓ ✓ ✓           |                     |         1.07 |         46.57 |\n| ✓ ✓ ✓ ✓ ✓           | Cut                 |         1.05 |         47.11 |\n| ✓ ✓ ✓ ✓ ✓           | Cut                 |         1.06 |         47.24 |\n| ✓ ✓ ✓ ✓ ✓           | Drop partial        |         1.05 |         47.25 |\n| ✓ ✓ ✓ ✓ ✓           | Drop any            |         1.07 |         47.77 |\n| ✓ ✓ ✓ ✓ ✓           | Drop any            |         1.07 |         47.86 |\n| ✓ ✓ ✓ ✓ ✓           | Drop partial        |         1.06 |         47.97 |\n|                     | Pile                |         0.88 |         43.7  |\n\n## E.2. Language modeling evaluation\n\nAlong with our aggregates, we also evaluated perplexity on Wikitext (Table 9). We found that models trained on RefinedWeb achieve performance close to that of models trained on The Pile. Importantly, we note that RefinedWeb does not contain any content from Wikipedia - it is explicitly filtered out at the URL level. We believe this accounts for most of the difference in perplexity, as RW models may not be familiar with the idiosyncrasies of Wikitext (e.g., layout of an article, etc.)\n\nTable 9. Models trained on RefinedWeb achieve performance close to models trained on The Pile on Wikitext, despite not having seen any content from Wikipedia. Perplexity in bits-per-bytes on Wikitext ( wiki-bpb , lower is better.)\n\n| Model size Dataset   |   1B The Pile |   RW |   7B RW |\n|----------------------|---------------|------|---------|\n| wiki-bpb ↓           |          0.64 | 0.66 |     0.6 |\n\n## E.3. Does deduplication help with multiple epochs?\n\nEarlier in this work, we outlined that to scale pretraining data, practitioners had two choices: (1) improve data collection, which is the avenue we chose to pursue; (2) train models on multiple epochs of the same data. Due to current uncertainties in the ability of larger models to sustain multiple epochs without adverse effects (Hernandez et al., 2022), we focused on (1). A fairly rational question regarding (2) is whether deduplication may improve the situation, and whether deduplicated data may be able to sustain more epochs without compromising model quality.\n\nWe train 1B parameters models on 30GT of RW and RW-Filtered. We keep the number of pretraining tokens fixed, but train for 1, 5, 25, and 100 epochs. This is a small-scale, limited set-up, which would have to be improved to obtain definitive results. We plot the degradation in performance compared to a single epoch in Figure 7(a) and the gap between RW and RW-F in Figure 7(b). We find that the absolute degradation is less important for RefinedWeb than for RefinedWeb-Filtered; furthermore, the gap widens with increasing number of epochs. However, we observe significant variability across tasks.\n\nFigure 7. Deduplication may reduce the degradation in performance incurred by multiple epochs. However, our experiments were only performed at small-scale (1B models trained on 30GT), and we see high variability in outcomes across tasks. Zero-shot performance measured on the agg-dev-2 aggregate (HellaSwag, PIQA, ARC, BoolQ, COPA, MRPC, SciQ). Individual curves for per-task results and 1σ standard deviation across all tasks in the aggregate in transparent.\n\n<!-- image -->\n\n## F. Tasks, models, and datasets from the state-of-the-art\n\n## F.1. Task aggregates\n\nTo evaluate models, we average zero-shot performance over diverse task aggregates Our aggregates are outlined in Table 3:\n\n- small : small-scale ablation studies, taskswith non-zero performance for 1B parameters models trained on 30GT;\n- core : comparisons with a wide range of models, notably based on the tasks reported in (Dey et al., 2023);\n- main : tasks available in the GPT-3 and PaLM papers (Brown et al., 2020; Chowdhery et al., 2022);\n- ext : tasks available in the work of the BigScience Architecture and Scaling group (Scao et al., 2022b).\n\nWhen comparing with models from the state-of-the-art, we source results from a few different papers, detailed in Table 10.\n\n## F.2. Models\n\nWe compare against nearly 50 models across 10 series trained on a variety of curated corpora, presented in Table 11.\n\nCerebras-GPT with µ -parametrization. The Cerebras-GPT series (Dey et al., 2023) also comes in a smaller series, up to 2.7B parameters, following the recommendations of µ -parametrization (Yang et al., 2021). As we found the performance of this smaller series to be close to the main series of models (see Figure 8), and as it does not include models of a similar compute scale as the ones we compare to, we chose not to report it in our main figures.\n\nTable 10. We source evaluation results from a variety of papers across the literature, maximizing task coverage. Although most results come from the EAI Evaluation Harness (Gao et al., 2021), results from PaLM and GPT-3 are sourced from their respective papers. Note in Figure 1 that the results from the GPT-3 paper are still ahead of results obtained through the API with the EAI evaluation harness.\n\n| Models                                                                                                                                  | Aggregates reported                                                                                | Source of results                                                                                                                                                                                                                                       | EAI eval harness?     |\n|-----------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------|\n| Ours BS-A&S ∗ GPT-Neo ∗ PaLM † GPT-3 API ∗ GPT-3 † Aleph Alpha ∗ Cerebras-GPT ∗ FairSeq ∗ Pythia(-Dedup) ∗ OPT ∗ GPT-J ∗ GPT-NeoX 20B ∗ | main , core , ext main , core main , core main main , core main core core core core core core core | This paper Scao et al. (2022b) Scao et al. (2022b) Chowdhery et al. (2022) Scao et al. (2022b) Brown et al. (2020) Aleph Alpha (2023) Dey et al. (2023) Black et al. (2022) Dey et al. (2023) Dey et al. (2023) Black et al. (2022) Black et al. (2022) | ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ |\n\nPythia and deduplication. The Pythia series of models is available in two flavours: one trained on the vanilla version of The Pile, and another trained on a version deduplicated with MinHash. Performance between these two flavours was noted to minimally differ (Biderman et al., 2023); in Figure 9, we find the deduplicated version may be slightly ahead of the non-deduplicated one under our aggregate. The higher end of this improvement is broadly in line with our findings in Table 5. Nevertheless, a difference in our findings and theirs remain. We posit a few possible hypotheses:\n\n- Differences between curated and web data. It is possible that web data is more sensitive to duplicates. For instance, the most common duplicates in web data (e.g., spam) may be more detrimental than the most common duplicates in curated data. This suggests a qualitative component to deduplication that we have not studied in this work.\n- Differences in deduplication pipeline. Because Biderman et al. (2023) uses the MinHash settings from Lee et al. (2022), they are mostly identical to ours. However, we also apply exact deduplication: while their deduplication incurs a 30% reduction in size, our deduplication is more aggressive, resulting in a 45% reduction in size. This may explain why our results in Table 5 show a stronger gain from deduplication than theirs in Figure 9.\n- Differences in pretraining. Finally, we note that Biderman et al. (2023) chooses to perform a partial extra epoch on the deduplicated data to reach 300GT, while we always perform a single epoch. Their setting corresponds to a data-constrained scenario, which is more realistic for the curated data they study; for us, web data is plentiful, so deduplication never truly limits the size of the datasets we can use.\n\n## F.3. Datasets\n\nWe extend on Table 1 in Table 12, providing details on the filtering and deduplication strategies used across the litterature.\n\nFigure 8. µ -parametrization (Yang et al., 2021) slightly improves performance in the Cerebras-GPT series (Dey et al., 2023). Zero-shot performance on our core aggregate, gap between Cerebras-GPT with µ -param and without. Individual curves for per-task results and 1σ standard deviation across all tasks in the aggregate in transparent.\n\n<!-- image -->\n\nFigure 9. In our core aggregate, deduplication brings a small improvement to the Pythia suite (Biderman et al., 2023). Zero-shot performance on our core aggregate, gap between Pythia trained on the deduplicated and vanilla Pile. Individual curves for per-task results and 1σ standard deviation across all tasks in the aggregate in transparent.\n\n<!-- image -->\n\nTable 11. Full-scale models trained on RefinedWeb (Falcon-RW) and other models from the state-of-the-art. Across models trained on The Pile, the Pythia models are the closest to our achitecture: they use FlashAttention with rotary embeddings-with for only notably exception the use of parallel attention and feedforward for their models. Training budget C in PF-days calculated using C = 6 ND , with N the number of parameters, and D the pretraining dataset size (Kaplan et al., 2020).\n\n| Series      | GPT-3 (paper) †   | GPT-3 (paper) †     | GPT-3 (API) ∗       | GPT-3 (API) ∗   | BigScience ∗        | PaLM †                  | Ours        | Ours       | Ours      |\n|-------------|-------------------|---------------------|---------------------|-----------------|---------------------|-------------------------|-------------|------------|-----------|\n| Model       | XL                | XXL                 | babbage             | curie           | BS-A&S              | PaLM-8B                 | Ours (Pile) | Falcon-RW  | Falcon-RW |\n| Dataset     | GPT-3             | GPT-3               | GPT-3               | GPT-3           | Pile                | PaLM                    | Pile        | RW         | RW        |\n| Params.     | 1.3B              | 6.7B                | 1.3B                | 6.7B            | 1.3B                | 8.6B                    | 1.3B        | 1.3B       | 7.5B      |\n| Pretraining | 300GT             | 300GT               | 300GT               | 300GT           | 300GT               | 780GT                   | 350GT       | 350GT      | 350GT     |\n| PF-days     | 27                | 140                 | 27                  | 140             | 27                  | 466                     | 32          | 32         | 182       |\n| Citation    |                   | Brown et al. (2020) | Brown et al. (2020) |                 | Scao et al. (2022b) | Chowdhery et al. (2022) |             | This paper |           |\n\n| Series                                 | EleutherAI                 | ∗                                      |                                              | Pythia ∗                                                   |\n|----------------------------------------|----------------------------|----------------------------------------|----------------------------------------------|------------------------------------------------------------|\n| Model Dataset Params. PF-days Citation | GPT-Neo Pile 1.3B 380GT 34 | GPT-J Pile 6.7B 402GT 187 &Komatsuzaki | GPT-NeoX 20B Pile 20B 472GT 656 Black et al. | Pythia(-Dedup) Pile (dedup) 70M-12B 300GT 1.5 - 250 et al. |\n| Pretraining                            |                            |                                        |                                              |                                                            |\n|                                        | Black et al. (2021)        | Wang (2021)                            | (2022)                                       | Biderman (2023)                                            |\n\n| Series                                             | Aleph Alpha ∗                                         | Cerebras-GPT ∗                                                    | OPT ∗                                                                      | FairSeq ∗                                                      |\n|----------------------------------------------------|-------------------------------------------------------|-------------------------------------------------------------------|----------------------------------------------------------------------------|----------------------------------------------------------------|\n| Model Dataset Params. Pretraining PF-days Citation | Luminous undisclosed 13B 400GT 361 Aleph Alpha (2023) | Cerebras-GPT Pile 111M-13B 2 - 257GT 0.02 - 232 Dey et al. (2023) | OPT Pile (subset) + curated 125M - 175B 300GT 3 - 3646 Zhang et al. (2022) | FairSeq curated 1.3 - 13B 300GT 27 - 271 Artetxe et al. (2021) |\n\nTable 12. Common massive web-scrape and LLM English datasets. Datasets such as OSCAR and C4 also have significant multilingual versions, which have enjoyed wide adoption (Xue et al., 2021). For OSCAR, the size corresponds to the non-deduplicated version, and is estimated from the number of words x0,75 (average number of words per tokens).\n\n| Deduplication                                                                                                                                                     | Exact : three sentences span (optional) Exact : per line ( ∼ 55% removed) NSFW (optional) Ex- act : per line   | Fuzzy : min- hash with 10 hashes ( ∼ 10% removed) Fuzzy : min- hash with 10 hashes, sim. treshold 0.5 ( ∼ 26% re- moved)                        | Exact &fuzzy : exact docu- ments, minhash w/ sim. treshold 0.8 Unknown   |\n|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------|\n| Content filtering Rules-based: code, NSFW None                                                                                                                    | Optional blocklist fastText trained on HQ-data fastText on cu- rated crawl                                     | SafeSearch                                                                                                                                      | ML-based filter on HQ data                                               |\n| Heuristics Document and line-level Line < 100 characters Line-level, optional document-level                                                                      | Unknown                                                                                                        | None Document- level                                                                                                                            | Document- level                                                          |\n| Language ID Document- level w/ langdetect Line-level w/ fastText (Joulin et al., 2016) Document- level w/ fast- Text (Joulin et al., 2016)                        | Unknown Document- level w/ pycld2 (Sites, 2013)                                                                | Unknown                                                                                                                                         | Unknown                                                                  |\n| data HTML extraction MASSIVE WEB DATASETS % .WET files % .WET files % .WET files                                                                                  | CURATED DATASETS Unknown jusText (Pomik´ alek, 2011)                                                           | Custom                                                                                                                                          | Unknown OURS                                                             |\n| Web Web 100 100                                                                                                                                                   | 100 60 %                                                                                                       | 18 % 48 %                                                                                                                                       | 27 %                                                                     |\n| Availability Public Public Public                                                                                                                                 | Private                                                                                                        | Public Private                                                                                                                                  | Private                                                                  |\n| models Size ∼ 360 GT ∼ 370 GT ∼ 283 GT                                                                                                                            | 300 GT ∼ 340 GT                                                                                                | Pythia 1 , 400 GT                                                                                                                               | 780 GT                                                                   |\n| General information Dataset Notable C4 (Raffel et al., 2020) T5 (Raffel et al., 2020) OSCAR 21.09 (Ortiz Su´ arez et al., 2019) OSCAR 22.01 (Abadji et al., 2022) | ■ GPT-3 (Brown et al., 2020) The Pile et al., GPT-J (Wang& Komatsuzaki, 2021), GPT- NeoX-20B (Black et al.,    | ▼ (Gao 2020) 2022), (Biderman et al., 2023), Cerebras-GPT (Dey et al., 2023) al., Gopher (Rae et al., 2021), Chinchilla (Hoffmann et al., 2022) | MassiveWeb (Rae et 2021) ⋆ PaLM (Chowdhery et al., 2022)                 |\n\n## G. Details of the Macrodata Refinement pipeline\n\n## G.1. URL filtering\n\nAs discussed in Section 3.1, we base our filtering of adult documents only on the URL itself, and not on the content of the documents. This design choice was motivated by: (1) challenges in avoiding overfiltering content from minorities when using ML-based classifiers on the content of documents (Welbl et al., 2021); (2) NSFW words block-list applied on content (such as the one used in C4) also resulting in overfiltering of legal and medical content (Dodge et al., 2021).\n\nOur URL filtering focuses on finding domains that are related to adult content, that may be harmful to users, or that are very likely to contain mostly unstructured text/spam (e.g., file hosting websites). First, we aggregated a list of 4.6M domains, detailed in Appendix G.1.1, that we explicitly ban; then, we built a simple URL scoring system, based on matching subwords in the URL against a list of words we curated (see Appendix G.1.2). We curated this list of words based on manual inspection, cross-referencing results with pages surfaced by ToxicBERT as being outliers in toxicity (Hanu &amp; Unitary team, 2020).\n\n## G.1.1. URL BLOCKLIST\n\nOrigin of the list. We use an aggregated list † of about 4.6M URLs that we explicitly ban. This list is broken in categories (e.g. pornography, gambling); we outline the categories we selected in Table 13. The list is regularly updated, with an original intended usage as a blocklist for universities.\n\nCuration. We noticed the list blocked a number of domains inappropriately; while these domains were few ( &lt; 100), they accounted for a significant portion of the data filtered by the list, as these were rather prolific domains, with thousands of pages of content. To identify these false positive domains, we applied the blocklist to a subset of 832M pages. 6.04M ( 0 . 73% ) pages matched with the blocklist, and the number of occurrences per URL ranged from 1 to 79k. We manually inspected all URLs matched more than 4k times, which represented an appreciable portion of the dataset. We found a number of benign domains, such as pop culture news websites, or blogging platforms, which we removed from the list.\n\nTable 13. We select categories likely to contain adult or malicious content, as well as spam or unstructured text.\n\n| Category    | Description                                        |   Number of links |\n|-------------|----------------------------------------------------|-------------------|\n| adult       | adult websites: from eroticism to hard pornography |           4516478 |\n| phishing    | phishing websites, malwares, etc.                  |             42445 |\n| dating      | dating websites                                    |              3829 |\n| gambling    | online casino                                      |              1365 |\n| filehosting | websites hosting files, videos, pictures, music    |               909 |\n| ddos        | websites related to ddos attacks                   |               421 |\n| agressif    | hate, racism, etc                                  |               390 |\n| chat        | online chat websites                               |               244 |\n| mixed adult | websites with some adult content                   |               153 |\n| arjel       | French regulated gambling websites                 |                69 |\n\n## G.1.2. URL SCORING WITH A WORD-LIST\n\nTo score URLs, we used three matching patterns based on a soft, hard, and strict violation word-list:\n\n- Strict subword matching : http://foobann.edsub-wo.rdbar.com/any/bar, matching words such as xvideos , groupsex ;\n- Hard whole word matching : http://www.foo.bannedword-bar.com, with words such as porn , xxx , orgy ;\n- Soft words matching : http://www.foo.soft1-bar-soft2.com, with 'softer' words such as sex , webcam , escort .\n\nEach list is associated with a different level of severity: for the strictest one (strict subword matching), we ban any URL matching a banned word in its substrings (as fraudulent websites may attempt to escape similar recognition schemes by breaking-up adult keywords); for the hard whole word matching, we ban URLs with a whole word matching in the list; finally, a minimum of two matches are required with the soft word matching.\n\n† https://dsi.ut-capitole.fr/blacklists/\n\nWe curated the lists based on manual inspection of the data, informed by top hits reported by ToxicBERT. For the strict subword matching, we included words that were unequivocally related to adult content (e.g., groupsex ). We avoided partial unclear matches (e.g., ass ), that may be part of neutral words (e.g., massachusetts ). In the soft word list, we included words that do not constitute a sufficient reason to discard the document on their own, but which are suspicious when multiple words from the list result in a match. This helped with keeping medical or legal content unaffected (e.g., a single match of dick ).\n\n## G.1.3. EXCLUDED HIGH QUALITY SOURCES\n\nSince our paper focuses on the study of RefinedWeb alone, we chose to exclude common online sources of curated data from it. This serves two objectives: (1) it strengthens our results, by ensuring that RefinedWeb doesn't end-up actually being made mostly of known high-quality sources (e.g., Wikipedia represents a significant portion of C4); (2) future works may be interested in combining RefinedWeb with existing curated copora, which would require further deduplication if they are included in RefinedWeb. Accordingly, we remove common sources used in The Pile (Gao et al., 2020) from RefinedWeb. The full list of curated data sources domains that we blocked is in Table 14.\n\nTable 14. RefinedWeb is stripped from common so-called high-quality sources to simplify combining it with existing curated corpora . This blocklist is applied at the URL filtering stage, along with the adult content blocklist.\n\n| Curated data source   | Domain name blocked                                                |\n|-----------------------|--------------------------------------------------------------------|\n| arxiv                 | arxiv.org                                                          |\n| AskUbuntu             | askubuntu.com                                                      |\n| StackOverflow         | stackoverflow.com stackapps.com stackexchange.com mathoverflow.net |\n| NIH Abstracts         | exporter.nih.gov ncbi.nlm.nih.gov                                  |\n| Github                | github.com                                                         |\n| Ubuntu IRC            | irclogs.ubuntu.com                                                 |\n| HackerNews            | news.ycombinator.com                                               |\n| FreeLaw               | courtlistener.com                                                  |\n| Reddit                | reddit.com                                                         |\n| Europarl              | statmt.org                                                         |\n| United States Patents | uspto.gov                                                          |\n| Wikipedia             | wikipedia.org                                                      |\n\n## G.2. Line-wise filtering\n\nDespite the improvements brought forth by running text extraction with Trafilatura, we found that a number of irrelevant lines still seeped through. These lines are usually related to navigation menus, call to actions, or social media counters. Following manual inspection of the data, we devised a line-wise filtering strategy. We analyse documents line-by-line, and discard or edit the lines based on the following rules:\n\n- If it is mainly composed of uppercase characters (discard);\n- If it is only composed of numerical characters (discard);\n- If it is a counter (e.g. 3 likes ) (discard);\n- If it only contains one word (discard);\n- If it is short ( ≤ 10 words) and matches a pattern (edit):\n- -At the beginning of the line (e.g. sign-in );\n- -At the end of the line (e.g. Read more... );\n- -Anywhere in the line (e.g. items in cart ).\n\nFinally, if the words in the flagged lines represent more than 5% of the total document words, the document is discarded. We derived these filters through manual inspection of the data, and note that they require adaptation across languages.\n\n## G.3. Deduplication\n\nWe make use of the two deduplication methods described in Lee et al. (2022): EXACTSUBSTR and NEARDEDUP (detailed in Appendix G.3.1 and Appendix G.3.2; see Appendix H for samples of duplicates).\n\nWe start with the most scalable approach, NEARDEDUP. We remove similar documents by applying MinHash (Broder, 1997), whereby a signature/sketch supporting efficient approximate similarity queries is computed for each document in the dataset, and document pairs with a high n -gram overlap are identified.\n\nWe then use EXACTSUBSTR, leveraging the implementation from Lee et al. (2022) ‡ , to identify ranges of exact duplicate text of at least 50 tokens. We experiment with three different approaches for these ranges: EXACTSUBSTR-CUT, where we remove them from the original text, as done in the original implementation; EXACTSUBSTR-MASK, where the dataset is unchanged but we do not compute the loss on the duplicated ranges; and EXACTSUBSTR-DROP, where we simply drop an entire document if the duplicated ranges make up more than a certain percentage of its content.\n\nWe present small-scale ablations around these different approaches in Appendix E.1.\n\n## G.3.1. MINHASH APPROXIMATE MATCHING\n\nWe employ MinHash to find approximate duplicate documents in our web corpora at a very large scale. This technique allows us to identify templated pages or otherwise very similar content where most of the interspersed duplicated sections are small enough to not be identified by exact matching methods (anything smaller than 50 tokens).\n\nSigning. We start by normalizing the content to increase recall: punctuation is removed, text is lowercased, NFD Unicode normalization is applied, accents are removed, and all whitespace is normalized. We tokenize the resulting text using the GPT-2 tokenizer (Radford et al., 2019) and obtain the set of unique n -grams for each document. Hash functions are used to obtain a signature for each document: for each hash function, the smallest value is kept from hashing every unique n -gram in the document. If two documents are similar, then there is a high probability that they will have the same minimum hash (MinHash) for at least some of the hash functions used (Broder, 1997). The ratio of matching hashes between two documents approximates the Jaccard Similarity (Jaccard, 1912) of the sets of their unique n -grams (the sets being d i and d j ):\n\n<!-- formula-not-decoded -->\n\nMatching. Since comparing MinHash signatures between every possible document pair is computationally expensive, we apply a locality sensitive hashing version of MinHash, MinHash LSH. A document signature is split into r buckets, each with b minhashes. Documents are indexed by these b minhashes on each of the r buckets, and we mark two documents as duplicates if their b minhashes are exactly the same on at least one of the buckets. These two parameters, b and r , will determine the probability that similar documents will be detected. For two documents i and j whose ratio of matching hashes between their MinHash signatures is s i,j , the probability that there is a match in a given bucket is s b i,j ; the probability that there isn't a match in any of the buckets is (1 -s b i,j ) r ; and finally that there is a match in at least one of the buckets:\n\n<!-- formula-not-decoded -->\n\nWe use the same parameters as Lee et al. (2022): n = 5 ( 5 -grams); b = 20 and r = 450 . This means that for each document, we compute a total of 9000 minhashes, and that the probability that a document pair with similarity 0.75 or 0.8 will be marked as duplicates will be 76% and 99 . 4% (respectively), diminishing rapidly for smaller similarity values.\n\nFinally, we cluster documents across all buckets - if documents A and B match in one bucket and B and C in another, A-B-C becomes a cluster. We randomly remove all but one of the documents in each cluster.\n\nLee et al. (2022) also proposed filtering down on false positives by computing the real Jaccard similarity, or other metrics such as the edit similarity between identified document pairs. Given the large amount of data we have available across all of CommonCrawl, and that our main concern is improving recall, we decided to skip this additional step.\n\n‡ https://github.com/google-research/deduplicate-text-datasets\n\n## G.3.2. EXACT SUBSTRING DEDUPLICATION\n\nWe make use of the EXACTSUBSTR implementation publicly released by Lee et al. (2022) for exact text matching. We apply exact substring deduplication to data that has already been deduplicated by MinHash, reducing by nearly 40% size of the dataset on which we have to operate. EXACTSUBSTR will find long strings of text that are present, character for character, across multiple documents. Some of these may have escaped the earlier stage of approximate deduplication: they might not constitute a big enough portion of the document; one document might have repeated sections sourced across many different documents; or they may simply not have been found due to the approximate nature of MinHash.\n\nFinding duplicates. EXACTSUBSTR concatenates all the documents in the dataset to create a single long text sequence; then, it builds a suffix array (Manber &amp; Myers, 1993) in linear time-an array of the indexes to a lexicographical ordering of all the suffixes in the sequence. Finally, duplicate sequences can also be found in linear time using the suffix array, by simply traversing the ordered list of suffixes and comparing the beginning of each pair of two consecutive suffixes.\n\nWe apply the same normalization and tokenization as for MinHash to the content of our documents before concatenating them. One important difference is that reversibility is important: for MinHash, we were discarding entire documents, and thus never relying on the normalized+tokenized representation for downstream use. Here, once we have identified duplicate normalized+tokenized spans, we need to revert to the original span to remove it. Accordingly, we include normalization in the tokenization process, and validate that the process is reversible.\n\nIf a match is longer than 50 tokens, there will be multiple overlapping duplicated ranges. These overlapping duplicated ranges in the concatenated dataset sequence are merged before we save them to a file. We then take these ranges and retrieve the original document that produced them, obtaining the character substrings corresponding to the duplicated token ranges.\n\nRemoving duplicates. We considered applying the following transformations to the duplicate spans:\n\n- EXACTSUBSTR-CUT: we remove the duplicated spans, and discard documents where there are fewer than 20 nonduplicated characters left-this is the vanilla setting used by Lee et al. (2022);\n- EXACTSUBSTR-MASK: we loss-mask the duplicated spans, preventing a loss from being computed on the duplicated text during pretraining, and discard documents where there are fewer than 20 non-masked characters left.\n- EXACTSUBSTR-DROPPARTIAL: if more than 20% of the document is duplicated, we remove the entire document;\n- EXACTSUBSTR-DROPANY: we drop any document with a duplicated span in it.\n\nBroadly speaking, EXACTSUBSTR-CUT might remove text mid-sentence resulting in disconnected text; EXACTSUBSTRMASK does not have this issue, but might be less efficient as a significant portion of the training tokens will not directly contribute to updating the model's weights; EXACTSUBSTR-DROP might still keep considerable duplicated sections in its PARTIAL version, especially on larger documents, while the ANY version might be overly aggressive. Following ablations in Appendix E.1, we choose to stick with the vanilla approach, EXACTSUBSTR-CUT.\n\nNote that in all cases, while MinHash keeps one copy of the duplicated documents, our exact deduplication removes all copies of the duplicated span.\n\n## G.4. Execution environment\n\nMost data processing took place in large CPU clusters, with 100-250 AWS c5.18xlarge instances; each instance has 72 vCPUs and 144 GiB of memory. We usually run with 10,000-20,000 vCPUs in the cluster, enabling rapid parallel processing.\n\nFor EXACTSUBSTR, the entire dataset being deduplicated needs to be loaded onto memory: we leveraged the AWS x2iedn instances, which come with up to 2 TiB of memory in a single instance.\n\n## H. Deduplication samples from RefinedWeb\n\n## H.1. MinHash clusters\n\nWe report the 8 largest duplicate clusters found by MinHash in Table 15 - each spanning hundreds of thousands of documents. We also found a large number of duplicate document pairs to be due to different URL GET parameters not resulting in significantly different content. An example of this behaviour can be seen in the URLs presented in Table 16.\n\nTable 15. Top-8 largest MinHash clusters found when building RefinedWeb. We cut some of the longest samples in the interest of readability, only keeping a brief description.\n\n| Description                                                                                | Example document                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n|--------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Wordpress sitemap notice generated by the Google Sitemap Generator Plugin                  | This is a XML Sitemap which is supposed to be processed by search engines which follow the XML Sitemap standard like Ask.com, Bing, Google and Yahoo. It was generated using the WordPress content management system and the Google Sitemap Generator Plugin by Arne Brachhold. You can find more information about XMLsitemaps on sitemaps.org and Google's list of sitemap programs. This file contains links to sub-sitemaps, follow them to see the actual sitemap content.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n| Cloudflare notice to enable Javascript                                                     |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n| Templated disability notice, with different phone numbers across pages                     | Welcome to our website! As we have the ability to list over one million items on our website (our selection changes all of the time), it is not feasible for a company our size to record and playback the descriptions on every item on our website. However, if you are an American with a disability we are here to help you. Please call our disability services phone line at [redacted] or [redacted] during regular business hours and one of our kind and friendly personal shoppers will help you navigate through our website, help conduct advanced searches, help you choose the item you are looking for with the specifications you are seeking, read you the specifications of any item and consult with you about the products themselves. There is no charge for the help of this personal shopper for any American with a disability. Finally, your personal shopper will explain our Privacy Policy and Terms of Service, and help you place an order if you so desire. |\n| Templated cookies notice                                                                   |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n| Templated domain name for sale page                                                        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n| www.metoperashop.org and sub-URLs, with content changes but always the same (large) footer |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n| Different pages across more than 80 different domain names but with a common section       | DC Customers also liked: Special event items are produced by man- ufacturers only after the outcome of a game or event. These are advanced sale items and will ship immediately after they are received in our warehouse. Manufacturer direct items are shipped directly from the manufacturer. These items are not available for international or expedited shipping. Customized items can be personalized with options such as your name, your favorite number, and/or designs. Some options may be limited by league rules.                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| http://www.boxofficemojo.com/daily and sub- URLs                                           |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n\n## Table 16. URL with different GET parameters don't always result in significantly different page content.\n\n| http://gamesandbiz.blogspot.com/2010/ 07/bad-reviews-can-hurt-game-sales.ht ml?showComment=1278486430242                                                                                                                                                                                | http://gamesandbiz.blogspot.com/2010/ 07/bad-reviews-can-hurt-game-sales.ht ml?showComment=1278499674195                                                                                                                                   |\n|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| https://www.ocean-oxygen.org/home;jse ssionid=1E3290E84F668552FAC643D0A8F81 BEC?p_p_id=122_INSTANCE_Zy6zjkRLAg7v& p_p_lifecycle=0&p_p_state=normal&p_p_ mode=view&p_p_col_id=column-2&p_p_col _pos=1&p_p_col_count=6&p_r_p_56423352 4_resetCur=true&p_r_p_564233524_categ oryId=1346016 | https://www.ocean-oxygen.org/home?p_p _id=122_INSTANCE_Zy6zjkRLAg7v&p_p_lif ecycle=0&p_p_state=normal&p_p_mode=vi ew&p_p_col_id=column-2&p_p_col_pos=1& p_p_col_count=6&p_r_p_564233524_reset Cur=true&p_r_p_564233524_categoryId=1 346016 |\n\n## H.2. Exact substring matches\n\nExamples of exact matches found by exact substring deduplication can be seen in Table 17.\n\nTable 17. Matches found by exact substring deduplication (in italics ).\n\n| it appears there is a transfer of ranking signals in this rela- tionship. Supporting this finding is a quote from Google's guidelines: Using JavaScript to redirect users can be a legitimate practice. For example, if you redirect users to an internal page once they're logged in, you can use JavaScript to do so. When examining JavaScript or other redirect meth- ods to ensure your site adheres to our guidelines, consider the intent. Keep in mind that 301 redirects are best when moving your site, but you could use a JavaScript redirect for this purpose if you don't have access to your website's server. NOTE: Their experiment is based on a live page with status code 200 and NOT an inactive page. So if you want to implement this for legacy   | Some examples of sneaky redirects include: - Search en- gines shown one type of content while users are redirected to something significantly different. - Desktop users receive a normal page, while mobile users are redirected to a com- pletely different spam domain. Using JavaScript to redirect users can be a legitimate practice. For example, if you redi- rect users to an internal page once they're logged in, you can use JavaScript to do so. When examining JavaScript or other redirect methods to ensure your site adheres to our guidelines, consider the intent. Keep in mind that 301 redirects are best when moving your site, but you could use a JavaScript redirect for this purpose if you don't have access to your website's server.   |\n|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Find Palm Beache FL homes for sale and other Palm Beach real estate on homesofthepalmbeaches.com. Browse and search Palm Beach houses, condos, townhomes and single- family homes by community , building, or location. Our extensive database of real estate listings provide the most comprehensive property details including home values, fea- tures and local school and neighborhood info so you can be sure that you have nearly all the facts you need upfront. Search homesofthepalmbeaches.com today! Want a closer look at what other Palm Beach properties are available?                                                                                                                                                                                     | Search Stuart houses, condos, townhomes and single-family homes by price and location. Our extensive database of real estate listings provide the most comprehensive property details including home values, features and local school and neighborhood info so you can be sure that you have nearly all the facts you need upfront. Search Stuart Listings today! Want a closer look at what other Stuart properties are available? Also search our listings for the Newest Stuart Listings and Stuart Homes with Price Reductions now. Stu- art FL Homes for Sale - Stuart Real Estate Listings FREE to search Stuart Property                                                                                                                                    |\n| To find the correct size you should measure your foot from the heel to the toe point. Add approximately 1 - 1,5cm to get the actual inner sole length. Measure both feet and fit shoes to the larger foot. Measure feet at the end of the day, when your feet are at their largest. Lente shoes are women's easy slip-on leisure shoes for everyday use. These lightweight shoes have a breathable textile mesh upper made of recycled PET bottles and cool Lycra lining.                                                                                                                                                                                                                                                                                                 | To find the correct size you should measure your foot from the heel to the toe point. Add approximately 1 - 1,5cm to get the actual inner sole length. Measure both feet and fit shoes to the larger foot. Measure feet at the end of the day, when your feet are at their largest. Enjoy your summer days with Masera leisure sneakers. These low-cut women's sneakers are extremely lightweight thanks to phylon midsole and breathable textile mesh upper                                                                                                                                                                                                                                                                                                        |\n| This bandana makes the perfect addition to every fur babies birthday collection! With its sparkly crown pattern, your pup will be ready for every birthday celebration! With snaps for security, this bandana is made with love, down to the very last stitch ! Fabric: cotton Care Instructions: Hand wash only, iron as needed, on low heat Always supervise your pup while wearing Faithful Paws Co. accessories, as it could become a choking hazard if consumed.                                                                                                                                                                                                                                                                                                     | This bandana makes the perfect addition to every fur babies summer collection! With its vibrant watercolor popsicle pattern, your pup will be ready for every summer cook- out! With snaps for security, this bandana is made with love, down to the very last stitch ! Fabric: cotton Care Instructions: Hand wash only, iron as needed, on low heat Always supervise your pup while wearing Faithful Paws Co. accessories, as it could become a choking hazard if consumed.                                                                                                                                                                                                                                                                                       |",
  "tables": [
    {
      "index": 0,
      "markdown": "| Dataset                    | Size                       | Availability         | Web                  | CC Processing                                                                                             | Deduplication                                                                                                                 |\n|----------------------------|----------------------------|----------------------|----------------------|-----------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------|\n| MASSIVE WEB DATASETS       | MASSIVE WEB DATASETS       | MASSIVE WEB DATASETS | MASSIVE WEB DATASETS | MASSIVE WEB DATASETS                                                                                      | MASSIVE WEB DATASETS                                                                                                          |\n| C4 OSCAR-21.09 OSCAR-22.01 | ∼ 360 GT ∼ 370 GT ∼ 283 GT | Public Public Public | 100 % 100 % 100 %    | Rules + NSFW words blocklist Built at the line-level Line-level rules + optional rules &NSFWURL blocklist | Exact: spans of 3 sentences Exact : per line ( ∼ 55% removed) Exact : per line (optional, not used for results in this paper) |\n| CURATED DATASETS           | CURATED DATASETS           | CURATED DATASETS     | CURATED DATASETS     | CURATED DATASETS                                                                                          | CURATED DATASETS                                                                                                              |\n| ■ GPT-3                    | 300 GT                     | Private              | 60 %                 | Content filter trained on known high-quality sources                                                      | Fuzzy : MinHash ( ∼ 10% removed)                                                                                              |\n| ▼ The Pile                 | ∼ 340 GT                   | Public               | 18 %                 | jusText for extraction, con- tent filter trained on curated data                                          | Fuzzy : MinHash ( ∼ 26% removed)                                                                                              |\n| ⋆ PaLM                     | 780 GT                     | Private              | 27 %                 | Filter trained on HQ data                                                                                 | Unknown                                                                                                                       |\n| OURS                       | OURS                       | OURS                 | OURS                 | OURS                                                                                                      | OURS                                                                                                                          |\n| REFINEDWEB                 | ∼ 5 , 000 GT               | Public (600GT)       | 100%                 | trafilatura for text extrac- tion, document and line-level rules, NSFW URL blocklist                      | Exact & fuzzy : exact sub- string+MinHash ( ∼ 50% removed)                                                                    |"
    },
    {
      "index": 1,
      "markdown": "| DOCUMENT PREPARATION                                                        | DOCUMENT PREPARATION                                                 | FILTERING                                                                                 | FILTERING                                                                                 | FILTERING                                                                                          | DEDUPLICATION                                                                                       | DEDUPLICATION                                                  |\n|-----------------------------------------------------------------------------|----------------------------------------------------------------------|-------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------|----------------------------------------------------------------|\n| URL filtering                                                               | Text extraction                                                      | Language identification                                                                   | Document-wise filtering                                                                   | Line-wise filtering                                                                                | Deduplication                                                                                       | URL deduplication                                              |\n| Aggregated block- list, URL scoring, common HQ sources blocked Appendix G.1 | From WARC using warcio , trafilatura for extraction Barbaresi (2021) | fastText classi- fier from CCNet, thresholding on top language score Wenzek et al. (2020) | In-document repe- tition removal and quality heuristics from MassiveWeb Rae et al. (2021) | Remove undesirable lines (call to actions, navigation buttons, social counters, etc.) Appendix G.2 | Fuzzy deduplication w/ MinHash + exact substring deduplica- tion w/ suffix arrays Lee et al. (2022) | Remove URLs revis- ited across Common- Crawl dumps Section 3.3 |"
    },
    {
      "index": 2,
      "markdown": "| Tasks                                       | Type                               |   Random | small   | core   | main   | ext   |\n|---------------------------------------------|------------------------------------|----------|---------|--------|--------|-------|\n| HellaSwag (Zellers et al., 2019)            | Sentence completion                |     25   | ✓       | ✓      | ✓      | ✓     |\n| LAMBADA (Paperno et al., 2016)              | Sentence completion                |      0   |         | ✓      | ✓      | ✓     |\n| Winogrande (Sakaguchi et al., 2021)         | Coreference resolution             |     50   | ✓       | ✓      | ✓      | ✓     |\n| PIQA (Bisk et al., 2020)                    | Multiple-choice question answering |     50   | ✓       | ✓      | ✓      | ✓     |\n| ARC (Clark et al., 2018)                    | Natural language inference         |     25   | ✓       | ✓      | ✓      | ✓     |\n| OpenBookQA (Mihaylov et al., 2018)          | Multiple-choice question answering |     25   |         | ✓      | ✓      | ✓     |\n| BoolQ (Clark et al., 2019)                  | Multiple-choice question answering |     50   | ✓       |        | ✓      | ✓     |\n| COPA (Gordon et al., 2012)                  | Sentence completion                |     50   |         |        | ✓      | ✓     |\n| CB (De Marneffe et al., 2019)               | Natural language inference         |     33.3 |         |        | ✓      | ✓     |\n| RTE (Dagan et al., 2010)                    | Natural language inference         |     50   |         |        | ✓      | ✓     |\n| ReCoRD (Zhang et al., 2018)                 | Question answering                 |      0   |         |        | ✓      |       |\n| ANLI (Nie et al., 2019)                     | Natural language inference         |     33.3 |         |        | ✓      |       |\n| LogiQA (Liu et al., 2021)                   | Multiple-choice question answering |     25   |         |        |        | ✓     |\n| HeadQA (Vilares &G´ omez-Rodr´ ıguez, 2019) | Multiple-choice question answering |     20   |         |        |        | ✓     |\n| MathQA (Amini et al., 2019)                 | Multiple-choice question answering |     20   |         |        |        | ✓     |\n| PROST (Aroca-Ouellette et al., 2021)        | Paraphrase identification          |     50   |         |        |        | ✓     |\n| PubMedQA (Jin et al., 2019)                 | Multiple-choice question answering |     50   |         |        |        | ✓     |\n| SciQ (Welbl et al., 2017)                   | Multiple-choice question answering |     25   | ✓       |        |        | ✓     |"
    },
    {
      "index": 3,
      "markdown": "| MASSIVE WEB DATASETS   | MASSIVE WEB DATASETS   | MASSIVE WEB DATASETS   |       | CURATED    | OURS   |             |            |\n|------------------------|------------------------|------------------------|-------|------------|--------|-------------|------------|\n|                        | OSCAR-21.09            | OSCAR-22.01            | C4    | ▼ The Pile | RW-Raw | RW-Filtered | REFINEDWEB |\n| 1B@27GT                | 55.0%                  | 52.7%                  | 55.7% | 53.4%      | 52.7%  | 54.3%       | 56.2%      |\n| 3B@60GT                | 59.1%                  | 55.9%                  | 59.6% | 57.9%      | 57.4%  | 58.2%       | 59.8%      |"
    },
    {
      "index": 4,
      "markdown": "|              | MASSIVE WEB DATASETS   | MASSIVE WEB DATASETS   |             | CURATED      | OURS         |\n|--------------|------------------------|------------------------|-------------|--------------|--------------|\n|              | OSCAR-21.09            | OSCAR-22.01            | C4          | ▼ Pile       | RefinedWeb   |\n| Base         | 55.0%                  | 52.7%                  | 55.7%       | 53.4%        | 52.7%        |\n| Filtered     | 55.4% [+.4]            | 52.3% [-.4]            | 56.2% [+.5] | 54.2% [+.8]  | 54.3% [+1.6] |\n| removal rate | -25.0%                 | -39.8%                 | -16.4%      | -27.1%       | -50.8%       |\n| Deduplicated | 55.6% [+.6]            | 55.6% [+2.9]           | 55.9% [+.2] | 54.5% [+1.1] |              |\n| removal rate | -10.8%                 | -60.8%                 | -7.59%      | -45.3%       |              |\n| Filt.+Dedup. | 55.5% [+.5]            | 55.4% [+2.7]           | 56.4% [+.7] | 55.2% [+1.8] | 56.2% [+3.5] |\n| removal rate | -28.2%                 | -62.2%                 | -17.9%      | -66.0%       | -75.4%       |"
    },
    {
      "index": 5,
      "markdown": "| MOTIVATION                                                                                                                   | MOTIVATION                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n|------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| For what purpose was the dataset cre- ated?                                                                                  | RefinedWeb was created to serve as a large-scale dataset for the pretrain- ing of large language models. It may be used on its own, or augmented with curated sources (e.g., Wikipedia, StackOverflow).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n| Who created the dataset and on behalf of which entity?                                                                       | The dataset was created by the Technology Innovation Institute.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n| Who funded the creation of the dataset?                                                                                      | The creation of the dataset was privately funded by the Technology Innovation Institute.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| Any other comment?                                                                                                           | RefinedWeb is built on-top of CommonCrawl, using the Macrodata Re- finement Pipeline, which combines content extraction, filtering heuristics, and deduplication. In designing RefinedWeb, we abided to the following philosophy: (1) Scale first. We intend MDR to produce datasets to be used to train 40-200B parameters models, thus requiring trillions of tokens (Hoffmann et al., 2022). For English-only RefinedWeb, we target a size of 3-6 trillion tokens. Specifically, we eschew any labour inten- sive human curation process, and focus on CommonCrawl instead of disparate single-domain sources. (2) Strict deduplication. Inspired by the work of Lee et al. (2022), which demonstrated the value of deduplica- tion for large language models, we implement a rigorous deduplication pipeline. We combine both exact and fuzzy deduplication, and use strict settings leading to removal rates far higher than others have reported. (3) Neutral filtering. To avoid introducing further undesirable biases into the model (Dodge et al., 2021; Welbl et al., 2021), we avoid using ML-based filtering outside of language identification. We stick to simple rules and heuristics, and use only URL filtering for adult content. |\n| COMPOSITION                                                                                                                  | COMPOSITION                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n| What do the instances that comprise the dataset represent?                                                                   | Instances are text-only documents, corresponding to single web pages.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n| How many instances are there in total?                                                                                       | RefinedWeb contains ∼ 10 billion documents, or around 5 trillion tokens. The public version is a subset representing a tenth of the full version.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n| Does the dataset contain all possible in- stances or is it a sample (not necessarily random) of instances from a larger set? | RefinedWeb is built using all CommonCrawl dumps until the 2023-06 one; it could be updated with additional dumps as they are released. The public release of RefinedWeb is a 600GT random extract of the 5,000GT of the full dataset. For all experiments, we randomly sampled from the public extract, or earlier development versions of it.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n| What data does each instance consist of?                                                                                     | Each instance is a text-only document, with metadata about its origin in CommonCrawl and source page URL. We also distribute a multimodal version of RefinedWeb, containing interlaced links to images.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n| Is there a label or target associated with each instance?                                                                    | No.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n| Is any information missing from individ- ual instances?                                                                      | No.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n| Are relationships between individual in- stances made explicit?                                                              | No.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n| Are there recommended data splits?                                                                                           | No.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |"
    },
    {
      "index": 6,
      "markdown": "| Are there any errors, sources of noise, or redundancies in the dataset?                                                                 | Despite our best efforts to filter content that does not qualify as natural language, and to deduplicate documents, our pipeline may let through documents that may be considered as errors or redundant.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n|-----------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Is the dataset self-contained, or does it link to or otherwise rely on external re- sources?                                            | The base version of the dataset is self-contained, but the multimodal version is interlaced with links to images-these are not distributed as part of the dataset, and constitute an external source.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n| Does the dataset contain data that might be considered confidential?                                                                    | All documents in RefinedWeb have been publicly available online.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n| Does the dataset contain data that, if viewed directly, might be offensive, in- sulting, threatening, or might otherwise cause anxiety? | Yes, as this type of data is prevalent on the internet, it is likely our dataset contains such content. Notably, we estimate the prevalence of toxic content in the dataset to be similar to The Pile (Figure 4).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n| COLLECTION                                                                                                                              | COLLECTION                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n| How was the data associated with each instance acquired?                                                                                | We downloaded with warcio publicly available .WET files from the CommonCrawl foundation.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n| What mechanisms or procedures were used to collect the data?                                                                            | We refer to the CommonCrawl website ( commoncrawl.org ) for de- tails on how they collect data.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n| If the dataset is a sample from a larger set, what was the sampling strategy?                                                           | Whenever we use subsets, we randomly sample from the original data.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| Who was involved in the data collec- tion process and how were they compen- sated?                                                      | The original data collection was performed by CommonCrawl; authors from this paper were involved in retrieving it and preparing it.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| Over what timeframe was the data col- lected?                                                                                           | We use all CommonCrawl dumps from 2008 to January/February 2023.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n| Were any ethical review processes con- ducted?                                                                                          | No.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| PREPROCESSING                                                                                                                           | PREPROCESSING                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n| Was any preprocessing/cleaning/labeling of the data done?                                                                               | Yes, we applied extensive preprocessing and cleaning of the data. We first filter URLs to remove adult content using a blocklist and a score sys- tem (Appendix G.1), we then use trafilatura (Barbaresi, 2021) to extract content from pages, and perform language identification with the fastText classifier from CCNet (Wenzek et al., 2020). Af- ter this first preprocessing stage, we filter data using heuristics from MassiveWeb (Rae et al., 2021) and our own line-wise corrections (Ap- pendix G.2). Finally, we run extensive deduplication, removing URLs revisited across dumps (Section 3.3) and performing subsequently fuzzy and exact substring deduplication, with each stage drawing from Lee et al. (2022). See Section 3 for further details and Table 2 for an outline. |\n| Was the 'raw' data saved in addition to the preprocessed/cleaned/labeled data?                                                          | During development, we saved intermediary outputs from our pipeline for investigations and for ablations-intermediary outputs exist for about 5% of RefinedWeb. We did not keep intermediary outputs for the final production version of the dataset due to storage and resource constraints.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n| Is the software that was used to prepro- cess/clean/label the data available?                                                           | No.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| USES                                                                                                                                    | USES                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n| Has the dataset been used for any tasks already?                                                                                        | Yes, this data has been used to develop large language models: both for scientific experiments (e.g., this paper) and production use.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |"
    },
    {
      "index": 7,
      "markdown": "| Is there a repository that links to any or all papers or systems that use the dataset?                                                               | No.                                                                                                                                                        |\n|------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| What (other) tasks could the dataset be used for?                                                                                                    | RefinedWeb was built as a large-scale corpora representative of the web, and as such may see many downstream uses which are difficult to predict.          |\n| Is there anything about the composition of the dataset or the way it was col- lected and preprocessed/cleaned/labeled that might impact future uses? | For the public extract of RefinedWeb, we chose to only draw from the English version of the dataset, preventing multilingual applications.                 |\n| Are there tasks for which the dataset should not be used?                                                                                            | Any tasks which may considered irresponsible or harmful.                                                                                                   |\n| DISTRIBUTION                                                                                                                                         | DISTRIBUTION                                                                                                                                               |\n| Will the dataset be distributed to third parties outside of the entity on behalf of which the dataset was created?                                   | Yes, we make a 600GT extract publicly available for NLP practitioners. We currently don't plan to share the full version of the dataset.                   |\n| How will the dataset will be distributed?                                                                                                            | The dataset will be made available through the HuggingFace Hub.                                                                                            |\n| When will the dataset be distributed?                                                                                                                | The dataset is available immediately.                                                                                                                      |\n| Will the dataset be distributed under a copyright or other intellectual prop- erty (IP) license, and/or under applicable terms of use (ToU)?         | The public extract is made available under an ODC-By 1.0 license; users should also abide to the CommonCrawl ToU: https:// commoncrawl.org/terms-of-use/ . |\n| Have any third parties imposed IP-based or other restrictions on the data associ- ated with the instances?                                           | Not to our knowledge.                                                                                                                                      |\n| Do any export controls or other regula- tory restrictions apply to the dataset or to individual instances?                                           | Not to our knowledge.                                                                                                                                      |\n| MAINTENANCE                                                                                                                                          | MAINTENANCE                                                                                                                                                |\n| Who will be support- ing/hosting/maintaining the dataset?                                                                                            | The dataset will be hosted on the HuggingFace Hub, we have no plans to further support or maintain it once it is released.                                 |\n| How can the owner/curator/manager of the dataset be contacted?                                                                                       | falconllm@tii.ae                                                                                                                                           |\n| Is there an erratum?                                                                                                                                 | No.                                                                                                                                                        |\n| Will the dataset be updated?                                                                                                                         | No.                                                                                                                                                        |\n| If others want to extend/augment/build on/contribute to the dataset, is there a mechanism for them to do so?                                         | No.                                                                                                                                                        |"
    },
    {
      "index": 8,
      "markdown": "| MODEL DETAILS                                 | MODEL DETAILS                                 | MODEL DETAILS                                 | MODEL DETAILS                                                                                                                                                                                                                                                                                                                                                                |\n|-----------------------------------------------|-----------------------------------------------|-----------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Person/organization model                     | developing                                    | the                                           | The models were created by the Technology Innovation Institute.                                                                                                                                                                                                                                                                                                              |\n| Model date                                    | Model date                                    | Model date                                    | Falcon-RW models were trained in December 2022/January 2023.                                                                                                                                                                                                                                                                                                                 |\n| Model type and information about train- ing   | Model type and information about train- ing   | Model type and information about train- ing   | Falcon-RW are autoregressive Transformer models trained with a causal language modeling objective. Architecture based on GPT-3 (Brown et al., 2020), with ALiBi positional encodings (Press et al., 2021) and FlashAt- tention (Dao et al., 2022). See Section 4.1 for details.                                                                                              |\n| Licence                                       | Licence                                       | Licence                                       | Apache 2.0: https://www.apache.org/licenses/ LICENSE-2.0 .                                                                                                                                                                                                                                                                                                                   |\n| Point of contact                              | Point of contact                              | Point of contact                              | falconllm@tii.ae                                                                                                                                                                                                                                                                                                                                                             |\n| INTENDED USE                                  | INTENDED USE                                  | INTENDED USE                                  | INTENDED USE                                                                                                                                                                                                                                                                                                                                                                 |\n| Primary intended uses                         | Primary intended uses                         | Primary intended uses                         | Research on large language models, and the influence of adequately filtered and deduplicated web data on the properties of large language models (fairness, safety, limitations, capabilities, etc.).                                                                                                                                                                        |\n| Primary intended users                        | Primary intended users                        | Primary intended users                        | NLP researchers.                                                                                                                                                                                                                                                                                                                                                             |\n| Out-of-scope use cases                        | Out-of-scope use cases                        | Out-of-scope use cases                        | Production use without adequate assessment of risks and mitigation; any use cases which may be considered irresponsible or harmful.                                                                                                                                                                                                                                          |\n| FACTORS                                       | FACTORS                                       | FACTORS                                       | FACTORS                                                                                                                                                                                                                                                                                                                                                                      |\n| Relevant factors                              | Relevant factors                              | Relevant factors                              | Falcon-RW models are trained on English data only, and will not gener- alize appropriately to other languages. Furthermore, as they are trained on a large-scale corpora representative of the web, they will carry the stereotypes and biases commonly encountered online.                                                                                                  |\n| Evaluation factors                            | Evaluation factors                            | Evaluation factors                            | We evaluated the toxicity of the underlying pretraining dataset and found it to be in line with common curated pretraining datasets such as The Pile (see Figure 4). Note that this only accounts for toxicity under the definition of Perspective API: 'content that is rude or disrespectful'. Notably, this fails to include concerns about social biases or harmfulness. |\n| METRICS                                       | METRICS                                       | METRICS                                       | METRICS                                                                                                                                                                                                                                                                                                                                                                      |\n| Model performance measures                    | Model performance measures                    | Model performance measures                    | We focus our evaluation on measuring the zero-shot generalization ca- pabilities of our models across a wide range of tasks, leveraging the Eleuther AI language model evaluation harness (Gao et al., 2021).                                                                                                                                                                |\n| Variation approaches                          | Variation approaches                          | Variation approaches                          | Due to the costs associated with training Falcon-RW we cannot train the models multiple times and measure variability across training runs.                                                                                                                                                                                                                                  |\n| EVALUATION DATA                               | EVALUATION DATA                               | EVALUATION DATA                               | EVALUATION DATA                                                                                                                                                                                                                                                                                                                                                              |\n| Datasets                                      | Datasets                                      | Datasets                                      | We evaluate zero-shot accuracy on 18 varied tasks, detailed in Table 3.                                                                                                                                                                                                                                                                                                      |\n| Motivation                                    | Motivation                                    | Motivation                                    | Weselected and aggregated tasks to build comparisons with other models in the literature (see Section 4.1; Appendix F.1 for details).                                                                                                                                                                                                                                        |\n| Preprocessing                                 | Preprocessing                                 | Preprocessing                                 | We use the default prompts and setup of Gao et al. (2021).                                                                                                                                                                                                                                                                                                                   |\n| TRAINING DATA dedicated datasheet in Table 6. | TRAINING DATA dedicated datasheet in Table 6. | TRAINING DATA dedicated datasheet in Table 6. | TRAINING DATA dedicated datasheet in Table 6.                                                                                                                                                                                                                                                                                                                                |"
    },
    {
      "index": 9,
      "markdown": "| Minhash             | Exact substring     |   pile-bpb ↓ |   agg-dev-1 ↑ |\n|---------------------|---------------------|--------------|---------------|\n| RefinedWeb-Filtered | RefinedWeb-Filtered |         1.11 |         43.51 |\n| ✓ ✓ ✓ ✓ ✓           | Mask                |         1.08 |         45.84 |\n| ✓ ✓ ✓ ✓ ✓           | Mask                |         1.07 |         46.28 |\n| ✓ ✓ ✓ ✓ ✓           |                     |         1.07 |         46.57 |\n| ✓ ✓ ✓ ✓ ✓           | Cut                 |         1.05 |         47.11 |\n| ✓ ✓ ✓ ✓ ✓           | Cut                 |         1.06 |         47.24 |\n| ✓ ✓ ✓ ✓ ✓           | Drop partial        |         1.05 |         47.25 |\n| ✓ ✓ ✓ ✓ ✓           | Drop any            |         1.07 |         47.77 |\n| ✓ ✓ ✓ ✓ ✓           | Drop any            |         1.07 |         47.86 |\n| ✓ ✓ ✓ ✓ ✓           | Drop partial        |         1.06 |         47.97 |\n|                     | Pile                |         0.88 |         43.7  |"
    },
    {
      "index": 10,
      "markdown": "| Model size Dataset   |   1B The Pile |   RW |   7B RW |\n|----------------------|---------------|------|---------|\n| wiki-bpb ↓           |          0.64 | 0.66 |     0.6 |"
    },
    {
      "index": 11,
      "markdown": "| Models                                                                                                                                  | Aggregates reported                                                                                | Source of results                                                                                                                                                                                                                                       | EAI eval harness?     |\n|-----------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------|\n| Ours BS-A&S ∗ GPT-Neo ∗ PaLM † GPT-3 API ∗ GPT-3 † Aleph Alpha ∗ Cerebras-GPT ∗ FairSeq ∗ Pythia(-Dedup) ∗ OPT ∗ GPT-J ∗ GPT-NeoX 20B ∗ | main , core , ext main , core main , core main main , core main core core core core core core core | This paper Scao et al. (2022b) Scao et al. (2022b) Chowdhery et al. (2022) Scao et al. (2022b) Brown et al. (2020) Aleph Alpha (2023) Dey et al. (2023) Black et al. (2022) Dey et al. (2023) Dey et al. (2023) Black et al. (2022) Black et al. (2022) | ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ |"
    },
    {
      "index": 12,
      "markdown": "| Series      | GPT-3 (paper) †   | GPT-3 (paper) †     | GPT-3 (API) ∗       | GPT-3 (API) ∗   | BigScience ∗        | PaLM †                  | Ours        | Ours       | Ours      |\n|-------------|-------------------|---------------------|---------------------|-----------------|---------------------|-------------------------|-------------|------------|-----------|\n| Model       | XL                | XXL                 | babbage             | curie           | BS-A&S              | PaLM-8B                 | Ours (Pile) | Falcon-RW  | Falcon-RW |\n| Dataset     | GPT-3             | GPT-3               | GPT-3               | GPT-3           | Pile                | PaLM                    | Pile        | RW         | RW        |\n| Params.     | 1.3B              | 6.7B                | 1.3B                | 6.7B            | 1.3B                | 8.6B                    | 1.3B        | 1.3B       | 7.5B      |\n| Pretraining | 300GT             | 300GT               | 300GT               | 300GT           | 300GT               | 780GT                   | 350GT       | 350GT      | 350GT     |\n| PF-days     | 27                | 140                 | 27                  | 140             | 27                  | 466                     | 32          | 32         | 182       |\n| Citation    |                   | Brown et al. (2020) | Brown et al. (2020) |                 | Scao et al. (2022b) | Chowdhery et al. (2022) |             | This paper |           |"
    },
    {
      "index": 13,
      "markdown": "| Series                                 | EleutherAI                 | ∗                                      |                                              | Pythia ∗                                                   |\n|----------------------------------------|----------------------------|----------------------------------------|----------------------------------------------|------------------------------------------------------------|\n| Model Dataset Params. PF-days Citation | GPT-Neo Pile 1.3B 380GT 34 | GPT-J Pile 6.7B 402GT 187 &Komatsuzaki | GPT-NeoX 20B Pile 20B 472GT 656 Black et al. | Pythia(-Dedup) Pile (dedup) 70M-12B 300GT 1.5 - 250 et al. |\n| Pretraining                            |                            |                                        |                                              |                                                            |\n|                                        | Black et al. (2021)        | Wang (2021)                            | (2022)                                       | Biderman (2023)                                            |"
    },
    {
      "index": 14,
      "markdown": "| Series                                             | Aleph Alpha ∗                                         | Cerebras-GPT ∗                                                    | OPT ∗                                                                      | FairSeq ∗                                                      |\n|----------------------------------------------------|-------------------------------------------------------|-------------------------------------------------------------------|----------------------------------------------------------------------------|----------------------------------------------------------------|\n| Model Dataset Params. Pretraining PF-days Citation | Luminous undisclosed 13B 400GT 361 Aleph Alpha (2023) | Cerebras-GPT Pile 111M-13B 2 - 257GT 0.02 - 232 Dey et al. (2023) | OPT Pile (subset) + curated 125M - 175B 300GT 3 - 3646 Zhang et al. (2022) | FairSeq curated 1.3 - 13B 300GT 27 - 271 Artetxe et al. (2021) |"
    },
    {
      "index": 15,
      "markdown": "| Deduplication                                                                                                                                                     | Exact : three sentences span (optional) Exact : per line ( ∼ 55% removed) NSFW (optional) Ex- act : per line   | Fuzzy : min- hash with 10 hashes ( ∼ 10% removed) Fuzzy : min- hash with 10 hashes, sim. treshold 0.5 ( ∼ 26% re- moved)                        | Exact &fuzzy : exact docu- ments, minhash w/ sim. treshold 0.8 Unknown   |\n|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------|\n| Content filtering Rules-based: code, NSFW None                                                                                                                    | Optional blocklist fastText trained on HQ-data fastText on cu- rated crawl                                     | SafeSearch                                                                                                                                      | ML-based filter on HQ data                                               |\n| Heuristics Document and line-level Line < 100 characters Line-level, optional document-level                                                                      | Unknown                                                                                                        | None Document- level                                                                                                                            | Document- level                                                          |\n| Language ID Document- level w/ langdetect Line-level w/ fastText (Joulin et al., 2016) Document- level w/ fast- Text (Joulin et al., 2016)                        | Unknown Document- level w/ pycld2 (Sites, 2013)                                                                | Unknown                                                                                                                                         | Unknown                                                                  |\n| data HTML extraction MASSIVE WEB DATASETS % .WET files % .WET files % .WET files                                                                                  | CURATED DATASETS Unknown jusText (Pomik´ alek, 2011)                                                           | Custom                                                                                                                                          | Unknown OURS                                                             |\n| Web Web 100 100                                                                                                                                                   | 100 60 %                                                                                                       | 18 % 48 %                                                                                                                                       | 27 %                                                                     |\n| Availability Public Public Public                                                                                                                                 | Private                                                                                                        | Public Private                                                                                                                                  | Private                                                                  |\n| models Size ∼ 360 GT ∼ 370 GT ∼ 283 GT                                                                                                                            | 300 GT ∼ 340 GT                                                                                                | Pythia 1 , 400 GT                                                                                                                               | 780 GT                                                                   |\n| General information Dataset Notable C4 (Raffel et al., 2020) T5 (Raffel et al., 2020) OSCAR 21.09 (Ortiz Su´ arez et al., 2019) OSCAR 22.01 (Abadji et al., 2022) | ■ GPT-3 (Brown et al., 2020) The Pile et al., GPT-J (Wang& Komatsuzaki, 2021), GPT- NeoX-20B (Black et al.,    | ▼ (Gao 2020) 2022), (Biderman et al., 2023), Cerebras-GPT (Dey et al., 2023) al., Gopher (Rae et al., 2021), Chinchilla (Hoffmann et al., 2022) | MassiveWeb (Rae et 2021) ⋆ PaLM (Chowdhery et al., 2022)                 |"
    },
    {
      "index": 16,
      "markdown": "| Category    | Description                                        |   Number of links |\n|-------------|----------------------------------------------------|-------------------|\n| adult       | adult websites: from eroticism to hard pornography |           4516478 |\n| phishing    | phishing websites, malwares, etc.                  |             42445 |\n| dating      | dating websites                                    |              3829 |\n| gambling    | online casino                                      |              1365 |\n| filehosting | websites hosting files, videos, pictures, music    |               909 |\n| ddos        | websites related to ddos attacks                   |               421 |\n| agressif    | hate, racism, etc                                  |               390 |\n| chat        | online chat websites                               |               244 |\n| mixed adult | websites with some adult content                   |               153 |\n| arjel       | French regulated gambling websites                 |                69 |"
    },
    {
      "index": 17,
      "markdown": "| Curated data source   | Domain name blocked                                                |\n|-----------------------|--------------------------------------------------------------------|\n| arxiv                 | arxiv.org                                                          |\n| AskUbuntu             | askubuntu.com                                                      |\n| StackOverflow         | stackoverflow.com stackapps.com stackexchange.com mathoverflow.net |\n| NIH Abstracts         | exporter.nih.gov ncbi.nlm.nih.gov                                  |\n| Github                | github.com                                                         |\n| Ubuntu IRC            | irclogs.ubuntu.com                                                 |\n| HackerNews            | news.ycombinator.com                                               |\n| FreeLaw               | courtlistener.com                                                  |\n| Reddit                | reddit.com                                                         |\n| Europarl              | statmt.org                                                         |\n| United States Patents | uspto.gov                                                          |\n| Wikipedia             | wikipedia.org                                                      |"
    },
    {
      "index": 18,
      "markdown": "| Description                                                                                | Example document                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n|--------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Wordpress sitemap notice generated by the Google Sitemap Generator Plugin                  | This is a XML Sitemap which is supposed to be processed by search engines which follow the XML Sitemap standard like Ask.com, Bing, Google and Yahoo. It was generated using the WordPress content management system and the Google Sitemap Generator Plugin by Arne Brachhold. You can find more information about XMLsitemaps on sitemaps.org and Google's list of sitemap programs. This file contains links to sub-sitemaps, follow them to see the actual sitemap content.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n| Cloudflare notice to enable Javascript                                                     |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n| Templated disability notice, with different phone numbers across pages                     | Welcome to our website! As we have the ability to list over one million items on our website (our selection changes all of the time), it is not feasible for a company our size to record and playback the descriptions on every item on our website. However, if you are an American with a disability we are here to help you. Please call our disability services phone line at [redacted] or [redacted] during regular business hours and one of our kind and friendly personal shoppers will help you navigate through our website, help conduct advanced searches, help you choose the item you are looking for with the specifications you are seeking, read you the specifications of any item and consult with you about the products themselves. There is no charge for the help of this personal shopper for any American with a disability. Finally, your personal shopper will explain our Privacy Policy and Terms of Service, and help you place an order if you so desire. |\n| Templated cookies notice                                                                   |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n| Templated domain name for sale page                                                        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n| www.metoperashop.org and sub-URLs, with content changes but always the same (large) footer |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n| Different pages across more than 80 different domain names but with a common section       | DC Customers also liked: Special event items are produced by man- ufacturers only after the outcome of a game or event. These are advanced sale items and will ship immediately after they are received in our warehouse. Manufacturer direct items are shipped directly from the manufacturer. These items are not available for international or expedited shipping. Customized items can be personalized with options such as your name, your favorite number, and/or designs. Some options may be limited by league rules.                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| http://www.boxofficemojo.com/daily and sub- URLs                                           |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |"
    },
    {
      "index": 19,
      "markdown": "| http://gamesandbiz.blogspot.com/2010/ 07/bad-reviews-can-hurt-game-sales.ht ml?showComment=1278486430242                                                                                                                                                                                | http://gamesandbiz.blogspot.com/2010/ 07/bad-reviews-can-hurt-game-sales.ht ml?showComment=1278499674195                                                                                                                                   |\n|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| https://www.ocean-oxygen.org/home;jse ssionid=1E3290E84F668552FAC643D0A8F81 BEC?p_p_id=122_INSTANCE_Zy6zjkRLAg7v& p_p_lifecycle=0&p_p_state=normal&p_p_ mode=view&p_p_col_id=column-2&p_p_col _pos=1&p_p_col_count=6&p_r_p_56423352 4_resetCur=true&p_r_p_564233524_categ oryId=1346016 | https://www.ocean-oxygen.org/home?p_p _id=122_INSTANCE_Zy6zjkRLAg7v&p_p_lif ecycle=0&p_p_state=normal&p_p_mode=vi ew&p_p_col_id=column-2&p_p_col_pos=1& p_p_col_count=6&p_r_p_564233524_reset Cur=true&p_r_p_564233524_categoryId=1 346016 |"
    },
    {
      "index": 20,
      "markdown": "| it appears there is a transfer of ranking signals in this rela- tionship. Supporting this finding is a quote from Google's guidelines: Using JavaScript to redirect users can be a legitimate practice. For example, if you redirect users to an internal page once they're logged in, you can use JavaScript to do so. When examining JavaScript or other redirect meth- ods to ensure your site adheres to our guidelines, consider the intent. Keep in mind that 301 redirects are best when moving your site, but you could use a JavaScript redirect for this purpose if you don't have access to your website's server. NOTE: Their experiment is based on a live page with status code 200 and NOT an inactive page. So if you want to implement this for legacy   | Some examples of sneaky redirects include: - Search en- gines shown one type of content while users are redirected to something significantly different. - Desktop users receive a normal page, while mobile users are redirected to a com- pletely different spam domain. Using JavaScript to redirect users can be a legitimate practice. For example, if you redi- rect users to an internal page once they're logged in, you can use JavaScript to do so. When examining JavaScript or other redirect methods to ensure your site adheres to our guidelines, consider the intent. Keep in mind that 301 redirects are best when moving your site, but you could use a JavaScript redirect for this purpose if you don't have access to your website's server.   |\n|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Find Palm Beache FL homes for sale and other Palm Beach real estate on homesofthepalmbeaches.com. Browse and search Palm Beach houses, condos, townhomes and single- family homes by community , building, or location. Our extensive database of real estate listings provide the most comprehensive property details including home values, fea- tures and local school and neighborhood info so you can be sure that you have nearly all the facts you need upfront. Search homesofthepalmbeaches.com today! Want a closer look at what other Palm Beach properties are available?                                                                                                                                                                                     | Search Stuart houses, condos, townhomes and single-family homes by price and location. Our extensive database of real estate listings provide the most comprehensive property details including home values, features and local school and neighborhood info so you can be sure that you have nearly all the facts you need upfront. Search Stuart Listings today! Want a closer look at what other Stuart properties are available? Also search our listings for the Newest Stuart Listings and Stuart Homes with Price Reductions now. Stu- art FL Homes for Sale - Stuart Real Estate Listings FREE to search Stuart Property                                                                                                                                    |\n| To find the correct size you should measure your foot from the heel to the toe point. Add approximately 1 - 1,5cm to get the actual inner sole length. Measure both feet and fit shoes to the larger foot. Measure feet at the end of the day, when your feet are at their largest. Lente shoes are women's easy slip-on leisure shoes for everyday use. These lightweight shoes have a breathable textile mesh upper made of recycled PET bottles and cool Lycra lining.                                                                                                                                                                                                                                                                                                 | To find the correct size you should measure your foot from the heel to the toe point. Add approximately 1 - 1,5cm to get the actual inner sole length. Measure both feet and fit shoes to the larger foot. Measure feet at the end of the day, when your feet are at their largest. Enjoy your summer days with Masera leisure sneakers. These low-cut women's sneakers are extremely lightweight thanks to phylon midsole and breathable textile mesh upper                                                                                                                                                                                                                                                                                                        |\n| This bandana makes the perfect addition to every fur babies birthday collection! With its sparkly crown pattern, your pup will be ready for every birthday celebration! With snaps for security, this bandana is made with love, down to the very last stitch ! Fabric: cotton Care Instructions: Hand wash only, iron as needed, on low heat Always supervise your pup while wearing Faithful Paws Co. accessories, as it could become a choking hazard if consumed.                                                                                                                                                                                                                                                                                                     | This bandana makes the perfect addition to every fur babies summer collection! With its vibrant watercolor popsicle pattern, your pup will be ready for every summer cook- out! With snaps for security, this bandana is made with love, down to the very last stitch ! Fabric: cotton Care Instructions: Hand wash only, iron as needed, on low heat Always supervise your pup while wearing Faithful Paws Co. accessories, as it could become a choking hazard if consumed.                                                                                                                                                                                                                                                                                       |"
    }
  ],
  "stats": {
    "pages": 32,
    "chunksCreated": 241,
    "totalCharacters": 182807,
    "totalWords": 18651,
    "numTables": 21,
    "processingTimeMs": 45027
  }
}
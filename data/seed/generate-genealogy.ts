/**
 * ç”ŸæˆAIã®ç™ºå±•ç³»è­œ - GraphRAGç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
 * Neo4jã®ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ã¦Mermaidå½¢å¼ã®ç³»è­œå›³ã‚’ç”Ÿæˆ
 */

import neo4j from 'neo4j-driver';
import { writeFileSync, mkdirSync } from 'fs';
import { join } from 'path';

const driver = neo4j.driver(
  'bolt://localhost:7687',
  neo4j.auth.basic('neo4j', 'password')
);

// ç”ŸæˆAIé–¢é€£ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
const GENERATIVE_AI_KEYWORDS = [
  'transformer', 'attention', 'gpt', 'bert', 'llm', 'language model',
  'generative', 'gan', 'diffusion', 'vae', 'autoencoder',
  'chatgpt', 'claude', 'llama', 'gemini', 'palm',
  'clip', 'dall-e', 'stable diffusion', 'imagen', 'midjourney',
  'whisper', 'wav2vec', 'speech',
  'multimodal', 'vision-language',
  'rlhf', 'alignment', 'instruction tuning', 'fine-tuning',
  'scaling law', 'emergent', 'chain-of-thought', 'reasoning'
];

interface ModelInfo {
  name: string;
  year: number;
  category: string;
  organization: string;
  description: string;
  arxivId?: string;
}

interface TimelineEvent {
  year: number;
  models: ModelInfo[];
}

// ã‚«ãƒ†ã‚´ãƒªåˆ¤å®š
function categorize(name: string, description: string): string {
  const text = `${name} ${description}`.toLowerCase();
  
  if (text.includes('diffusion') || text.includes('stable diffusion') || text.includes('imagen') || text.includes('dall-e')) {
    return 'Image Generation';
  }
  if (text.includes('gan') || text.includes('generative adversarial')) {
    return 'GAN';
  }
  if (text.includes('whisper') || text.includes('speech') || text.includes('wav2vec') || text.includes('tts')) {
    return 'Speech/Audio';
  }
  if (text.includes('clip') || text.includes('blip') || text.includes('multimodal') || text.includes('vision-language') || text.includes('llava') || text.includes('flamingo')) {
    return 'Multimodal';
  }
  if (text.includes('gpt') || text.includes('llama') || text.includes('claude') || text.includes('gemini') || text.includes('palm') || text.includes('chatgpt')) {
    return 'LLM';
  }
  if (text.includes('bert') || text.includes('roberta') || text.includes('xlnet') || text.includes('electra')) {
    return 'Encoder LM';
  }
  if (text.includes('transformer') || text.includes('attention')) {
    return 'Foundation';
  }
  if (text.includes('rlhf') || text.includes('alignment') || text.includes('dpo') || text.includes('ppo')) {
    return 'Alignment';
  }
  if (text.includes('vae') || text.includes('autoencoder')) {
    return 'VAE';
  }
  return 'Other';
}

// çµ„ç¹”æŠ½å‡º
function extractOrg(description: string): string {
  const text = description.toLowerCase();
  if (text.includes('openai')) return 'OpenAI';
  if (text.includes('google') || text.includes('deepmind')) return 'Google';
  if (text.includes('meta') || text.includes('facebook')) return 'Meta';
  if (text.includes('anthropic')) return 'Anthropic';
  if (text.includes('microsoft')) return 'Microsoft';
  if (text.includes('nvidia')) return 'NVIDIA';
  if (text.includes('stability')) return 'Stability AI';
  if (text.includes('hugging face')) return 'Hugging Face';
  if (text.includes('alibaba')) return 'Alibaba';
  if (text.includes('baidu')) return 'Baidu';
  if (text.includes('tsinghua')) return 'Tsinghua';
  if (text.includes('stanford')) return 'Stanford';
  if (text.includes('berkeley')) return 'UC Berkeley';
  return 'Academic/Other';
}

async function fetchGenerativeAIData(session: neo4j.Session): Promise<ModelInfo[]> {
  console.log('ğŸ“¥ Fetching generative AI data from Neo4j...');
  
  // ä¸»è¦ãªãƒ¢ãƒ‡ãƒ«ãƒ»æ‰‹æ³•ãƒ»è«–æ–‡ã‚’å–å¾—
  const result = await session.run(`
    MATCH (n)
    WHERE (n:AIModel OR n:Technique OR n:Publication OR n:Entity)
      AND n.name IS NOT NULL
      AND n.description IS NOT NULL
    RETURN n.name as name, 
           n.description as description, 
           n.year as year,
           n.arxivId as arxivId,
           labels(n) as labels
    ORDER BY n.year
  `);
  
  const models: ModelInfo[] = [];
  const seen = new Set<string>();
  
  for (const record of result.records) {
    const name = record.get('name');
    const description = record.get('description') || '';
    const yearRaw = record.get('year');
    const arxivId = record.get('arxivId');
    
    // é‡è¤‡ãƒã‚§ãƒƒã‚¯
    const normalizedName = name.toLowerCase().trim();
    if (seen.has(normalizedName)) continue;
    
    // ç”ŸæˆAIé–¢é€£ã‹ãƒã‚§ãƒƒã‚¯
    const text = `${name} ${description}`.toLowerCase();
    const isGenerativeAI = GENERATIVE_AI_KEYWORDS.some(kw => text.includes(kw));
    
    if (!isGenerativeAI) continue;
    
    // å¹´ã‚’æŠ½å‡º
    let year = yearRaw ? (typeof yearRaw === 'object' ? yearRaw.toNumber() : yearRaw) : null;
    
    // arxivIdã‹ã‚‰å¹´ã‚’æ¨æ¸¬
    if (!year && arxivId) {
      const match = arxivId.match(/^(\d{2})(\d{2})\./);
      if (match) {
        year = 2000 + parseInt(match[1]);
      }
    }
    
    // èª¬æ˜æ–‡ã‹ã‚‰å¹´ã‚’æ¨æ¸¬
    if (!year) {
      const yearMatch = description.match(/\b(201[0-9]|202[0-5])\b/);
      if (yearMatch) {
        year = parseInt(yearMatch[1]);
      }
    }
    
    if (!year || year < 2014 || year > 2025) continue;
    
    seen.add(normalizedName);
    
    models.push({
      name: name.substring(0, 50), // åå‰ã‚’çŸ­ç¸®
      year,
      category: categorize(name, description),
      organization: extractOrg(description),
      description: description.substring(0, 200),
      arxivId
    });
  }
  
  // é‡è¦ãªãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã‚’è¿½åŠ ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãªã„å ´åˆï¼‰
  const milestones: ModelInfo[] = [
    { name: 'Transformer', year: 2017, category: 'Foundation', organization: 'Google', description: 'Attention Is All You Need - Self-attention architecture' },
    { name: 'GPT-1', year: 2018, category: 'LLM', organization: 'OpenAI', description: 'Generative Pre-Training - First GPT model' },
    { name: 'BERT', year: 2018, category: 'Encoder LM', organization: 'Google', description: 'Bidirectional Encoder Representations from Transformers' },
    { name: 'GPT-2', year: 2019, category: 'LLM', organization: 'OpenAI', description: 'Language Models are Unsupervised Multitask Learners' },
    { name: 'GPT-3', year: 2020, category: 'LLM', organization: 'OpenAI', description: '175B parameters, Few-shot learning' },
    { name: 'DALL-E', year: 2021, category: 'Image Generation', organization: 'OpenAI', description: 'Text-to-image generation' },
    { name: 'CLIP', year: 2021, category: 'Multimodal', organization: 'OpenAI', description: 'Contrastive Language-Image Pre-training' },
    { name: 'Codex', year: 2021, category: 'LLM', organization: 'OpenAI', description: 'Code generation model' },
    { name: 'Stable Diffusion', year: 2022, category: 'Image Generation', organization: 'Stability AI', description: 'Open-source diffusion model' },
    { name: 'ChatGPT', year: 2022, category: 'LLM', organization: 'OpenAI', description: 'Conversational AI with RLHF' },
    { name: 'Whisper', year: 2022, category: 'Speech/Audio', organization: 'OpenAI', description: 'Robust speech recognition' },
    { name: 'LLaMA', year: 2023, category: 'LLM', organization: 'Meta', description: 'Open foundation model' },
    { name: 'GPT-4', year: 2023, category: 'LLM', organization: 'OpenAI', description: 'Multimodal large language model' },
    { name: 'Claude', year: 2023, category: 'LLM', organization: 'Anthropic', description: 'Constitutional AI' },
    { name: 'Gemini', year: 2023, category: 'LLM', organization: 'Google', description: 'Multimodal AI model' },
    { name: 'Sora', year: 2024, category: 'Image Generation', organization: 'OpenAI', description: 'Text-to-video generation' },
    { name: 'Claude 3', year: 2024, category: 'LLM', organization: 'Anthropic', description: 'Advanced reasoning capabilities' },
    { name: 'LLaMA 3', year: 2024, category: 'LLM', organization: 'Meta', description: 'Improved open model' },
    { name: 'GPT-4o', year: 2024, category: 'LLM', organization: 'OpenAI', description: 'Omni model with native multimodal' },
  ];
  
  // ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã‚’è¿½åŠ ï¼ˆé‡è¤‡ãªã—ï¼‰
  for (const m of milestones) {
    if (!seen.has(m.name.toLowerCase())) {
      models.push(m);
      seen.add(m.name.toLowerCase());
    }
  }
  
  return models.sort((a, b) => a.year - b.year);
}

function generateMermaidTimeline(models: ModelInfo[]): string {
  // å¹´ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
  const byYear = new Map<number, ModelInfo[]>();
  for (const m of models) {
    if (!byYear.has(m.year)) {
      byYear.set(m.year, []);
    }
    byYear.get(m.year)!.push(m);
  }
  
  let mermaid = `%%{init: {'theme': 'base', 'themeVariables': { 'fontSize': '14px'}}}%%
timeline
    title ç”ŸæˆAIã®ç™ºå±•ç³»è­œ (2014-2025)
`;
  
  const years = Array.from(byYear.keys()).sort();
  
  for (const year of years) {
    const yearModels = byYear.get(year)!;
    mermaid += `    ${year}\n`;
    
    // ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    const byCategory = new Map<string, ModelInfo[]>();
    for (const m of yearModels) {
      if (!byCategory.has(m.category)) {
        byCategory.set(m.category, []);
      }
      byCategory.get(m.category)!.push(m);
    }
    
    for (const [category, categoryModels] of byCategory) {
      const names = categoryModels.slice(0, 5).map(m => m.name).join(', ');
      mermaid += `        : ${category} - ${names}\n`;
    }
  }
  
  return mermaid;
}

function generateMermaidFlowchart(models: ModelInfo[]): string {
  let mermaid = `%%{init: {'theme': 'base', 'themeVariables': { 'fontSize': '12px'}}}%%
flowchart TB
    subgraph legend[" å‡¡ä¾‹ "]
        direction LR
        L1[ğŸ”µ Foundation]
        L2[ğŸŸ¢ LLM]
        L3[ğŸŸ¡ Encoder]
        L4[ğŸŸ£ Image Gen]
        L5[ğŸ”´ Multimodal]
        L6[ğŸŸ  Speech]
        L7[âšª Alignment]
    end

`;
  
  // ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ã‚¹ã‚¿ã‚¤ãƒ«
  const categoryColors: Record<string, string> = {
    'Foundation': '#4A90D9',
    'LLM': '#27AE60',
    'Encoder LM': '#F1C40F',
    'Image Generation': '#9B59B6',
    'Multimodal': '#E74C3C',
    'Speech/Audio': '#E67E22',
    'Alignment': '#95A5A6',
    'GAN': '#8E44AD',
    'VAE': '#16A085',
    'Other': '#7F8C8D'
  };
  
  // å¹´ä»£åˆ¥ã‚µãƒ–ã‚°ãƒ©ãƒ•
  const periods = [
    { name: '2014-2016', start: 2014, end: 2016, label: 'åŸºç›¤æŠ€è¡“æœŸ' },
    { name: '2017-2019', start: 2017, end: 2019, label: 'Transformeré©å‘½' },
    { name: '2020-2021', start: 2020, end: 2021, label: 'ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ™‚ä»£' },
    { name: '2022-2023', start: 2022, end: 2023, label: 'ChatGPTé©å‘½' },
    { name: '2024-2025', start: 2024, end: 2025, label: 'ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ™‚ä»£' }
  ];
  
  const nodeIds = new Map<string, string>();
  let nodeCounter = 0;
  
  for (const period of periods) {
    const periodModels = models.filter(m => m.year >= period.start && m.year <= period.end);
    if (periodModels.length === 0) continue;
    
    mermaid += `    subgraph ${period.name.replace('-', '_')}["${period.label} (${period.name})"]
        direction TB
`;
    
    // ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦è¡¨ç¤º
    const byCategory = new Map<string, ModelInfo[]>();
    for (const m of periodModels) {
      if (!byCategory.has(m.category)) {
        byCategory.set(m.category, []);
      }
      byCategory.get(m.category)!.push(m);
    }
    
    for (const [category, catModels] of byCategory) {
      // å„ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰æœ€å¤§3ã¤ã‚’é¸æŠ
      const selected = catModels.slice(0, 3);
      for (const m of selected) {
        const nodeId = `n${nodeCounter++}`;
        nodeIds.set(m.name, nodeId);
        const shortName = m.name.length > 20 ? m.name.substring(0, 17) + '...' : m.name;
        mermaid += `        ${nodeId}["${shortName}<br/>${m.organization}"]\n`;
      }
    }
    
    mermaid += `    end
`;
  }
  
  // ä¸»è¦ãªé–¢ä¿‚æ€§ã‚’è¿½åŠ 
  mermaid += `
    %% ä¸»è¦ãªç™ºå±•çµŒè·¯
`;
  
  // Transformerç³»åˆ—
  const transformerLineage = ['Transformer', 'BERT', 'GPT-1', 'GPT-2', 'GPT-3', 'ChatGPT', 'GPT-4', 'GPT-4o'];
  for (let i = 0; i < transformerLineage.length - 1; i++) {
    const from = nodeIds.get(transformerLineage[i]);
    const to = nodeIds.get(transformerLineage[i + 1]);
    if (from && to) {
      mermaid += `    ${from} --> ${to}\n`;
    }
  }
  
  // LLaMAç³»åˆ—
  const llamaLineage = ['GPT-3', 'LLaMA', 'LLaMA 3'];
  for (let i = 0; i < llamaLineage.length - 1; i++) {
    const from = nodeIds.get(llamaLineage[i]);
    const to = nodeIds.get(llamaLineage[i + 1]);
    if (from && to) {
      mermaid += `    ${from} -.-> ${to}\n`;
    }
  }
  
  // Claudeç³»åˆ—
  const claudeLineage = ['ChatGPT', 'Claude', 'Claude 3'];
  for (let i = 0; i < claudeLineage.length - 1; i++) {
    const from = nodeIds.get(claudeLineage[i]);
    const to = nodeIds.get(claudeLineage[i + 1]);
    if (from && to) {
      mermaid += `    ${from} -.-> ${to}\n`;
    }
  }
  
  // ç”»åƒç”Ÿæˆç³»åˆ—
  const imageLineage = ['CLIP', 'DALL-E', 'Stable Diffusion', 'Sora'];
  for (let i = 0; i < imageLineage.length - 1; i++) {
    const from = nodeIds.get(imageLineage[i]);
    const to = nodeIds.get(imageLineage[i + 1]);
    if (from && to) {
      mermaid += `    ${from} --> ${to}\n`;
    }
  }
  
  // ã‚¹ã‚¿ã‚¤ãƒ«å®šç¾©
  mermaid += `
    %% ã‚¹ã‚¿ã‚¤ãƒ«å®šç¾©
`;
  for (const [name, nodeId] of nodeIds) {
    const model = models.find(m => m.name === name);
    if (model) {
      const color = categoryColors[model.category] || '#7F8C8D';
      mermaid += `    style ${nodeId} fill:${color},color:#fff,stroke:#333\n`;
    }
  }
  
  return mermaid;
}

function generateMarkdownReport(models: ModelInfo[]): string {
  let md = `# ç”ŸæˆAIã®ç™ºå±•ç³»è­œ

> Generated by YAGOKORO GraphRAG on ${new Date().toISOString().split('T')[0]}

## æ¦‚è¦

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯YAGOKOROã®GraphRAGã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ã—ã¦ã€Neo4jãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã‹ã‚‰æŠ½å‡ºã—ãŸç”ŸæˆAIé–¢é€£ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«ä½œæˆã•ã‚ŒãŸç³»è­œã§ã™ã€‚

- **ç·ãƒ¢ãƒ‡ãƒ«/æŠ€è¡“æ•°**: ${models.length}
- **æœŸé–“**: 2014å¹´ã€œ2025å¹´
- **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: Neo4j (${models.filter(m => m.arxivId).length}ä»¶ã®arXivè«–æ–‡ã‚’å«ã‚€)

## ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ

| ã‚«ãƒ†ã‚´ãƒª | ä»¶æ•° | ä»£è¡¨ä¾‹ |
|----------|------|--------|
`;

  const byCategory = new Map<string, ModelInfo[]>();
  for (const m of models) {
    if (!byCategory.has(m.category)) {
      byCategory.set(m.category, []);
    }
    byCategory.get(m.category)!.push(m);
  }
  
  for (const [category, catModels] of Array.from(byCategory).sort((a, b) => b[1].length - a[1].length)) {
    const examples = catModels.slice(0, 3).map(m => m.name).join(', ');
    md += `| ${category} | ${catModels.length} | ${examples} |\n`;
  }

  md += `
## å¹´è¡¨

`;

  const byYear = new Map<number, ModelInfo[]>();
  for (const m of models) {
    if (!byYear.has(m.year)) {
      byYear.set(m.year, []);
    }
    byYear.get(m.year)!.push(m);
  }
  
  for (const year of Array.from(byYear.keys()).sort()) {
    const yearModels = byYear.get(year)!;
    md += `### ${year}å¹´

`;
    for (const m of yearModels.sort((a, b) => a.category.localeCompare(b.category))) {
      md += `- **${m.name}** (${m.category}) - ${m.organization}\n`;
      if (m.arxivId) {
        md += `  - arXiv: ${m.arxivId}\n`;
      }
    }
    md += '\n';
  }

  md += `## ä¸»è¦ãªãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³

### 2017: Transformeré©å‘½
- **Attention Is All You Need** - Google ãŒ Self-Attention ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç™ºè¡¨
- RNN/LSTMã‹ã‚‰ã®è»¢æ›ç‚¹

### 2018: äº‹å‰å­¦ç¿’ã®æ™‚ä»£
- **BERT** - åŒæ–¹å‘ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã«ã‚ˆã‚‹æ–‡è„ˆç†è§£
- **GPT-1** - ç”Ÿæˆçš„äº‹å‰å­¦ç¿’ã®é–‹å§‹

### 2020: ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡
- **GPT-3** - 1750å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€Few-shotå­¦ç¿’èƒ½åŠ›ã®å®Ÿè¨¼
- ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ï¼ˆScaling Lawsï¼‰ã®ç¢ºç«‹

### 2022: ChatGPTé©å‘½
- **ChatGPT** - RLHF ã«ã‚ˆã‚‹å¯¾è©±AI
- **Stable Diffusion** - ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ç”»åƒç”Ÿæˆ
- **Whisper** - å …ç‰¢ãªéŸ³å£°èªè­˜

### 2023: ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã®å¹•é–‹ã‘
- **GPT-4** - ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«
- **LLaMA** - ã‚ªãƒ¼ãƒ—ãƒ³ãªåŸºç›¤ãƒ¢ãƒ‡ãƒ«
- **Claude** - Constitutional AI

### 2024-2025: æ¬¡ä¸–ä»£ã¸
- **Sora** - ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å‹•ç”»ç”Ÿæˆ
- **GPT-4o** - ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«
- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ AI ã®å°é ­

## ç³»è­œå›³ (Mermaid)

ä»¥ä¸‹ã®Mermaidå›³ã¯ \`genai-timeline.mmd\` ãŠã‚ˆã³ \`genai-flowchart.mmd\` ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚

---

*This document was auto-generated by YAGOKORO GraphRAG system.*
`;

  return md;
}

async function main() {
  console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
  console.log('â•‘     ç”ŸæˆAIã®ç™ºå±•ç³»è­œ - YAGOKORO GraphRAG Generator        â•‘');
  console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  
  const session = driver.session();
  
  try {
    // ãƒ‡ãƒ¼ã‚¿å–å¾—
    const models = await fetchGenerativeAIData(session);
    console.log(`\nğŸ“Š Found ${models.length} generative AI models/techniques`);
    
    // å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    const outputDir = join(process.cwd(), '..', 'outputs');
    mkdirSync(outputDir, { recursive: true });
    
    // Timelineç”Ÿæˆ
    console.log('\nğŸ“ Generating timeline...');
    const timeline = generateMermaidTimeline(models);
    writeFileSync(join(outputDir, 'genai-timeline.mmd'), timeline);
    console.log('   âœ… genai-timeline.mmd');
    
    // Flowchartç”Ÿæˆ
    console.log('\nğŸ“ Generating flowchart...');
    const flowchart = generateMermaidFlowchart(models);
    writeFileSync(join(outputDir, 'genai-flowchart.mmd'), flowchart);
    console.log('   âœ… genai-flowchart.mmd');
    
    // ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    console.log('\nğŸ“ Generating report...');
    const report = generateMarkdownReport(models);
    writeFileSync(join(outputDir, 'genai-genealogy.md'), report);
    console.log('   âœ… genai-genealogy.md');
    
    // çµ±è¨ˆè¡¨ç¤º
    console.log('\n' + 'â•'.repeat(60));
    console.log('ğŸ“Š Statistics:');
    
    const byCategory = new Map<string, number>();
    for (const m of models) {
      byCategory.set(m.category, (byCategory.get(m.category) || 0) + 1);
    }
    
    for (const [cat, count] of Array.from(byCategory).sort((a, b) => b[1] - a[1])) {
      console.log(`   ${cat}: ${count}`);
    }
    
    console.log('\nâœ… All files saved to outputs/ directory');
    console.log('â•'.repeat(60));
    
  } finally {
    await session.close();
    await driver.close();
  }
}

main().catch(console.error);

{
  "paper": {
    "id": "2305.14325v1",
    "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in language generation, understanding, and few-shot learning in recent years. An extensive body of work has explored how their performance may be further improved through the tools of prompting, ranging from verification, self-consistency, or intermediate scratchpads. In this paper, we present a complementary approach to improve language responses where multiple language model instances propose and debate their individual responses and reasoning processes over multiple rounds to arrive at a common final answer. Our findings indicate that this approach significantly enhances mathematical and strategic reasoning across a number of tasks. We also demonstrate that our approach improves the factual validity of generated content, reducing fallacious answers and hallucinations that contemporary models are prone to. Our approach may be directly applied to existing black-box models and uses identical procedure and prompts for all tasks we investigate. Overall, our findings suggest that such \"society of minds\" approach has the potential to significantly advance the capabilities of LLMs and pave the way for further breakthroughs in language generation and understanding.",
    "authors": [
      "Yilun Du",
      "Shuang Li",
      "Antonio Torralba",
      "Joshua B. Tenenbaum",
      "Igor Mordatch"
    ],
    "published": "2023-05-23T17:55:11.000Z",
    "updated": "2023-05-23T17:55:11.000Z",
    "primaryCategory": "cs.CL",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "pdfUrl": "https://arxiv.org/pdf/2305.14325v1",
    "absUrl": "https://arxiv.org/abs/2305.14325v1"
  },
  "chunks": [
    {
      "id": "2305.14325v1-chunk-0",
      "content": "Yilun Du MIT CSAIL\n\nyilundu@mit.edu\n\nShuang Li MIT CSAIL\n\nAntonio Torralba MIT CSAIL\n\nlishuang@mit.edu torralba@mit.edu",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "chunkIndex": 0,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-1",
      "content": "Google Brain imordatch@google.com",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "Igor Mordatch",
        "chunkIndex": 1,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-2",
      "content": "Large language models (LLMs) have demonstrated remarkable capabilities in language generation, understanding, and few-shot learning in recent years. An extensive body of work has explored how their performance may be further improved through the tools of prompting, ranging from verification, self-consistency, or intermediate scratchpads. In this paper, we present a complementary approach to improve language responses where multiple language model instances propose and debate their individual responses and reasoning processes over multiple rounds to arrive at a common final answer. Our findings indicate that this approach significantly enhances mathematical and strategic reasoning across a number of tasks. We also demonstrate that our approach improves the factual validity of generated content, reducing fallacious answers and hallucinations that contemporary models are prone to.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "Abstract",
        "chunkIndex": 2,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-3",
      "content": "cross a number of tasks. We also demonstrate that our approach improves the factual validity of generated content, reducing fallacious answers and hallucinations that contemporary models are prone to. Our approach may be directly applied to existing black-box models and uses identical procedure and prompts for all tasks we investigate. Overall, our findings suggest that such \"society of minds\" approach has the potential to significantly advance the capabilities of LLMs and pave the way for further breakthroughs in language generation and understanding. Project website at https://composable-models.github.io/llm\\_debate/ .",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "Abstract",
        "chunkIndex": 3,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-4",
      "content": "Large language models (LLMs) have demonstrated remarkable language generation, understanding, and few-shot learning capabilities in recent years. These methods are trained on a massive corpus of text on the internet, where the quality and accuracy of extracted natural language may not be ensured. Thus, current models may suffer from confidently hallucinating facts or making implausible jumps in chains of reasoning. An extensive body of recent work has focused on improving factual accuracy and reasoning in language models. These range from prompting models with few or zero-shot chain-of-thought demonstrations, use of verification, self-consistency, or intermediate scratchpads.\n\nWe note that these techniques are applied over a single model instance. Instead, we propose a complementary approach inspired by The Society of Mind [19] and multi-agent settings, where multiple language model instances (or agents) individually propose and jointly debate their responses and reasoning processes to",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "1 Introduction",
        "chunkIndex": 4,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-5",
      "content": "ch inspired by The Society of Mind [19] and multi-agent settings, where multiple language model instances (or agents) individually propose and jointly debate their responses and reasoning processes to arrive at a single common answer. More specifically, given a query, multiple instances of a language model first generate individual candidate answers to a query. Then each individual model instance reads and critiques the responses of all other models and uses this content to update its own answer. This step is then repeated over several rounds. This process induces models to construct answers that are consistent with both their internal critic as well as sensible in\n\nPreprint. Under review.\n\nJoshua B. Tenenbaum MIT CSAIL, BCS, CBMM jbt@mit.edu\n\nFigure 1: Multiagent Debate Improves Reasoning and Factual Accuracy. Accuracy of traditional inference and our multi-agent debate over six benchmarks (chess move optimality reported as a normalized score)\n\n<!-- image -->",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "1 Introduction",
        "chunkIndex": 5,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-6",
      "content": "Debate Improves Reasoning and Factual Accuracy. Accuracy of traditional inference and our multi-agent debate over six benchmarks (chess move optimality reported as a normalized score)\n\n<!-- image -->\n\nlight of the responses of other agents. The resulting quorum of models can hold and maintain multiple chains of reasoning and possible answers simultaneously before proposing the final answer.\n\nWe find that our debate approach outperforms single model baselines such as zero-shot chain of thought [11] and reflection [26, 18] on a variety of six reasoning, factuality, and question-answering tasks. Using both multiple model agents and multiple rounds of debate are important to achieve the best performance. Given an initial query, we find that individual model instances propose a diverse range of answers despite being the same model class (although we also investigate the case of mixing different model types, such as chatGPT [21] and Bard [23]).",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "1 Introduction",
        "chunkIndex": 6,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-7",
      "content": "idual model instances propose a diverse range of answers despite being the same model class (although we also investigate the case of mixing different model types, such as chatGPT [21] and Bard [23]). After debating and examining the responses of other model instances, we find that the population almost always converges on a single and more accurate common answer. Debate results are also less likely to include false facts that models are internally uncertain of. This is because as the debate progresses, individual model instances tend to disagree on uncertain facts and omit them from the answer (Figure 7). Lastly, we find that debate does not just act to amplify one correct answer in a model quorum - we find many cases where all the models initially make incorrect predictions, but then arrive at the correct answer as debate progresses (Figure 4,11).",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "1 Introduction",
        "chunkIndex": 7,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-8",
      "content": "o amplify one correct answer in a model quorum - we find many cases where all the models initially make incorrect predictions, but then arrive at the correct answer as debate progresses (Figure 4,11).\n\nWe use the same methodology and prompt templates for all our tasks and require only black-box access to language model generations - no model-internal information such as likelihoods or gradients is needed. This allows our method to be used with common public models serving interfaces. The method is also orthogonal to other model generation improvements such as retrieval or prompt engineering (in fact, we combine our debate method with zero-shot chain of thought). While the debate process is more costly, requiring multiple model instances and rounds, it arrives at significantly improved answers and may be used to generate additional model training data, effectively creating a model self-improvement loop.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "1 Introduction",
        "chunkIndex": 8,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-9",
      "content": "uiring multiple model instances and rounds, it arrives at significantly improved answers and may be used to generate additional model training data, effectively creating a model self-improvement loop.\n\nTo help evaluate the effect of our approach on factual accuracy, we introduce a new benchmark and dataset evaluating factual accuracy of famous computer scientist biographies. We find that contemporary language models have an especially high tendency to hallucinate factually incorrect biographies, often misrepresenting the relevant institutions and dates. Moreover, these facts often inconsistent across different language model instances. By asking models to come to a consensus across their answers, such inconsistent facts may be either removed or corrected.\n\nIn summary, our work contributes the following. First, we present a novel approach to improving factual correctness and reasoning accuracy in contemporary language models, leveraging a multiagent debate process between models.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "1 Introduction",
        "chunkIndex": 9,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-10",
      "content": "ibutes the following. First, we present a novel approach to improving factual correctness and reasoning accuracy in contemporary language models, leveraging a multiagent debate process between models. Second, we introduce a new benchmark of factual correctness which contemporary language models struggle with. Finally, we evaluate the performance of our debate procedure in language generation, both in terms of the number of agents, the underlying rounds of debate, and the prompts that elicit such behavior across a set of six different reasoning and factual accuracy tasks.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "1 Introduction",
        "chunkIndex": 10,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-11",
      "content": "We present an approach to generate language responses through multiagent debate. We provide an overview of our approach in Section 2.1. We further discuss convergence to consensus in the debate process in Section 2.2. The overall overview of our approach is shown in Figure 2.\n\nFigure 2: Illustration of Debate. Illustration of the debate procedure.\n\n<!-- image -->",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "2 Language Generation through Multiagent Debate",
        "chunkIndex": 11,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-12",
      "content": "Consider your work process when solving the following math question on an exam: 'What is the area of a triangle with side lengths of 3, 4, 5?\" . In one thread of work, you may recognize that the triangle side-lengths directly correspond to a right triangle, and thus directly compute the area as 0 . 5 × 3 × 4 = 64 . To make sure that you have the right answer, you may then try to solve the problem differently by estimating an angle θ in the triangle using the Law of Cosines, and then obtain the area by using the formula 0 . 5 × 3 × 4 × sin( θ ) , arriving at another answer to the given exam problem.\n\nWhen these lines of work give the same answer, your confidence about the answer increases. In contrast, when these answers are different, individual lines of work may engage in a mental 'debate\" procedure, where you closely cross-examine the reasoning and assumptions of each line of work and refine solutions until a consistent answer.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "2.1 Multiagent Language Generation",
        "chunkIndex": 12,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-13",
      "content": ", individual lines of work may engage in a mental 'debate\" procedure, where you closely cross-examine the reasoning and assumptions of each line of work and refine solutions until a consistent answer.\n\nSimilarly, consider writing a biography of a historical figure. To ensure the factuality of the biography, you may consult multiple different sources on each fact. Facts that are consistent in each source increase your confidence about the fact. In contrast, facts that are inconsistent require careful cross-examination between sources to determine the final consistent data.\n\nFigure 3: Prompts to induce long and short form debate. Responses of other agents to questions are are inserted in the middle of the prompt (indicated with [other answers] )\n\n| Debate Length   | Prompt                                                                                                                                                                       |\n|-----------------|-------------------------------",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "2.1 Multiagent Language Generation",
        "chunkIndex": 13,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-14",
      "content": "|\n|-----------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Short           | \" These are the solutions to the problem from other agents: [other answers] Based off the opinion of other agents, can you give an updated response . . . \"                  |\n| Long            | \" These are the solutions to the problem from other agents: [other answers] Using the opinion of other agents as additional advice, can you give an updated response . . . \" |\n\nTo mimic the above multi-threaded reasoning process and multi-source factuality checking processes, we propose to generate answers subject to a multi-agent debate procedure between multiple instances of large language models.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "2.1 Multiagent Language Generation",
        "chunkIndex": 14,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-15",
      "content": "threaded reasoning process and multi-source factuality checking processes, we propose to generate answers subject to a multi-agent debate procedure between multiple instances of large language models. Given a question, multiple agents represented as copies of a large language model, generate answers to the question. Each response serves as a possible thought process or source of information which agents may re-examine to find consistent final answers.\n\nAfter initial responses are generated from different agents, we initiate a round of debate between agents. Individual responses from other agents are concatenated and given as context to each agent, with each agent instructed to construct a new response based on such responses. Each language agent is thus responsible for both verifying the collection of responses given by other agents, and refining its own response based on other agents' responses.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "2.1 Multiagent Language Generation",
        "chunkIndex": 15,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-16",
      "content": "e based on such responses. Each language agent is thus responsible for both verifying the collection of responses given by other agents, and refining its own response based on other agents' responses. We iteratively repeat this debate procedure over multiple rounds for improved performance.\n\nConcretely, we first prompt each agent to independently solve the given problem or task. After each agent generates a response, we feed each agent a consensus prompt, illustrated in Figure 3, where each agent is instructed to update their responses based on the responses of other agents. This resultant consensus prompt may then be repeatedly given, using the updated responses of each agent. We illustrate an overview of this multiagent debate procedure in Figure 2.\n\nNote that our proposed approach operates in an orthogonal manner to existing approaches to prompt language models.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "2.1 Multiagent Language Generation",
        "chunkIndex": 16,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-17",
      "content": "ch agent. We illustrate an overview of this multiagent debate procedure in Figure 2.\n\nNote that our proposed approach operates in an orthogonal manner to existing approaches to prompt language models. Given a question, we may apply additional techniques for prompting language models to further improve our debate procedure by eliciting additional more detailed responses from language models. We illustrate the synergy of our approach with existing approaches to prompting language models in Figure 6 and directly apply zero-shot chain-of-thought reasoning in our evaluations.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "2.1 Multiagent Language Generation",
        "chunkIndex": 17,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-18",
      "content": "Given multiple rounds of debate, how can we ensure that a set of language model agents will converge to a final consensus answer? In general, debate can be seen as a multi-agent game, where convergence is not guaranteed. Empirically, however, we find that language models are able to converge on a single shared answer after multiple rounds of debate (Figure 4).\n\nWe found that we could control the duration of debates by how changing how much a language model trusts its own outputs over those generated by other models through different prompts. We illustrate two prompts below in Figure 3, which we use to induce different debate durations between language models, and illustrate the effect of such prompts in Figure 12. In general, we found that prompts that encouraged models to be more 'stubborn' based on their own solutions led to longer debates and better final solutions.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "2.2 Consensus in Debates",
        "chunkIndex": 18,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-19",
      "content": "e the effect of such prompts in Figure 12. In general, we found that prompts that encouraged models to be more 'stubborn' based on their own solutions led to longer debates and better final solutions. Overall, we observed that language model agents were relatively \"agreeable\", perhaps as a result of instruction tuning or reinforcement learning based on human feedback [22].",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "2.2 Consensus in Debates",
        "chunkIndex": 19,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-20",
      "content": "In our experiments, we evaluate our multiagent debate procedure and answer the following questions: (1) To what extent does multiagent debate improve reasoning? (2) To what extent does multiagent debate improve factual validity? (3) What design choices enable multiagent debate to improve language generation performance?",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3 Experiments",
        "chunkIndex": 20,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-21",
      "content": "We first evaluate the extent to which multiagent debate improves the underlying reasoning process in language models.\n\nTasks. We evaluate our approach on three reasoning tasks of increasing difficulty:\n\nFigure 5: Illustration of Solving Grade School Math. Reasoning between agents omitted.\n\n<!-- image -->\n\n- Arithmetic. We first evaluate the ability of models to correctly evaluate an arithmetic expression (containing addition, multiplication, and subtraction) consisting of six different two-digit numbers. For example: What is the result of 12+15*21+0-3*27?\n- GSM8K. Next, we consider harder mathematical reasoning tasks. Using the GSM8K dataset [3], the models must correctly solve grade school mathematical reasoning tasks.\n- Chess Move Prediction. Finally, we consider the strategic reasoning of the ability of models, and ask models to predict the best next move in a game of chess, given the first 14 moves of a chess game between two chess grand-masters described in PGN notation [6].",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.1 Improving Reasoning with Multiagent Debate",
        "chunkIndex": 21,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-22",
      "content": "oning of the ability of models, and ask models to predict the best next move in a game of chess, given the first 14 moves of a chess game between two chess grand-masters described in PGN notation [6].\n\nWe report the accuracy of final answers in arithmetic and GSM8K tasks and report the pawn score (advantage) of predicted moves, as estimated by Stockfish in the Chess move prediction tasks. Additional details may be found in the Appendix.\n\nBaselines. We compare our approach to three alternative approaches to generate responses for reasoning problems. First, we ask agents to directly generate responses (single agent). Next, we consider asking language models to generate and then \"self-reflect\" on the responses generated [26, 18]. Finally, we consider generating responses using multiple agents and performing majority voting [15, 3].",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.1 Improving Reasoning with Multiagent Debate",
        "chunkIndex": 22,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-23",
      "content": "asking language models to generate and then \"self-reflect\" on the responses generated [26, 18]. Finally, we consider generating responses using multiple agents and performing majority voting [15, 3]. As the focus of our experiments is to verify the effectiveness of multiagent agent debate, we run both baselines and our approach, using the identical starting prompt and language model across all evaluations. We evaluate models in a zero-shot setting, with prompts found in the Appendix of the paper.\n\nFigure 6: Synergy with Other Methods. Performance of debate increases with use of Chain of Thought prompting.\n\n<!-- image -->\n\nWe use chatGPT-based language model [21] in all our experiments except those in Figure 11 where we compare multiple language models.\n\nDue to computational expense, we evaluate our approach across benchmarks mainly using three agents with two rounds of debates, although we found further gains with both more agents and rounds of debate (Figure 10).",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.1 Improving Reasoning with Multiagent Debate",
        "chunkIndex": 23,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-24",
      "content": "tional expense, we evaluate our approach across benchmarks mainly using three agents with two rounds of debates, although we found further gains with both more agents and rounds of debate (Figure 10). Additional evaluation details are found in the Appendix.\n\nQuantitative Results. In Table 1, we report the results of each approach on arithmetic, grade school math, and chess reasoning task. In each task, we observe that utilizing multiple different agents to generate solutions improves performance over using a single language model agent to generate a solution. Simultaneously, we also see that reflection, where a language model is asked to critique its early generation, generally gives a modest boost in performance. Multiagent debate, which may be seen as a combination of both reflection and multiagent generation, gives a substantial boost in reasoning across each of the tasks.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.1 Improving Reasoning with Multiagent Debate",
        "chunkIndex": 24,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-25",
      "content": "ives a modest boost in performance. Multiagent debate, which may be seen as a combination of both reflection and multiagent generation, gives a substantial boost in reasoning across each of the tasks.\n\nTable 1: Multiagent Debate Improves Reasoning Multi-agent debate improves the reasoning abilities of language models. Multi-agent results in the table are run with 3 agents and two rounds of debate.\n\n| Model                     | Arithmetic (%) ↑   | Grade School Math (%) ↑   | Chess ( ∆ PS) ↑   |\n|---------------------------|--------------------|---------------------------|-------------------|\n| Single Agent              | 67.0 ± 4.7         | 77.0 ± 4.2                | 91.4 ± 10.6       |\n| Single Agent (Reflection) | 72.1 ± 4.5         | 75.0 ± 4.3                | 102.1 ± 11.9      |\n| Multi-Agent (Majority)    | 69.0 ± 4.6         | 81.0 ± 3.9                | 102.2 ± 6.2       |\n| Multi-Agent (Debate)      | 81.8 ± 2.3         | 85.0 ± 3.5                | 122.9 ± 7.6       |",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.1 Improving Reasoning with Multiagent Debate",
        "chunkIndex": 25,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-26",
      "content": "|\n| Multi-Agent (Majority)    | 69.0 ± 4.6         | 81.0 ± 3.9                | 102.2 ± 6.2       |\n| Multi-Agent (Debate)      | 81.8 ± 2.3         | 85.0 ± 3.5                | 122.9 ± 7.6       |\n\nPrompt: Give a bullet point biography of David S. Johnson highlighting their contributions and achievements as a computer scientist, with each fact separated with a new line character.\n\nFigure 7: Illustration of Generating Biographies. Illustration of generating bullet biographies of computer scientists. For brevity, only the first 3 generated bullets are shown.\n\n<!-- image -->\n\nQualitative Results. In Figure 4, 5, we provide qualitative illustrations of the debate procedure between models. Interestingly, we find cases in which all models initially give an incorrect response, yet the result of debate still obtains the correct answer as agents critique each others' reasoning.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.1 Improving Reasoning with Multiagent Debate",
        "chunkIndex": 26,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-27",
      "content": "ween models. Interestingly, we find cases in which all models initially give an incorrect response, yet the result of debate still obtains the correct answer as agents critique each others' reasoning. Thus, the purpose of our debate isn't just to amplify a correct answer - all models can initially be wrong but arrive at the correct answer through the debate process.\n\nCompatibility with other reasoning methods. Our multiagent generation procedure operates orthogonally approach to other prompting methods which focus on single-agent generation. In Figure 6, we illustrate the performance of multi-agent debate with and without zero-shot chain-ofthought prompting [11] on GSM8K. In both settings, multiagent generation is beneficial.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.1 Improving Reasoning with Multiagent Debate",
        "chunkIndex": 27,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-28",
      "content": "We next evaluate the extent to which multiagent debate improves the underlying factuality in language models.\n\nTasks. We evaluate the factuality of language models in three different settings:\n\n- Biographies. To evaluate the factuality of language models, we introduce a novel task of accurately generating historical biographies of people. In preliminary testing, we found that existing language models had a tendency to hallucinate many facts on this task. We constructed ground truth bullet point biographies of 524 well-known computer scientists. We then asked language models to generate bullet point biographies for each person, and evaluated the accuracy at which each ground truth bullet point agreed with generated bullets. We report additional evaluation details in the Appendix.\n\nFigure 8: Illustration of MMLU. Illustration of debate when answering factual tasks. Reasoning omitted.\n\n<!-- image -->",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.2 Extracting Factual Information from Multiagent Debate",
        "chunkIndex": 28,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-29",
      "content": "ith generated bullets. We report additional evaluation details in the Appendix.\n\nFigure 8: Illustration of MMLU. Illustration of debate when answering factual tasks. Reasoning omitted.\n\n<!-- image -->\n\nTable 2: Multiagent Debate Improves Factual Accuracy Multi-agent debate improves the factual accuracy.\n\n| Model                     | Biographies   | MMLU       | Chess Move Validity   |\n|---------------------------|---------------|------------|-----------------------|\n| Single Agent              | 66.0 ± 2.2    | 63.9 ± 4.8 | 29.3 ± 2.6            |\n| Single Agent (Reflection) | 68.3 ± 2.9    | 57.7 ± 5.0 | 38.8 ± 2.9            |\n| Multi-Agent (Debate)      | 73.8 ± 2.3    | 71.1 ± 4.6 | 45.2 ± 2.9            |\n\n- MMLU. Next, we assess the factuality of language models in responding to different factual knowledge questions typically learned and assessed in different exams. We utilize the existing MMLU dataset [8] to benchmark the accuracy of responses.\n- Chess Move Validity.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.2 Extracting Factual Information from Multiagent Debate",
        "chunkIndex": 29,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-30",
      "content": "ding to different factual knowledge questions typically learned and assessed in different exams. We utilize the existing MMLU dataset [8] to benchmark the accuracy of responses.\n- Chess Move Validity. Lastly, we study the hallucinations in language models when planning under to the given rules of an existing environment or game. Specifically, we measure the validity of possible moves in a game of Chess given by BIG-Bench Chess-State Tracking Benchmark [27] task of chess-move prediction. In this task, an agent is given a set of next moves, and must make a valid next move of a piece on a board.\n\nBaselines. We use the same baselines as in Section 3.1. The multiagent (majority) is not directly applicable in this setting as individual responses are not easily comparable, and so we omit baseline comparison with the majority voting in this setting.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.2 Extracting Factual Information from Multiagent Debate",
        "chunkIndex": 30,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-31",
      "content": ".1. The multiagent (majority) is not directly applicable in this setting as individual responses are not easily comparable, and so we omit baseline comparison with the majority voting in this setting.\n\nResults. We analyze the performance of each method in Table 2. We found that approaches based on reflection led to poor performance in the factuality setting. In contrast, debate gives the best performance in this setting also, and significantly outperforms each baseline. We illustrate a debate between agents on the biography task in Figure 7 and on MMLU in Figure 8. We found that multiagent debate improved and settled on bullets that were more consistent across agents.\n\nWe found that different language agents tended to give different answers when the underlying language model was uncertain about the question. However, directly asking each agent about their confidence [10] of the answer led to high confidence assessments on each answer.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.2 Extracting Factual Information from Multiagent Debate",
        "chunkIndex": 31,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-32",
      "content": "rs when the underlying language model was uncertain about the question. However, directly asking each agent about their confidence [10] of the answer led to high confidence assessments on each answer. However, when these different language agents were asked to communicate with each other, each agent would quickly change their opinion to a consensus answer which was more accurate. We illustrate this in Figure 9. Interestingly, we found that on facts that the language model was confident in (i.e. many instances of the same model all gave the same answer), it was very difficult to convince an agent to change their opinion, suggesting that 'ease of persuasion' may be a method to assess factual confidence.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.2 Extracting Factual Information from Multiagent Debate",
        "chunkIndex": 32,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-33",
      "content": "Finally, we analyze how multiagent debate improves the underlying language generation procedure in language models.\n\nNumber of Agents. First, we analyze the impact of agents number in debate. In Figure 10(a), we increase the number of agents used in debate, while fixing the debate length to be two. On arithmetic, performance monotonically increases with the increased number of agents. For larger number of agents, we first summarize all agent responses with chatGPT instead of directly concatenating responses due to context length error.\n\nRounds of Debate Next, we analyze the impact of the number of rounds of debate in multiagent debate. In Figure 10(b), we increase the debate length between agents, while fixing the number of agents to three. We find that on the arithmetic task, the performance also monotonically increases with debate length. However, we found that additional debate rounds above four led to a similar final performance to 4 rounds of debate.\n\nRound 1\n\nRound 2",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.3 Analysis: Understanding Multiagent Debate",
        "chunkIndex": 33,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-34",
      "content": "the performance also monotonically increases with debate length. However, we found that additional debate rounds above four led to a similar final performance to 4 rounds of debate.\n\nRound 1\n\nRound 2\n\nPrompt: What country was the computer scientist Tomas Lozano-Perez born in?\n\nAgent 1: Tomas Lozano-Perez, a renowned computer scientist, was born in Spain.\n\n<!-- image -->\n\n<!-- image -->\n\nAgent 2: Tomas Lozano-Perez, a renowned computer scientist, was born in Havana, Cuba.\n\n<!-- image -->\n\nAgent 2: I apologize for the conflicting responses. Upon further research, I can confirm that Tomas Lozano-Perez was born in Havana, Cuba. ✓\n\nAgent 1: I apologize for the confusion. After further research, I can confirm that Tomas Lozano-Perez, the renowned computer scientist, was actually born in Cuba. Thank you for bringing this to my attention.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.3 Analysis: Understanding Multiagent Debate",
        "chunkIndex": 34,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-35",
      "content": ": I apologize for the confusion. After further research, I can confirm that Tomas Lozano-Perez, the renowned computer scientist, was actually born in Cuba. Thank you for bringing this to my attention.\n\nFigure 9: Expressing Uncertainty with Multiple Answers. For facts that a language model is uncertain about, different language agents generate different facts. Debate causes agents to converge to one fact that is more accurate, but not necessarily always factually correct.\n\n<!-- image -->\n\nFigure 10: (a) Performance with Increased Agents. Performance improves as the number of underlying agents involved in debate increases. (b) Performance with Increased Rounds. Performance rises as the number of rounds of underlying debate increases. Performance vs Number of Debating Agents\n\n<!-- image -->\n\nEffect of Debate Length on Accuracy As discussed in Section 2.2, the underlying convergence time in the debate between agents can be controlled by the extent to which agents are encouraged to maintain",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.3 Analysis: Understanding Multiagent Debate",
        "chunkIndex": 35,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-36",
      "content": "Effect of Debate Length on Accuracy As discussed in Section 2.2, the underlying convergence time in the debate between agents can be controlled by the extent to which agents are encouraged to maintain their opinions. In Figure 12, we consider the effect of short and long-form prompts discussed in Figure 3. We find that debates using longer prompts lead to slower convergence to correct answers, but also lead to a better final consensus on the correct answer. We provide an analysis of consensus between agents in Figure 14.\n\nUsing Different Initialization Prompts In our experiments we use the same prompts for all agents. We\n\nFigure 12: Performance vs Debate Length. Prompts which induce longer debate improve performance.\n\n<!-- image -->\n\nalso consider the effect of using different questions, where we first instruct each language model to behave like a different persona (professor, doctor, mathematician) on the MMLU dataset.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.3 Analysis: Understanding Multiagent Debate",
        "chunkIndex": 36,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-37",
      "content": "image -->\n\nalso consider the effect of using different questions, where we first instruct each language model to behave like a different persona (professor, doctor, mathematician) on the MMLU dataset. We found that improved performance on MMLU from 71.1 to 74.2 with different agents, suggesting further gains can be obtained with different initialization prompts.\n\nSummarization. While in the majority of experiments in the paper we directly concatenate the responses of other agents as context for an agent to generate a new response, this is expensive when the number of agents involved in debate gets large. We may alternatively first summarize the responses from all other agents into a single response that we provide to agent at each round for more efficient debate. We apply this strategy in Figure 10 to enable the use of five or more agents in debate. In Figure 13, we analyze the effect compared to directly concatenating the responses of other agents.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.3 Analysis: Understanding Multiagent Debate",
        "chunkIndex": 37,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-38",
      "content": "nt debate. We apply this strategy in Figure 10 to enable the use of five or more agents in debate. In Figure 13, we analyze the effect compared to directly concatenating the responses of other agents. We find this improves the performance of debate, suggesting that summarization is another tool that can further improve multiagent debate.\n\nFigure 13: Effect of Summarization. When there are many agents in a debate, responses from other agents may be first summarized and then given as context, reducing context length. This operation improves performance.\n\n<!-- image -->\n\nUtilizing Different Language Models Our existing debate results are reported using multiple instances of a chatGPT language model. We further assess\n\nQuestion: Carla is downloading a 200 GB file. Normally she can download 2 GB/minute, but 40% of the way through the download, Windows forces a restart to install updates, which takes 20 minutes. Then Carla has to restart the download from the beginning.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.3 Analysis: Understanding Multiagent Debate",
        "chunkIndex": 38,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-39",
      "content": "y she can download 2 GB/minute, but 40% of the way through the download, Windows forces a restart to install updates, which takes 20 minutes. Then Carla has to restart the download from the beginning. How load does it take to download the file?\n\nFigure 11: Debate Between chatGPT and Bard Illustration of debate between different models.\n\n<!-- image -->\n\nthe impact of using two different language models, where we ask chatGPT and Bard [23] language models to debate with each other on a set of 20 GSM8K math problems. In this set, we find that multi-agent debate improves the performance of both agents, with Bard solving 11 problems, chatGPT solving 14 problems, and joint multi-agent debate solving 17 problems. We qualitatively illustrate a debate between agents in Figure 11. While both agents initially provide incorrect answers to the problem, chatGPT is able to utilize the incorrect response given by Bard to generate the final correct answer.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.3 Analysis: Understanding Multiagent Debate",
        "chunkIndex": 39,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-40",
      "content": "nitially provide incorrect answers to the problem, chatGPT is able to utilize the incorrect response given by Bard to generate the final correct answer.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "3.3 Analysis: Understanding Multiagent Debate",
        "chunkIndex": 40,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-41",
      "content": "Reasoning and Factuality in Language Models. A wide range of work has explored how to enable reasoning and factuality in language models. To improve reasoning, approaches have relied on prompting techniques such as scratchpads [20], verification [3], chain-of-thought demonstrations [30, 11, 25], and intermediate self-reflection [26, 18] and finetuning [13, 24, 31]. To improve factuality, approaches have relied on training techniques such as RLHF [33, 16, 2], pruning truthful datasets [12], external knowledge retrieval [7] and training-free methods based off likelihood estimation [10].\n\nOur work provides an alternative way to obtain reasoning and factuality in language models using multiagent debates, which only requires black-box access to a language generator. Prior work also has explored how to take the majority vote across different models [15, 3, 29, 28] while in this work, we use the power of a language model to combine different answers. Most similar to our work, Irving et al.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "4 Related Work",
        "chunkIndex": 41,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-42",
      "content": "red how to take the majority vote across different models [15, 3, 29, 28] while in this work, we use the power of a language model to combine different answers. Most similar to our work, Irving et al. [9] also proposes a debate procedure to verify the accuracy and safety of powerful AI agents. In contrast to our approach, in their work, agents are asked to alternatively provide proof of a input, and humans are tasked with assessing these debates and determining safety.\n\nCompositional Generation. Our work is also related to existing works that focus on text generation by combining different models [4, 17, 32, 1, 5]. Most similar to our work, [14, 32] propose to combine multiple different large pretrained models together for multimodal reasoning. In contrast, in our work, we aim to use communication between different language models to enable more effective reasoning and factuality in language models.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "4 Related Work",
        "chunkIndex": 42,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-43",
      "content": "nication between different language models to enable more effective reasoning and factuality in language models.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "4 Related Work",
        "chunkIndex": 43,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-44",
      "content": "In this paper, we present an orthogonal approach to improve the performance of language models using multi-agent debate. We find that the approach is simple and effective across a wide set of different reasoning and validity language modeling tasks.\n\nLimitations. In comparison to other prompting techniques, our multiagent debate procedure is more computationally expensive, as it requires both multiple language generations, and an underlying debate procedure. However, we believe that this approach may be seen as a method to generate additional data that may be distilled back to self-improve the original base model.\n\nFurther, we observed that as debates became longer in duration, current language models sometimes struggled to fully process the entire debate input, and typically only focused on the most recent generations. We believe that this performance will be alleviated with longer-context and improved language models or by summarizing early portions of the debate.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "5 Limitations and Discussion",
        "chunkIndex": 44,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-45",
      "content": "ically only focused on the most recent generations. We believe that this performance will be alleviated with longer-context and improved language models or by summarizing early portions of the debate.\n\nFinally, we found that while debates typically converged into single final answers, these answers were not necessarily correct. Despite answers being incorrect, language models would confidently affirm that their answer is correct and consistent with all other agent responses. We believe this result is in part due to the fact that LMs do not correctly express their uncertainty when generating responses, and believe that other orthogonal approaches to improve this performance would improve the results of multiagent debate.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "5 Limitations and Discussion",
        "chunkIndex": 45,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-46",
      "content": "- [1] J.-B. Alayrac, J. Donahue, P. Luc, A. Miech, I. Barr, Y . Hasson, K. Lenc, A. Mensch, K. Millican, M. Reynolds, et al. Flamingo: A visual language model for few-shot learning. NeurIPS , 2022. URL https://arxiv.org/abs/2204.14198 . 9\n- [2] P. F. Christiano, J. Leike, T. Brown, M. Martic, S. Legg, and D. Amodei. Deep reinforcement learning from human preferences. In Neural Information Processing Systems , 2017. 9\n- [3] K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser, M. Plappert, J. Tworek, J. Hilton, R. Nakano, et al. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168 , 2021. 5, 9\n- [4] Y. Du, S. Li, and I. Mordatch. Compositional visual generation with energy based models. In Advances in Neural Information Processing Systems , 2020. 9\n- [5] Y. Du, C. Durkan, R. Strudel, J. B. Tenenbaum, S. Dieleman, R. Fergus, J. Sohl-Dickstein, A. Doucet, and W. Grathwohl.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "References",
        "chunkIndex": 46,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-47",
      "content": "ased models. In Advances in Neural Information Processing Systems , 2020. 9\n- [5] Y. Du, C. Durkan, R. Strudel, J. B. Tenenbaum, S. Dieleman, R. Fergus, J. Sohl-Dickstein, A. Doucet, and W. Grathwohl. Reduce, reuse, recycle: Compositional generation with energybased diffusion models and mcmc. arXiv preprint arXiv:2302.11552 , 2023. 9\n- [6] Fsmosca. Fsmosca/pgn-standard: Portable game notation specification and implementation guide. URL https://github.com/fsmosca/PGN-Standard . 5\n- [7] K. Guu, K. Lee, Z. Tung, P. Pasupat, and M.-W. Chang. REALM: Retrieval-augmented language model pre-training. arXiv preprint arXiv:2002.08909 , 2020. 9\n- [8] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt. Measuring massive multitask language understanding. arXiv preprint arXiv:2009.03300 , 2020. 7\n- [9] G. Irving, P. Christiano, and D. Amodei. Ai safety via debate. arXiv preprint arXiv:1805.00899 , 2018. 9\n- [10] S. Kadavath, T. Conerly, A. Askell, T. Henighan, D.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "References",
        "chunkIndex": 47,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-48",
      "content": "int arXiv:2009.03300 , 2020. 7\n- [9] G. Irving, P. Christiano, and D. Amodei. Ai safety via debate. arXiv preprint arXiv:1805.00899 , 2018. 9\n- [10] S. Kadavath, T. Conerly, A. Askell, T. Henighan, D. Drain, E. Perez, N. Schiefer, Z. H. Dodds, N. DasSarma, E. Tran-Johnson, et al. Language models (mostly) know what they know. arXiv preprint arXiv:2207.05221 , 2022. 7, 9\n- [11] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa. Large language models are zero-shot reasoners. arXiv preprint arXiv:2205.11916 , 2022. 2, 6, 9\n\n- [12] N. Lee, W. Ping, P. Xu, M. Patwary, P. N. Fung, M. Shoeybi, and B. Catanzaro. Factuality enhanced language models for open-ended text generation. Advances in Neural Information Processing Systems , 35:34586-34599, 2022. 9\n- [13] A. Lewkowycz, A. Andreassen, D. Dohan, E. Dyer, H. Michalewski, V. Ramasesh, A. Slone, C. Anil, I. Schlag, T. Gutman-Solo, et al. Solving quantitative reasoning problems with language models. arXiv preprint arXiv:2206.14858 , 2022.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "References",
        "chunkIndex": 48,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-49",
      "content": "Dohan, E. Dyer, H. Michalewski, V. Ramasesh, A. Slone, C. Anil, I. Schlag, T. Gutman-Solo, et al. Solving quantitative reasoning problems with language models. arXiv preprint arXiv:2206.14858 , 2022. 9\n- [14] S. Li, Y. Du, J. B. Tenenbaum, A. Torralba, and I. Mordatch. Composing ensembles of pre-trained models via iterative consensus. arXiv preprint arXiv:2210.11522 , 2022. 9\n- [15] Y. Li, D. Choi, J. Chung, N. Kushman, J. Schrittwieser, R. Leblond, T. Eccles, J. Keeling, F. Gimeno, A. Dal Lago, et al. Competition-level code generation with alphacode. Science , 378 (6624):1092-1097, 2022. 5, 9\n- [16] H. Liu, L. Lee, K. Lee, and P. Abbeel. Instruction-following agents with jointly pre-trained vision-language models. arXiv preprint arXiv:2210.13431 , 2022. 9\n- [17] N. Liu, S. Li, Y. Du, A. Torralba, and J. B. Tenenbaum. Compositional visual generation with composable diffusion models. arXiv preprint arXiv:2206.01714 , 2022. 9\n- [18] A. Madaan, N. Tandon, P. Gupta, S. Hallinan, L.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "References",
        "chunkIndex": 49,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-50",
      "content": "Du, A. Torralba, and J. B. Tenenbaum. Compositional visual generation with composable diffusion models. arXiv preprint arXiv:2206.01714 , 2022. 9\n- [18] A. Madaan, N. Tandon, P. Gupta, S. Hallinan, L. Gao, S. Wiegreffe, U. Alon, N. Dziri, S. Prabhumoye, Y. Yang, et al. Self-refine: Iterative refinement with self-feedback. arXiv preprint arXiv:2303.17651 , 2023. 2, 5, 9\n- [19] M. Minsky. Society of mind . Simon and Schuster, 1988. 1\n- [20] M. Nye, A. J. Andreassen, G. Gur-Ari, H. Michalewski, J. Austin, D. Bieber, D. Dohan, A. Lewkowycz, M. Bosma, D. Luan, et al. Show your work: Scratchpads for intermediate computation with language models. arXiv preprint arXiv:2112.00114 , 2021. 9\n- [21] OpenAI. Chatgpt: Optimizing language models for dialogue, Dec 2022. URL https:// openai.com/blog/chatgpt/ . 2, 5\n- [22] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "References",
        "chunkIndex": 50,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-51",
      "content": "models for dialogue, Dec 2022. URL https:// openai.com/blog/chatgpt/ . 2, 5\n- [22] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al. Training language models to follow instructions with human feedback. arXiv preprint arXiv:2203.02155 , 2022. 4\n- [23] S. Pichai. An important next step on our ai journey, Feb 2023. URL https://blog.google/ technology/ai/bard-google-ai-search-updates/ . 2, 9\n- [24] N. F. Rajani, B. McCann, C. Xiong, and R. Socher. Explain yourself! leveraging language models for commonsense reasoning. arXiv preprint arXiv:1906.02361 , 2019. 9\n- [25] L. Reynolds and K. McDonell. Prompt programming for large language models: Beyond the few-shot paradigm. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems , pages 1-7, 2021. 9\n- [26] N. Shinn, B. Labash, and A. Gopinath. Reflexion: an autonomous agent with dynamic memory and self-reflection.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "References",
        "chunkIndex": 51,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-52",
      "content": "the 2021 CHI Conference on Human Factors in Computing Systems , pages 1-7, 2021. 9\n- [26] N. Shinn, B. Labash, and A. Gopinath. Reflexion: an autonomous agent with dynamic memory and self-reflection. arXiv preprint arXiv:2303.11366 , 2023. 2, 5, 9\n- [27] A. Srivastava, A. Rastogi, A. Rao, A. A. M. Shoeb, A. Abid, A. Fisch, A. R. Brown, A. Santoro, A. Gupta, A. Garriga-Alonso, et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. arXiv preprint arXiv:2206.04615 , 2022. 7, 14\n- [28] R. Thoppilan, D. De Freitas, J. Hall, N. Shazeer, A. Kulshreshtha, H.-T. Cheng, A. Jin, T. Bos, L. Baker, Y. Du, et al. Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239 , 2022. 9\n- [29] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, and D. Zhou. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171 , 2022. 9\n- [30] J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. Chi, Q. Le, and D.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "References",
        "chunkIndex": 52,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-53",
      "content": ", and D. Zhou. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171 , 2022. 9\n- [30] J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. Chi, Q. Le, and D. Zhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903 , 2022. 9\n\n- [31] E. Zelikman, Y. Wu, J. Mu, and N. Goodman. Star: Bootstrapping reasoning with reasoning. Advances in Neural Information Processing Systems , 35:15476-15488, 2022. 9\n- [32] A. Zeng, A. Wong, S. Welker, K. Choromanski, F. Tombari, A. Purohit, M. Ryoo, V. Sindhwani, J. Lee, V. Vanhoucke, et al. Socratic models: Composing zero-shot multimodal reasoning with language. arXiv preprint arXiv:2204.00598 , 2022. URL https://arxiv.org/abs/2204. 00598 . 9\n- [33] D. M. Ziegler, N. Stiennon, J. Wu, T. B. Brown, A. Radford, D. Amodei, P. Christiano, and G. Irving. Fine-tuning language models from human preferences. arXiv preprint arXiv:1909.08593 , 2019. 9",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "References",
        "chunkIndex": 53,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-54",
      "content": "Stiennon, J. Wu, T. B. Brown, A. Radford, D. Amodei, P. Christiano, and G. Irving. Fine-tuning language models from human preferences. arXiv preprint arXiv:1909.08593 , 2019. 9",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "References",
        "chunkIndex": 54,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-55",
      "content": "In this appendix, we provide additional analysis and visualizations of the debates used in the main paper in Section A.1. We further provide detailed experimental details on each dataset in Section A.2.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A Appendix",
        "chunkIndex": 55,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-56",
      "content": "Consensus Between Agents. In Figure 14, we illustrate the consensus between agents using either short or long consensus prompts discussed in Figure 3. The use of debate prompts that encourage agents to adapt more to the opinions of other agents improves consensus.\n\nAdditional Qualitative Visualizations. We added additional qualitative visualizations of the debate process. In Figure 16, Figure 17, Figure 18, Figure 19, Figure 20, we illustrate debates between agents in the GSM8K dataset which result in the correct answer. In Figure 21, Figure 22, Figure 23, we further illustrate debates in GSM8K which lead to the incorrect answer. We further provide an example illustration of debate in\n\nFigure 14: Effect of Prompts on Consensus. Using a short debate prompt induces faster consensus between agents\n\n<!-- image -->",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.1 Additional Results",
        "chunkIndex": 56,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-57",
      "content": "ncorrect answer. We further provide an example illustration of debate in\n\nFigure 14: Effect of Prompts on Consensus. Using a short debate prompt induces faster consensus between agents\n\n<!-- image -->\n\narithmetic in Figure 24, arithmetic with summarization of individual responses of agents in Figure 25, MMLUin Figure 26, a debate with the full contents biographies in Figure 27, and debate in chess in Figure 28. In general, we found that debate improved the performance of final generated answers, though sometimes answers would converge to the incorrect value.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.1 Additional Results",
        "chunkIndex": 57,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-58",
      "content": "We provided detailed evaluation details for each setting in the paper. We run all experiments using the gpt-3.5-turbo-0301 model. We provide a table listing the prompts used to prompt models and initialize debate in Table 15.\n\nArithmetic. To evaluate the arithmetic task, we generated six random integers for each task between 0 and 30. We then evaluated the extent to which the correct integer answer was correctly obtained. We evaluated models on one hundred generated arithmetic tasks.\n\nGrade School Math. To evaluate the GSM8K task, we evaluated the accuracy at which models were able to obtain the final correct answer, as extracted from a box. We evaluated models on one hundred grade school math problems.\n\nChess. To evaluate the chess reasoning task, we used chess games from https://www.pgnmentor. com/players/Adams.zip .",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.2 Evaluation Details",
        "chunkIndex": 58,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-59",
      "content": "tracted from a box. We evaluated models on one hundred grade school math problems.\n\nChess. To evaluate the chess reasoning task, we used chess games from https://www.pgnmentor. com/players/Adams.zip . We asked chatGPT to predict the next move for white to move at turn 14 and reported the relative Stockfish pawn score with search depth 20 after executing the suggested move from chatGPT. We evaluated models on three hundred selected chess games.\n\nBiographies. To evaluate the biographies task, we compare each generated bullet point biography for a person with a ground truth set of facts about the person extracted from Wikipedia. We iteratively loop through each ground truth fact, and validate the extent to which the generated biography matches a particular bullet by prompting chatGPT with the prompt: Consider the following biography of &lt;person&gt;: &lt;generated biography&gt; Is the above biography above consistent with the fact below? &lt;ground truth bullet&gt; Give a single-word ans",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.2 Evaluation Details",
        "chunkIndex": 59,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-60",
      "content": "prompt: Consider the following biography of &lt;person&gt;: &lt;generated biography&gt; Is the above biography above consistent with the fact below? &lt;ground truth bullet&gt; Give a single-word answer, yes, no, or uncertain. We then evaluate and report the percentage of ground bullets that chatGPT returns either yes or no on. We ignored ground truth bullets that chatGPT returns returned uncertain.\n\nWe found this evaluation metric provided a fast way to evaluate how relatively correct a generated bullet point biography is. However, we found that generated facts could contain incorrect information that was not captured in the ground truth bullet and thus could not be validated through this metric. Nevertheless, we believe this evaluation scheme estimates the relative accuracy of a generated biography.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.2 Evaluation Details",
        "chunkIndex": 60,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-61",
      "content": "s not captured in the ground truth bullet and thus could not be validated through this metric. Nevertheless, we believe this evaluation scheme estimates the relative accuracy of a generated biography.\n\nMMLU. To evaluate MMLU, we measured the accuracy in which models were able to select the correct multiple-choice answer in each problem. We evaluated models on one hundred selected MMLUquestions randomly distributed across each of the subject areas.\n\nFigure 15: Prompts in each task. List of prompts used in each task\n\n| Task           | Type     | Prompt                                                                                                                                                                                                                                                                                                                                                                                                                    |\n|----------------|----------|--------",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.2 Evaluation Details",
        "chunkIndex": 61,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-62",
      "content": "|\n|----------------|----------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Arithmetic     | Starting | What is the result of {}+{}*{}+{}-{}*{}? Make sure to state your answer at the end of the response.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.2 Evaluation Details",
        "chunkIndex": 62,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-63",
      "content": "|\n| Arithmetic     | Debate   | These are the recent/updated opinions from other agents: <other agent responses> Use these opinions carefully as additional advice, can you provide an updated answer? Make sure to state your answer at the end of the response.                                                                                                                                                                                         |\n| GSM8K          | Starting | Can you solve the following math problem? <Problem> Explain your reasoning. Your final answer should be a single numerical number, in the form \\boxed{{answer}}, at the end of your response.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.2 Evaluation Details",
        "chunkIndex": 63,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-64",
      "content": "Starting | Can you solve the following math problem? <Problem> Explain your reasoning. Your final answer should be a single numerical number, in the form \\boxed{{answer}}, at the end of your response.                                                                                                                                                                                                                             |\n| GSM8K          | Debate   | These are the solutions to the problem from other agents: <other agent responses> Using the solutions from other agents as additional information, can you provide your answer to the math problem? The original math problem is <Problem>. Your final answer should be a single numerical number, in the form \\boxed{{answer}}, at the end of your response.                                                             |\n| Chess          | Starting | Here is the current sequence of moves in a chess game: <moves>.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.2 Evaluation Details",
        "chunkIndex": 64,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-65",
      "content": "oxed{{answer}}, at the end of your response.                                                             |\n| Chess          | Starting | Here is the current sequence of moves in a chess game: <moves>. What is the best chess move I should execute next? Give a single move suggestion of the form 14. <XXX> and make sure the chess move is valid in the current board state.                                                                                                                                                                                  |\n| Chess          | Debate   | Here are other chess move suggestions from other agents: <other agent responses> Using the chess suggestions from other agents as additional advice and your earlier generated solution, can you give me your updated thoughts on the best next chess move I should play given the chess sequence ? Give a single move suggestion of the form 14. <XXX> and make sure the chess move is valid in the current board state.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.2 Evaluation Details",
        "chunkIndex": 65,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-66",
      "content": "ated thoughts on the best next chess move I should play given the chess sequence ? Give a single move suggestion of the form 14. <XXX> and make sure the chess move is valid in the current board state. |\n| Biographies    | Starting | Give a bullet point biography of highlighting their contributions and achievements as a computer scientist, with each fact separated with a new line character.                                                                                                                                                                                                                                                           |\n| Biographies    | Debate   | Here are some bullet point biographies of <person> given by other agents: <other agent response> Closely examine your biography and the biography of other agents and provide an updated bullet point biography.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.2 Evaluation Details",
        "chunkIndex": 66,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-67",
      "content": "some bullet point biographies of <person> given by other agents: <other agent response> Closely examine your biography and the biography of other agents and provide an updated bullet point biography.                                                                                                                                                                                                          |\n| MMLU           | Starting | Can you answer the following question as accurately as possible? : A) , B) , C) , D) Explain your answer, putting the answer in the form (X) at the end of your response.                                                                                                                                                                                                                                                 |\n| MMLU           | Debate   | These are the solutions to the problem from other agents: <other agent responses> Using the reasoning from other agents as a",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.2 Evaluation Details",
        "chunkIndex": 67,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-68",
      "content": "|\n| MMLU           | Debate   | These are the solutions to the problem from other agents: <other agent responses> Using the reasoning from other agents as additional advice, can you give an updated answer? Examine your solution and that other agents. Put your answer in the form (X) at the end of your response.                                                                                                                                   |\n| Chess Validity | Starting | Given the chess game , give one valid destination square for the chess piece at . State the destination square in the form (X), where X follows the regex [a-h][1-8], for example (e5). Give a one line explanation of why your destination square is a valid move.                                                                                                                                                       |\n| Chess Validity | Debate   | Here are destination square suggestions",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.2 Evaluation Details",
        "chunkIndex": 68,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-69",
      "content": "|\n| Chess Validity | Debate   | Here are destination square suggestions from other agents: <other agent responses> Can you double check that your destination square is a valid move? Check the valid move justifications from other agents. State your final answer in a newline with a 2 letter response following the regex [a-h][1-8].                                                                                                                |\n\nChess Validity. To evaluate chess validity, we consider the BIG-Bench Chess-State Tracking Benchmark [27], where we used the hardest reported task in the benchmark synthetic\\_short . Each generated answer was deemed correct as long as it was one of the valid answers in the sequence. We evaluated models of one hundred selected chess validity tasks.\n\nFigure 16: Example of a correct GSM8K Debate.\n\n<!-- image -->",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.2 Evaluation Details",
        "chunkIndex": 69,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-70",
      "content": "med correct as long as it was one of the valid answers in the sequence. We evaluated models of one hundred selected chess validity tasks.\n\nFigure 16: Example of a correct GSM8K Debate.\n\n<!-- image -->\n\nFigure 17: Example of Correct GSM8K Debate.\n\n<!-- image -->\n\nFigure 18: Example of Correct GSM8K Debate.\n\n<!-- image -->\n\nFigure 19: Example of Correct GSM8K Debate.\n\n<!-- image -->\n\nFigure 20: Example of Correct GSM8K Debate.\n\n<!-- image -->\n\nFigure 21: Example of Incorrect GSM8K Debate.\n\n<!-- image -->\n\nFigure 22: Example of Incorrect GSM8K Debate.\n\n<!-- image -->\n\nFigure 23: Example of Incorrect GSM8K Debate.\n\n<!-- image -->\n\nFigure 24: Example of Arithmetic Debate.\n\n<!-- image -->\n\nFigure 25: Example of Arithmetic Debate with Summarization. Four separate agents participate in debate, with two illustrated above. Instruction contains the summarized responses across agents.\n\n<!-- image -->\n\nFigure 26: Example of MMLU Debate.\n\n<!-- image -->",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.2 Evaluation Details",
        "chunkIndex": 70,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-71",
      "content": "Four separate agents participate in debate, with two illustrated above. Instruction contains the summarized responses across agents.\n\n<!-- image -->\n\nFigure 26: Example of MMLU Debate.\n\n<!-- image -->\n\nInstruction: Give a bullet point biography of Stephan R. Bourne highlighting their contributions and achievements as a computer scientist, with each fact separated by a new line character.\n\n| Round 1",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.2 Evaluation Details",
        "chunkIndex": 71,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-72",
      "content": "|\n|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.2 Evaluation Details",
        "chunkIndex": 72,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-73",
      "content": "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.2 Evaluation Details",
        "chunkIndex": 73,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-74",
      "content": "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Agent 1: - Stephen R. Bourne is a British-born American computer scientist. - He is best known for creating the Bourne shell (sh) for the Unix operating system in 1979.\\n- The Bourne shell was the default Unix shell for many years and is still in use today. - Bourne also worked on the development of the UNIX System III and IV operating systems. - He later joinedAT&T Bell Laboratories, where he worked on the UNIX System Voperating system and its derivatives. - Bourne was awarded theACM Software System Award in 1983 for his work on the Bourne shell.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.2 Evaluation Details",
        "chunkIndex": 74,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-75",
      "content": "ater joinedAT&T Bell Laboratories, where he worked on the UNIX System Voperating system and its derivatives. - Bourne was awarded theACM Software System Award in 1983 for his work on the Bourne shell. - He is also a recipient of the USENIX Lifetime Achievement Award (2001) and the IEEE Computer Pioneer Award (2010). - Bourne is now retired and continues to be involved in the computer science community. | Agent 2: . - Stephen R. Bourne is a computer scientist known for his development of the Unix shell, or command-line interface, known as the Bourne shell. - He earned a bachelor's degree in mathematics and a doctorate in computer science from Cambridge University. - Bourne worked at Bell Labs, where he helped to create the Unix operating system and its command- line interface. - In addition to the Bourne shell, he also created the Bourne-Again shell (bash) and was involved in the creation of the Korn shell.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.2 Evaluation Details",
        "chunkIndex": 75,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-76",
      "content": "o create the Unix operating system and its command- line interface. - In addition to the Bourne shell, he also created the Bourne-Again shell (bash) and was involved in the creation of the Korn shell. - Bourne was awarded the USENIX Lifetime Achievement Award in 1999 and was elected as a Fellow of the Association for Computing Machinery in 2013. - He has authored and co-authored numerous technical papers and books, including \"The Unix System,\" a widely used textbook on Unix programming. |\n\nInstruction: Here are  some bullet point biographies from other agents: (Copy Agent 2's reply) Using the biographies as additional information, can you give an updated  bullet point biography.\n\nInstruction: Here are  some bullet point biographies from other agents: (Copy Agent 1's reply) Using the biographies as additional information, can you give an updated  bullet point biography.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "A.2 Evaluation Details",
        "chunkIndex": 76,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-77",
      "content": "- -Stephen R. Bourne is a highly respected computer scientist and mathematician who revolutionized the computing field with his development of the Unix shell, popularly known as the Bourne shell.\n- -He earned his bachelor's degree in mathematics and a doctorate in computer science from Cambridge University, and began his career at Bell Labs where he played an integral role in the creation of the Unix operating system.\n- -During his tenure, Bourne developed the Bourne shell, which became the foundation for the Unix commandline interface.\n- -Bourne was not only a prolific developer, but he also contributed to the development of several other command-line interfaces, including the Bourne-Again shell (bash) and the Korn shell.\n- -As a testament to his significant contributions to the field of computer science, Bourne was honored with the ACM Software System Award in 1983, and later the USENIX Lifetime Achievement Award in 1999.\n- -In recognition of his substantial contributions, he was ele",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "Agent 2:",
        "chunkIndex": 77,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-78",
      "content": "computer science, Bourne was honored with the ACM Software System Award in 1983, and later the USENIX Lifetime Achievement Award in 1999.\n- -In recognition of his substantial contributions, he was elected as a Fellow of the Association for Computing Machinery in 2013.\n- -Bourne is also an accomplished author and co-author of several technical papers and books, including \"The Unix System,\" a widely used textbook on Unix programming.\n- -Despite his retirement, Bourne continues to be actively involved in the computer science community, sharing his expertise and experiences with younger generations of aspiring computer scientists.\n\nFigure 27: Example of Biography Debate. While we found that generated biographies after debate to be more accurate, many facts remain incorrect.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "Agent 2:",
        "chunkIndex": 78,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-79",
      "content": "- -Stephen R. Bourne is a computer scientist known for his development of the Unix shell, or command-line interface, known as the Bourne shell.\n- -He earned a bachelor's degree in mathematics and a doctorate in computer science from Cambridge University.\n- -Bourne worked at Bell Labs, where he played a key role in the creation of the Unix operating system, and was involved in the development of its command-line interfaces.\n- -In addition to the Bourne shell, he also created the Bourne-Again shell (bash) and contributed to the development of the Korn shell.\n- -Bourne was awarded the ACM Software System Award in 1983 for his work on the Bourne shell, and the USENIX Lifetime Achievement Award in 1999 for his contributions to the field of computer science.\n- -He was also elected as a Fellow of the Association for Computing Machinery in 2013 in recognition of his significant contributions to the field.\n- -Bourne has authored and co-authored numerous technical papers and books, including \"Th",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "Agent 1:",
        "chunkIndex": 79,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-80",
      "content": "the Association for Computing Machinery in 2013 in recognition of his significant contributions to the field.\n- -Bourne has authored and co-authored numerous technical papers and books, including \"The Unix System,\" a widely used textbook on Unix programming, and continues to be involved in the computer science community after his retirement.\n\nInstruction: Here is the current sequence of moves in a chess game: 1. e4 c6 2. d4 d5 3. Nd2 Qc7 4. Bd3 dxe4 5. Nxe4 Bf5 6. Nf3 Nd7 7. O-O e6 8. c4 Bg6 9. d5 Bxe4 10. Bxe4 Ndf6 11. Re1 Nxe4 12. Rxe4 Nf6 13. Re1 O-O-O . What is the best chess move I should execute next? Give a single move suggestion of the form 14. &lt;XXX&gt; and make sure the chess move is valid in the current board state.\n\nFigure 28: Example of Chess Debate.\n\n<!-- image -->\n\n| Round 1",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "Agent 1:",
        "chunkIndex": 80,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-81",
      "content": "d 1                                                                                                                                                                                                                                           | Round 1                                                                                                                                                                                         |\n|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Agent 1: 14.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "Agent 1:",
        "chunkIndex": 81,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-82",
      "content": "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Agent 1: 14. dxe6                                                                                                                                                                                                                                 | Agent 2: 14. Be3                                                                                                                                                                                |\n| Instruction: Using the solutions from other agents as additional information. (Copy Agent 2's reply)                                                                                                                                              | Instruction: Using the solutions from other agents as additional information.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "Agent 1:",
        "chunkIndex": 82,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-83",
      "content": "| Instruction: Using the solutions from other agents as additional information. (Copy Agent 1's reply)                                                                                            |\n| Round 2                                                                                                                                                                                                                                           | Round 2                                                                                                                                                                                         |\n| Agent 1: Based on the current board state and the suggested moves, I would suggest the move: 14. Qa4. This move attacks the undefended bishop on f5 and puts pressure on black's position.",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "Agent 1:",
        "chunkIndex": 83,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-84",
      "content": "|\n| Agent 1: Based on the current board state and the suggested moves, I would suggest the move: 14. Qa4. This move attacks the undefended bishop on f5 and puts pressure on black's position.                                                        | Agent 2: I would still suggest the move 14. Be3. It develops a piece and prepares to put pressure on black's position. Additionally, it reinforces the e4 pawn and prepares to castle kingside. |\n| Instruction: Using the solutions from other agents as additional information. (Copy Agent 2's reply)                                                                                                                                              | Instruction: Using the solutions from other agents as additional information. (Copy Agent 1's reply)                                                                                            |\n| Round 3",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "Agent 1:",
        "chunkIndex": 84,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-85",
      "content": "|\n| Round 3                                                                                                                                                                                                                                           | Round 3                                                                                                                                                                                         |\n| Agent 1: After considering the suggestions of other agents, I still believe that the move 14. Qa4 is the best move in the current board state. It attacks the bishop on f5, prepares to develop the queen, and puts pressure on Black's position. | Agent 2: After considering the suggestions of other agents, I would suggest the move 14. Qa4. It attacks the bishop on f5, prepares to develop the queen and puts pressure on Black's position. |",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "Agent 1:",
        "chunkIndex": 85,
        "totalChunks": 87
      }
    },
    {
      "id": "2305.14325v1-chunk-86",
      "content": "ring the suggestions of other agents, I would suggest the move 14. Qa4. It attacks the bishop on f5, prepares to develop the queen and puts pressure on Black's position. |",
      "metadata": {
        "source": "arxiv:2305.14325v1",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate",
        "authors": [
          "Yilun Du",
          "Shuang Li",
          "Antonio Torralba",
          "Joshua B. Tenenbaum",
          "Igor Mordatch"
        ],
        "section": "Agent 1:",
        "chunkIndex": 86,
        "totalChunks": 87
      }
    }
  ],
  "fullText": "## Improving Factuality and Reasoning in Language Models through Multiagent Debate\n\nYilun Du MIT CSAIL\n\nyilundu@mit.edu\n\nShuang Li MIT CSAIL\n\nAntonio Torralba MIT CSAIL\n\nlishuang@mit.edu torralba@mit.edu\n\n## Igor Mordatch\n\nGoogle Brain imordatch@google.com\n\n## Abstract\n\nLarge language models (LLMs) have demonstrated remarkable capabilities in language generation, understanding, and few-shot learning in recent years. An extensive body of work has explored how their performance may be further improved through the tools of prompting, ranging from verification, self-consistency, or intermediate scratchpads. In this paper, we present a complementary approach to improve language responses where multiple language model instances propose and debate their individual responses and reasoning processes over multiple rounds to arrive at a common final answer. Our findings indicate that this approach significantly enhances mathematical and strategic reasoning across a number of tasks. We also demonstrate that our approach improves the factual validity of generated content, reducing fallacious answers and hallucinations that contemporary models are prone to. Our approach may be directly applied to existing black-box models and uses identical procedure and prompts for all tasks we investigate. Overall, our findings suggest that such \"society of minds\" approach has the potential to significantly advance the capabilities of LLMs and pave the way for further breakthroughs in language generation and understanding. Project website at https://composable-models.github.io/llm\\_debate/ .\n\n## 1 Introduction\n\nLarge language models (LLMs) have demonstrated remarkable language generation, understanding, and few-shot learning capabilities in recent years. These methods are trained on a massive corpus of text on the internet, where the quality and accuracy of extracted natural language may not be ensured. Thus, current models may suffer from confidently hallucinating facts or making implausible jumps in chains of reasoning. An extensive body of recent work has focused on improving factual accuracy and reasoning in language models. These range from prompting models with few or zero-shot chain-of-thought demonstrations, use of verification, self-consistency, or intermediate scratchpads.\n\nWe note that these techniques are applied over a single model instance. Instead, we propose a complementary approach inspired by The Society of Mind [19] and multi-agent settings, where multiple language model instances (or agents) individually propose and jointly debate their responses and reasoning processes to arrive at a single common answer. More specifically, given a query, multiple instances of a language model first generate individual candidate answers to a query. Then each individual model instance reads and critiques the responses of all other models and uses this content to update its own answer. This step is then repeated over several rounds. This process induces models to construct answers that are consistent with both their internal critic as well as sensible in\n\nPreprint. Under review.\n\nJoshua B. Tenenbaum MIT CSAIL, BCS, CBMM jbt@mit.edu\n\nFigure 1: Multiagent Debate Improves Reasoning and Factual Accuracy. Accuracy of traditional inference and our multi-agent debate over six benchmarks (chess move optimality reported as a normalized score)\n\n<!-- image -->\n\nlight of the responses of other agents. The resulting quorum of models can hold and maintain multiple chains of reasoning and possible answers simultaneously before proposing the final answer.\n\nWe find that our debate approach outperforms single model baselines such as zero-shot chain of thought [11] and reflection [26, 18] on a variety of six reasoning, factuality, and question-answering tasks. Using both multiple model agents and multiple rounds of debate are important to achieve the best performance. Given an initial query, we find that individual model instances propose a diverse range of answers despite being the same model class (although we also investigate the case of mixing different model types, such as chatGPT [21] and Bard [23]). After debating and examining the responses of other model instances, we find that the population almost always converges on a single and more accurate common answer. Debate results are also less likely to include false facts that models are internally uncertain of. This is because as the debate progresses, individual model instances tend to disagree on uncertain facts and omit them from the answer (Figure 7). Lastly, we find that debate does not just act to amplify one correct answer in a model quorum - we find many cases where all the models initially make incorrect predictions, but then arrive at the correct answer as debate progresses (Figure 4,11).\n\nWe use the same methodology and prompt templates for all our tasks and require only black-box access to language model generations - no model-internal information such as likelihoods or gradients is needed. This allows our method to be used with common public models serving interfaces. The method is also orthogonal to other model generation improvements such as retrieval or prompt engineering (in fact, we combine our debate method with zero-shot chain of thought). While the debate process is more costly, requiring multiple model instances and rounds, it arrives at significantly improved answers and may be used to generate additional model training data, effectively creating a model self-improvement loop.\n\nTo help evaluate the effect of our approach on factual accuracy, we introduce a new benchmark and dataset evaluating factual accuracy of famous computer scientist biographies. We find that contemporary language models have an especially high tendency to hallucinate factually incorrect biographies, often misrepresenting the relevant institutions and dates. Moreover, these facts often inconsistent across different language model instances. By asking models to come to a consensus across their answers, such inconsistent facts may be either removed or corrected.\n\nIn summary, our work contributes the following. First, we present a novel approach to improving factual correctness and reasoning accuracy in contemporary language models, leveraging a multiagent debate process between models. Second, we introduce a new benchmark of factual correctness which contemporary language models struggle with. Finally, we evaluate the performance of our debate procedure in language generation, both in terms of the number of agents, the underlying rounds of debate, and the prompts that elicit such behavior across a set of six different reasoning and factual accuracy tasks.\n\n## 2 Language Generation through Multiagent Debate\n\nWe present an approach to generate language responses through multiagent debate. We provide an overview of our approach in Section 2.1. We further discuss convergence to consensus in the debate process in Section 2.2. The overall overview of our approach is shown in Figure 2.\n\nFigure 2: Illustration of Debate. Illustration of the debate procedure.\n\n<!-- image -->\n\n## 2.1 Multiagent Language Generation\n\nConsider your work process when solving the following math question on an exam: 'What is the area of a triangle with side lengths of 3, 4, 5?\" . In one thread of work, you may recognize that the triangle side-lengths directly correspond to a right triangle, and thus directly compute the area as 0 . 5 × 3 × 4 = 64 . To make sure that you have the right answer, you may then try to solve the problem differently by estimating an angle θ in the triangle using the Law of Cosines, and then obtain the area by using the formula 0 . 5 × 3 × 4 × sin( θ ) , arriving at another answer to the given exam problem.\n\nWhen these lines of work give the same answer, your confidence about the answer increases. In contrast, when these answers are different, individual lines of work may engage in a mental 'debate\" procedure, where you closely cross-examine the reasoning and assumptions of each line of work and refine solutions until a consistent answer.\n\nSimilarly, consider writing a biography of a historical figure. To ensure the factuality of the biography, you may consult multiple different sources on each fact. Facts that are consistent in each source increase your confidence about the fact. In contrast, facts that are inconsistent require careful cross-examination between sources to determine the final consistent data.\n\nFigure 3: Prompts to induce long and short form debate. Responses of other agents to questions are are inserted in the middle of the prompt (indicated with [other answers] )\n\n| Debate Length   | Prompt                                                                                                                                                                       |\n|-----------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Short           | \" These are the solutions to the problem from other agents: [other answers] Based off the opinion of other agents, can you give an updated response . . . \"                  |\n| Long            | \" These are the solutions to the problem from other agents: [other answers] Using the opinion of other agents as additional advice, can you give an updated response . . . \" |\n\nTo mimic the above multi-threaded reasoning process and multi-source factuality checking processes, we propose to generate answers subject to a multi-agent debate procedure between multiple instances of large language models. Given a question, multiple agents represented as copies of a large language model, generate answers to the question. Each response serves as a possible thought process or source of information which agents may re-examine to find consistent final answers.\n\nAfter initial responses are generated from different agents, we initiate a round of debate between agents. Individual responses from other agents are concatenated and given as context to each agent, with each agent instructed to construct a new response based on such responses. Each language agent is thus responsible for both verifying the collection of responses given by other agents, and refining its own response based on other agents' responses. We iteratively repeat this debate procedure over multiple rounds for improved performance.\n\nConcretely, we first prompt each agent to independently solve the given problem or task. After each agent generates a response, we feed each agent a consensus prompt, illustrated in Figure 3, where each agent is instructed to update their responses based on the responses of other agents. This resultant consensus prompt may then be repeatedly given, using the updated responses of each agent. We illustrate an overview of this multiagent debate procedure in Figure 2.\n\nNote that our proposed approach operates in an orthogonal manner to existing approaches to prompt language models. Given a question, we may apply additional techniques for prompting language models to further improve our debate procedure by eliciting additional more detailed responses from language models. We illustrate the synergy of our approach with existing approaches to prompting language models in Figure 6 and directly apply zero-shot chain-of-thought reasoning in our evaluations.\n\n## 2.2 Consensus in Debates\n\nGiven multiple rounds of debate, how can we ensure that a set of language model agents will converge to a final consensus answer? In general, debate can be seen as a multi-agent game, where convergence is not guaranteed. Empirically, however, we find that language models are able to converge on a single shared answer after multiple rounds of debate (Figure 4).\n\nWe found that we could control the duration of debates by how changing how much a language model trusts its own outputs over those generated by other models through different prompts. We illustrate two prompts below in Figure 3, which we use to induce different debate durations between language models, and illustrate the effect of such prompts in Figure 12. In general, we found that prompts that encouraged models to be more 'stubborn' based on their own solutions led to longer debates and better final solutions. Overall, we observed that language model agents were relatively \"agreeable\", perhaps as a result of instruction tuning or reinforcement learning based on human feedback [22].\n\n## 3 Experiments\n\nIn our experiments, we evaluate our multiagent debate procedure and answer the following questions: (1) To what extent does multiagent debate improve reasoning? (2) To what extent does multiagent debate improve factual validity? (3) What design choices enable multiagent debate to improve language generation performance?\n\n## 3.1 Improving Reasoning with Multiagent Debate\n\nWe first evaluate the extent to which multiagent debate improves the underlying reasoning process in language models.\n\nTasks. We evaluate our approach on three reasoning tasks of increasing difficulty:\n\nFigure 5: Illustration of Solving Grade School Math. Reasoning between agents omitted.\n\n<!-- image -->\n\n- Arithmetic. We first evaluate the ability of models to correctly evaluate an arithmetic expression (containing addition, multiplication, and subtraction) consisting of six different two-digit numbers. For example: What is the result of 12+15*21+0-3*27?\n- GSM8K. Next, we consider harder mathematical reasoning tasks. Using the GSM8K dataset [3], the models must correctly solve grade school mathematical reasoning tasks.\n- Chess Move Prediction. Finally, we consider the strategic reasoning of the ability of models, and ask models to predict the best next move in a game of chess, given the first 14 moves of a chess game between two chess grand-masters described in PGN notation [6].\n\nWe report the accuracy of final answers in arithmetic and GSM8K tasks and report the pawn score (advantage) of predicted moves, as estimated by Stockfish in the Chess move prediction tasks. Additional details may be found in the Appendix.\n\nBaselines. We compare our approach to three alternative approaches to generate responses for reasoning problems. First, we ask agents to directly generate responses (single agent). Next, we consider asking language models to generate and then \"self-reflect\" on the responses generated [26, 18]. Finally, we consider generating responses using multiple agents and performing majority voting [15, 3]. As the focus of our experiments is to verify the effectiveness of multiagent agent debate, we run both baselines and our approach, using the identical starting prompt and language model across all evaluations. We evaluate models in a zero-shot setting, with prompts found in the Appendix of the paper.\n\nFigure 6: Synergy with Other Methods. Performance of debate increases with use of Chain of Thought prompting.\n\n<!-- image -->\n\nWe use chatGPT-based language model [21] in all our experiments except those in Figure 11 where we compare multiple language models.\n\nDue to computational expense, we evaluate our approach across benchmarks mainly using three agents with two rounds of debates, although we found further gains with both more agents and rounds of debate (Figure 10). Additional evaluation details are found in the Appendix.\n\nQuantitative Results. In Table 1, we report the results of each approach on arithmetic, grade school math, and chess reasoning task. In each task, we observe that utilizing multiple different agents to generate solutions improves performance over using a single language model agent to generate a solution. Simultaneously, we also see that reflection, where a language model is asked to critique its early generation, generally gives a modest boost in performance. Multiagent debate, which may be seen as a combination of both reflection and multiagent generation, gives a substantial boost in reasoning across each of the tasks.\n\nTable 1: Multiagent Debate Improves Reasoning Multi-agent debate improves the reasoning abilities of language models. Multi-agent results in the table are run with 3 agents and two rounds of debate.\n\n| Model                     | Arithmetic (%) ↑   | Grade School Math (%) ↑   | Chess ( ∆ PS) ↑   |\n|---------------------------|--------------------|---------------------------|-------------------|\n| Single Agent              | 67.0 ± 4.7         | 77.0 ± 4.2                | 91.4 ± 10.6       |\n| Single Agent (Reflection) | 72.1 ± 4.5         | 75.0 ± 4.3                | 102.1 ± 11.9      |\n| Multi-Agent (Majority)    | 69.0 ± 4.6         | 81.0 ± 3.9                | 102.2 ± 6.2       |\n| Multi-Agent (Debate)      | 81.8 ± 2.3         | 85.0 ± 3.5                | 122.9 ± 7.6       |\n\nPrompt: Give a bullet point biography of David S. Johnson highlighting their contributions and achievements as a computer scientist, with each fact separated with a new line character.\n\nFigure 7: Illustration of Generating Biographies. Illustration of generating bullet biographies of computer scientists. For brevity, only the first 3 generated bullets are shown.\n\n<!-- image -->\n\nQualitative Results. In Figure 4, 5, we provide qualitative illustrations of the debate procedure between models. Interestingly, we find cases in which all models initially give an incorrect response, yet the result of debate still obtains the correct answer as agents critique each others' reasoning. Thus, the purpose of our debate isn't just to amplify a correct answer - all models can initially be wrong but arrive at the correct answer through the debate process.\n\nCompatibility with other reasoning methods. Our multiagent generation procedure operates orthogonally approach to other prompting methods which focus on single-agent generation. In Figure 6, we illustrate the performance of multi-agent debate with and without zero-shot chain-ofthought prompting [11] on GSM8K. In both settings, multiagent generation is beneficial.\n\n## 3.2 Extracting Factual Information from Multiagent Debate\n\nWe next evaluate the extent to which multiagent debate improves the underlying factuality in language models.\n\nTasks. We evaluate the factuality of language models in three different settings:\n\n- Biographies. To evaluate the factuality of language models, we introduce a novel task of accurately generating historical biographies of people. In preliminary testing, we found that existing language models had a tendency to hallucinate many facts on this task. We constructed ground truth bullet point biographies of 524 well-known computer scientists. We then asked language models to generate bullet point biographies for each person, and evaluated the accuracy at which each ground truth bullet point agreed with generated bullets. We report additional evaluation details in the Appendix.\n\nFigure 8: Illustration of MMLU. Illustration of debate when answering factual tasks. Reasoning omitted.\n\n<!-- image -->\n\nTable 2: Multiagent Debate Improves Factual Accuracy Multi-agent debate improves the factual accuracy.\n\n| Model                     | Biographies   | MMLU       | Chess Move Validity   |\n|---------------------------|---------------|------------|-----------------------|\n| Single Agent              | 66.0 ± 2.2    | 63.9 ± 4.8 | 29.3 ± 2.6            |\n| Single Agent (Reflection) | 68.3 ± 2.9    | 57.7 ± 5.0 | 38.8 ± 2.9            |\n| Multi-Agent (Debate)      | 73.8 ± 2.3    | 71.1 ± 4.6 | 45.2 ± 2.9            |\n\n- MMLU. Next, we assess the factuality of language models in responding to different factual knowledge questions typically learned and assessed in different exams. We utilize the existing MMLU dataset [8] to benchmark the accuracy of responses.\n- Chess Move Validity. Lastly, we study the hallucinations in language models when planning under to the given rules of an existing environment or game. Specifically, we measure the validity of possible moves in a game of Chess given by BIG-Bench Chess-State Tracking Benchmark [27] task of chess-move prediction. In this task, an agent is given a set of next moves, and must make a valid next move of a piece on a board.\n\nBaselines. We use the same baselines as in Section 3.1. The multiagent (majority) is not directly applicable in this setting as individual responses are not easily comparable, and so we omit baseline comparison with the majority voting in this setting.\n\nResults. We analyze the performance of each method in Table 2. We found that approaches based on reflection led to poor performance in the factuality setting. In contrast, debate gives the best performance in this setting also, and significantly outperforms each baseline. We illustrate a debate between agents on the biography task in Figure 7 and on MMLU in Figure 8. We found that multiagent debate improved and settled on bullets that were more consistent across agents.\n\nWe found that different language agents tended to give different answers when the underlying language model was uncertain about the question. However, directly asking each agent about their confidence [10] of the answer led to high confidence assessments on each answer. However, when these different language agents were asked to communicate with each other, each agent would quickly change their opinion to a consensus answer which was more accurate. We illustrate this in Figure 9. Interestingly, we found that on facts that the language model was confident in (i.e. many instances of the same model all gave the same answer), it was very difficult to convince an agent to change their opinion, suggesting that 'ease of persuasion' may be a method to assess factual confidence.\n\n## 3.3 Analysis: Understanding Multiagent Debate\n\nFinally, we analyze how multiagent debate improves the underlying language generation procedure in language models.\n\nNumber of Agents. First, we analyze the impact of agents number in debate. In Figure 10(a), we increase the number of agents used in debate, while fixing the debate length to be two. On arithmetic, performance monotonically increases with the increased number of agents. For larger number of agents, we first summarize all agent responses with chatGPT instead of directly concatenating responses due to context length error.\n\nRounds of Debate Next, we analyze the impact of the number of rounds of debate in multiagent debate. In Figure 10(b), we increase the debate length between agents, while fixing the number of agents to three. We find that on the arithmetic task, the performance also monotonically increases with debate length. However, we found that additional debate rounds above four led to a similar final performance to 4 rounds of debate.\n\nRound 1\n\nRound 2\n\nPrompt: What country was the computer scientist Tomas Lozano-Perez born in?\n\nAgent 1: Tomas Lozano-Perez, a renowned computer scientist, was born in Spain.\n\n<!-- image -->\n\n<!-- image -->\n\nAgent 2: Tomas Lozano-Perez, a renowned computer scientist, was born in Havana, Cuba.\n\n<!-- image -->\n\nAgent 2: I apologize for the conflicting responses. Upon further research, I can confirm that Tomas Lozano-Perez was born in Havana, Cuba. ✓\n\nAgent 1: I apologize for the confusion. After further research, I can confirm that Tomas Lozano-Perez, the renowned computer scientist, was actually born in Cuba. Thank you for bringing this to my attention.\n\nFigure 9: Expressing Uncertainty with Multiple Answers. For facts that a language model is uncertain about, different language agents generate different facts. Debate causes agents to converge to one fact that is more accurate, but not necessarily always factually correct.\n\n<!-- image -->\n\nFigure 10: (a) Performance with Increased Agents. Performance improves as the number of underlying agents involved in debate increases. (b) Performance with Increased Rounds. Performance rises as the number of rounds of underlying debate increases. Performance vs Number of Debating Agents\n\n<!-- image -->\n\nEffect of Debate Length on Accuracy As discussed in Section 2.2, the underlying convergence time in the debate between agents can be controlled by the extent to which agents are encouraged to maintain their opinions. In Figure 12, we consider the effect of short and long-form prompts discussed in Figure 3. We find that debates using longer prompts lead to slower convergence to correct answers, but also lead to a better final consensus on the correct answer. We provide an analysis of consensus between agents in Figure 14.\n\nUsing Different Initialization Prompts In our experiments we use the same prompts for all agents. We\n\nFigure 12: Performance vs Debate Length. Prompts which induce longer debate improve performance.\n\n<!-- image -->\n\nalso consider the effect of using different questions, where we first instruct each language model to behave like a different persona (professor, doctor, mathematician) on the MMLU dataset. We found that improved performance on MMLU from 71.1 to 74.2 with different agents, suggesting further gains can be obtained with different initialization prompts.\n\nSummarization. While in the majority of experiments in the paper we directly concatenate the responses of other agents as context for an agent to generate a new response, this is expensive when the number of agents involved in debate gets large. We may alternatively first summarize the responses from all other agents into a single response that we provide to agent at each round for more efficient debate. We apply this strategy in Figure 10 to enable the use of five or more agents in debate. In Figure 13, we analyze the effect compared to directly concatenating the responses of other agents. We find this improves the performance of debate, suggesting that summarization is another tool that can further improve multiagent debate.\n\nFigure 13: Effect of Summarization. When there are many agents in a debate, responses from other agents may be first summarized and then given as context, reducing context length. This operation improves performance.\n\n<!-- image -->\n\nUtilizing Different Language Models Our existing debate results are reported using multiple instances of a chatGPT language model. We further assess\n\nQuestion: Carla is downloading a 200 GB file. Normally she can download 2 GB/minute, but 40% of the way through the download, Windows forces a restart to install updates, which takes 20 minutes. Then Carla has to restart the download from the beginning. How load does it take to download the file?\n\nFigure 11: Debate Between chatGPT and Bard Illustration of debate between different models.\n\n<!-- image -->\n\nthe impact of using two different language models, where we ask chatGPT and Bard [23] language models to debate with each other on a set of 20 GSM8K math problems. In this set, we find that multi-agent debate improves the performance of both agents, with Bard solving 11 problems, chatGPT solving 14 problems, and joint multi-agent debate solving 17 problems. We qualitatively illustrate a debate between agents in Figure 11. While both agents initially provide incorrect answers to the problem, chatGPT is able to utilize the incorrect response given by Bard to generate the final correct answer.\n\n## 4 Related Work\n\nReasoning and Factuality in Language Models. A wide range of work has explored how to enable reasoning and factuality in language models. To improve reasoning, approaches have relied on prompting techniques such as scratchpads [20], verification [3], chain-of-thought demonstrations [30, 11, 25], and intermediate self-reflection [26, 18] and finetuning [13, 24, 31]. To improve factuality, approaches have relied on training techniques such as RLHF [33, 16, 2], pruning truthful datasets [12], external knowledge retrieval [7] and training-free methods based off likelihood estimation [10].\n\nOur work provides an alternative way to obtain reasoning and factuality in language models using multiagent debates, which only requires black-box access to a language generator. Prior work also has explored how to take the majority vote across different models [15, 3, 29, 28] while in this work, we use the power of a language model to combine different answers. Most similar to our work, Irving et al. [9] also proposes a debate procedure to verify the accuracy and safety of powerful AI agents. In contrast to our approach, in their work, agents are asked to alternatively provide proof of a input, and humans are tasked with assessing these debates and determining safety.\n\nCompositional Generation. Our work is also related to existing works that focus on text generation by combining different models [4, 17, 32, 1, 5]. Most similar to our work, [14, 32] propose to combine multiple different large pretrained models together for multimodal reasoning. In contrast, in our work, we aim to use communication between different language models to enable more effective reasoning and factuality in language models.\n\n## 5 Limitations and Discussion\n\nIn this paper, we present an orthogonal approach to improve the performance of language models using multi-agent debate. We find that the approach is simple and effective across a wide set of different reasoning and validity language modeling tasks.\n\nLimitations. In comparison to other prompting techniques, our multiagent debate procedure is more computationally expensive, as it requires both multiple language generations, and an underlying debate procedure. However, we believe that this approach may be seen as a method to generate additional data that may be distilled back to self-improve the original base model.\n\nFurther, we observed that as debates became longer in duration, current language models sometimes struggled to fully process the entire debate input, and typically only focused on the most recent generations. We believe that this performance will be alleviated with longer-context and improved language models or by summarizing early portions of the debate.\n\nFinally, we found that while debates typically converged into single final answers, these answers were not necessarily correct. Despite answers being incorrect, language models would confidently affirm that their answer is correct and consistent with all other agent responses. We believe this result is in part due to the fact that LMs do not correctly express their uncertainty when generating responses, and believe that other orthogonal approaches to improve this performance would improve the results of multiagent debate.\n\n## References\n\n- [1] J.-B. Alayrac, J. Donahue, P. Luc, A. Miech, I. Barr, Y . Hasson, K. Lenc, A. Mensch, K. Millican, M. Reynolds, et al. Flamingo: A visual language model for few-shot learning. NeurIPS , 2022. URL https://arxiv.org/abs/2204.14198 . 9\n- [2] P. F. Christiano, J. Leike, T. Brown, M. Martic, S. Legg, and D. Amodei. Deep reinforcement learning from human preferences. In Neural Information Processing Systems , 2017. 9\n- [3] K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser, M. Plappert, J. Tworek, J. Hilton, R. Nakano, et al. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168 , 2021. 5, 9\n- [4] Y. Du, S. Li, and I. Mordatch. Compositional visual generation with energy based models. In Advances in Neural Information Processing Systems , 2020. 9\n- [5] Y. Du, C. Durkan, R. Strudel, J. B. Tenenbaum, S. Dieleman, R. Fergus, J. Sohl-Dickstein, A. Doucet, and W. Grathwohl. Reduce, reuse, recycle: Compositional generation with energybased diffusion models and mcmc. arXiv preprint arXiv:2302.11552 , 2023. 9\n- [6] Fsmosca. Fsmosca/pgn-standard: Portable game notation specification and implementation guide. URL https://github.com/fsmosca/PGN-Standard . 5\n- [7] K. Guu, K. Lee, Z. Tung, P. Pasupat, and M.-W. Chang. REALM: Retrieval-augmented language model pre-training. arXiv preprint arXiv:2002.08909 , 2020. 9\n- [8] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt. Measuring massive multitask language understanding. arXiv preprint arXiv:2009.03300 , 2020. 7\n- [9] G. Irving, P. Christiano, and D. Amodei. Ai safety via debate. arXiv preprint arXiv:1805.00899 , 2018. 9\n- [10] S. Kadavath, T. Conerly, A. Askell, T. Henighan, D. Drain, E. Perez, N. Schiefer, Z. H. Dodds, N. DasSarma, E. Tran-Johnson, et al. Language models (mostly) know what they know. arXiv preprint arXiv:2207.05221 , 2022. 7, 9\n- [11] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa. Large language models are zero-shot reasoners. arXiv preprint arXiv:2205.11916 , 2022. 2, 6, 9\n\n- [12] N. Lee, W. Ping, P. Xu, M. Patwary, P. N. Fung, M. Shoeybi, and B. Catanzaro. Factuality enhanced language models for open-ended text generation. Advances in Neural Information Processing Systems , 35:34586-34599, 2022. 9\n- [13] A. Lewkowycz, A. Andreassen, D. Dohan, E. Dyer, H. Michalewski, V. Ramasesh, A. Slone, C. Anil, I. Schlag, T. Gutman-Solo, et al. Solving quantitative reasoning problems with language models. arXiv preprint arXiv:2206.14858 , 2022. 9\n- [14] S. Li, Y. Du, J. B. Tenenbaum, A. Torralba, and I. Mordatch. Composing ensembles of pre-trained models via iterative consensus. arXiv preprint arXiv:2210.11522 , 2022. 9\n- [15] Y. Li, D. Choi, J. Chung, N. Kushman, J. Schrittwieser, R. Leblond, T. Eccles, J. Keeling, F. Gimeno, A. Dal Lago, et al. Competition-level code generation with alphacode. Science , 378 (6624):1092-1097, 2022. 5, 9\n- [16] H. Liu, L. Lee, K. Lee, and P. Abbeel. Instruction-following agents with jointly pre-trained vision-language models. arXiv preprint arXiv:2210.13431 , 2022. 9\n- [17] N. Liu, S. Li, Y. Du, A. Torralba, and J. B. Tenenbaum. Compositional visual generation with composable diffusion models. arXiv preprint arXiv:2206.01714 , 2022. 9\n- [18] A. Madaan, N. Tandon, P. Gupta, S. Hallinan, L. Gao, S. Wiegreffe, U. Alon, N. Dziri, S. Prabhumoye, Y. Yang, et al. Self-refine: Iterative refinement with self-feedback. arXiv preprint arXiv:2303.17651 , 2023. 2, 5, 9\n- [19] M. Minsky. Society of mind . Simon and Schuster, 1988. 1\n- [20] M. Nye, A. J. Andreassen, G. Gur-Ari, H. Michalewski, J. Austin, D. Bieber, D. Dohan, A. Lewkowycz, M. Bosma, D. Luan, et al. Show your work: Scratchpads for intermediate computation with language models. arXiv preprint arXiv:2112.00114 , 2021. 9\n- [21] OpenAI. Chatgpt: Optimizing language models for dialogue, Dec 2022. URL https:// openai.com/blog/chatgpt/ . 2, 5\n- [22] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al. Training language models to follow instructions with human feedback. arXiv preprint arXiv:2203.02155 , 2022. 4\n- [23] S. Pichai. An important next step on our ai journey, Feb 2023. URL https://blog.google/ technology/ai/bard-google-ai-search-updates/ . 2, 9\n- [24] N. F. Rajani, B. McCann, C. Xiong, and R. Socher. Explain yourself! leveraging language models for commonsense reasoning. arXiv preprint arXiv:1906.02361 , 2019. 9\n- [25] L. Reynolds and K. McDonell. Prompt programming for large language models: Beyond the few-shot paradigm. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems , pages 1-7, 2021. 9\n- [26] N. Shinn, B. Labash, and A. Gopinath. Reflexion: an autonomous agent with dynamic memory and self-reflection. arXiv preprint arXiv:2303.11366 , 2023. 2, 5, 9\n- [27] A. Srivastava, A. Rastogi, A. Rao, A. A. M. Shoeb, A. Abid, A. Fisch, A. R. Brown, A. Santoro, A. Gupta, A. Garriga-Alonso, et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. arXiv preprint arXiv:2206.04615 , 2022. 7, 14\n- [28] R. Thoppilan, D. De Freitas, J. Hall, N. Shazeer, A. Kulshreshtha, H.-T. Cheng, A. Jin, T. Bos, L. Baker, Y. Du, et al. Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239 , 2022. 9\n- [29] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, and D. Zhou. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171 , 2022. 9\n- [30] J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. Chi, Q. Le, and D. Zhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903 , 2022. 9\n\n- [31] E. Zelikman, Y. Wu, J. Mu, and N. Goodman. Star: Bootstrapping reasoning with reasoning. Advances in Neural Information Processing Systems , 35:15476-15488, 2022. 9\n- [32] A. Zeng, A. Wong, S. Welker, K. Choromanski, F. Tombari, A. Purohit, M. Ryoo, V. Sindhwani, J. Lee, V. Vanhoucke, et al. Socratic models: Composing zero-shot multimodal reasoning with language. arXiv preprint arXiv:2204.00598 , 2022. URL https://arxiv.org/abs/2204. 00598 . 9\n- [33] D. M. Ziegler, N. Stiennon, J. Wu, T. B. Brown, A. Radford, D. Amodei, P. Christiano, and G. Irving. Fine-tuning language models from human preferences. arXiv preprint arXiv:1909.08593 , 2019. 9\n\n## A Appendix\n\nIn this appendix, we provide additional analysis and visualizations of the debates used in the main paper in Section A.1. We further provide detailed experimental details on each dataset in Section A.2.\n\n## A.1 Additional Results\n\nConsensus Between Agents. In Figure 14, we illustrate the consensus between agents using either short or long consensus prompts discussed in Figure 3. The use of debate prompts that encourage agents to adapt more to the opinions of other agents improves consensus.\n\nAdditional Qualitative Visualizations. We added additional qualitative visualizations of the debate process. In Figure 16, Figure 17, Figure 18, Figure 19, Figure 20, we illustrate debates between agents in the GSM8K dataset which result in the correct answer. In Figure 21, Figure 22, Figure 23, we further illustrate debates in GSM8K which lead to the incorrect answer. We further provide an example illustration of debate in\n\nFigure 14: Effect of Prompts on Consensus. Using a short debate prompt induces faster consensus between agents\n\n<!-- image -->\n\narithmetic in Figure 24, arithmetic with summarization of individual responses of agents in Figure 25, MMLUin Figure 26, a debate with the full contents biographies in Figure 27, and debate in chess in Figure 28. In general, we found that debate improved the performance of final generated answers, though sometimes answers would converge to the incorrect value.\n\n## A.2 Evaluation Details\n\nWe provided detailed evaluation details for each setting in the paper. We run all experiments using the gpt-3.5-turbo-0301 model. We provide a table listing the prompts used to prompt models and initialize debate in Table 15.\n\nArithmetic. To evaluate the arithmetic task, we generated six random integers for each task between 0 and 30. We then evaluated the extent to which the correct integer answer was correctly obtained. We evaluated models on one hundred generated arithmetic tasks.\n\nGrade School Math. To evaluate the GSM8K task, we evaluated the accuracy at which models were able to obtain the final correct answer, as extracted from a box. We evaluated models on one hundred grade school math problems.\n\nChess. To evaluate the chess reasoning task, we used chess games from https://www.pgnmentor. com/players/Adams.zip . We asked chatGPT to predict the next move for white to move at turn 14 and reported the relative Stockfish pawn score with search depth 20 after executing the suggested move from chatGPT. We evaluated models on three hundred selected chess games.\n\nBiographies. To evaluate the biographies task, we compare each generated bullet point biography for a person with a ground truth set of facts about the person extracted from Wikipedia. We iteratively loop through each ground truth fact, and validate the extent to which the generated biography matches a particular bullet by prompting chatGPT with the prompt: Consider the following biography of &lt;person&gt;: &lt;generated biography&gt; Is the above biography above consistent with the fact below? &lt;ground truth bullet&gt; Give a single-word answer, yes, no, or uncertain. We then evaluate and report the percentage of ground bullets that chatGPT returns either yes or no on. We ignored ground truth bullets that chatGPT returns returned uncertain.\n\nWe found this evaluation metric provided a fast way to evaluate how relatively correct a generated bullet point biography is. However, we found that generated facts could contain incorrect information that was not captured in the ground truth bullet and thus could not be validated through this metric. Nevertheless, we believe this evaluation scheme estimates the relative accuracy of a generated biography.\n\nMMLU. To evaluate MMLU, we measured the accuracy in which models were able to select the correct multiple-choice answer in each problem. We evaluated models on one hundred selected MMLUquestions randomly distributed across each of the subject areas.\n\nFigure 15: Prompts in each task. List of prompts used in each task\n\n| Task           | Type     | Prompt                                                                                                                                                                                                                                                                                                                                                                                                                    |\n|----------------|----------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Arithmetic     | Starting | What is the result of {}+{}*{}+{}-{}*{}? Make sure to state your answer at the end of the response.                                                                                                                                                                                                                                                                                                                       |\n| Arithmetic     | Debate   | These are the recent/updated opinions from other agents: <other agent responses> Use these opinions carefully as additional advice, can you provide an updated answer? Make sure to state your answer at the end of the response.                                                                                                                                                                                         |\n| GSM8K          | Starting | Can you solve the following math problem? <Problem> Explain your reasoning. Your final answer should be a single numerical number, in the form \\boxed{{answer}}, at the end of your response.                                                                                                                                                                                                                             |\n| GSM8K          | Debate   | These are the solutions to the problem from other agents: <other agent responses> Using the solutions from other agents as additional information, can you provide your answer to the math problem? The original math problem is <Problem>. Your final answer should be a single numerical number, in the form \\boxed{{answer}}, at the end of your response.                                                             |\n| Chess          | Starting | Here is the current sequence of moves in a chess game: <moves>. What is the best chess move I should execute next? Give a single move suggestion of the form 14. <XXX> and make sure the chess move is valid in the current board state.                                                                                                                                                                                  |\n| Chess          | Debate   | Here are other chess move suggestions from other agents: <other agent responses> Using the chess suggestions from other agents as additional advice and your earlier generated solution, can you give me your updated thoughts on the best next chess move I should play given the chess sequence ? Give a single move suggestion of the form 14. <XXX> and make sure the chess move is valid in the current board state. |\n| Biographies    | Starting | Give a bullet point biography of highlighting their contributions and achievements as a computer scientist, with each fact separated with a new line character.                                                                                                                                                                                                                                                           |\n| Biographies    | Debate   | Here are some bullet point biographies of <person> given by other agents: <other agent response> Closely examine your biography and the biography of other agents and provide an updated bullet point biography.                                                                                                                                                                                                          |\n| MMLU           | Starting | Can you answer the following question as accurately as possible? : A) , B) , C) , D) Explain your answer, putting the answer in the form (X) at the end of your response.                                                                                                                                                                                                                                                 |\n| MMLU           | Debate   | These are the solutions to the problem from other agents: <other agent responses> Using the reasoning from other agents as additional advice, can you give an updated answer? Examine your solution and that other agents. Put your answer in the form (X) at the end of your response.                                                                                                                                   |\n| Chess Validity | Starting | Given the chess game , give one valid destination square for the chess piece at . State the destination square in the form (X), where X follows the regex [a-h][1-8], for example (e5). Give a one line explanation of why your destination square is a valid move.                                                                                                                                                       |\n| Chess Validity | Debate   | Here are destination square suggestions from other agents: <other agent responses> Can you double check that your destination square is a valid move? Check the valid move justifications from other agents. State your final answer in a newline with a 2 letter response following the regex [a-h][1-8].                                                                                                                |\n\nChess Validity. To evaluate chess validity, we consider the BIG-Bench Chess-State Tracking Benchmark [27], where we used the hardest reported task in the benchmark synthetic\\_short . Each generated answer was deemed correct as long as it was one of the valid answers in the sequence. We evaluated models of one hundred selected chess validity tasks.\n\nFigure 16: Example of a correct GSM8K Debate.\n\n<!-- image -->\n\nFigure 17: Example of Correct GSM8K Debate.\n\n<!-- image -->\n\nFigure 18: Example of Correct GSM8K Debate.\n\n<!-- image -->\n\nFigure 19: Example of Correct GSM8K Debate.\n\n<!-- image -->\n\nFigure 20: Example of Correct GSM8K Debate.\n\n<!-- image -->\n\nFigure 21: Example of Incorrect GSM8K Debate.\n\n<!-- image -->\n\nFigure 22: Example of Incorrect GSM8K Debate.\n\n<!-- image -->\n\nFigure 23: Example of Incorrect GSM8K Debate.\n\n<!-- image -->\n\nFigure 24: Example of Arithmetic Debate.\n\n<!-- image -->\n\nFigure 25: Example of Arithmetic Debate with Summarization. Four separate agents participate in debate, with two illustrated above. Instruction contains the summarized responses across agents.\n\n<!-- image -->\n\nFigure 26: Example of MMLU Debate.\n\n<!-- image -->\n\nInstruction: Give a bullet point biography of Stephan R. Bourne highlighting their contributions and achievements as a computer scientist, with each fact separated by a new line character.\n\n| Round 1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | Round 1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Agent 1: - Stephen R. Bourne is a British-born American computer scientist. - He is best known for creating the Bourne shell (sh) for the Unix operating system in 1979.\\n- The Bourne shell was the default Unix shell for many years and is still in use today. - Bourne also worked on the development of the UNIX System III and IV operating systems. - He later joinedAT&T Bell Laboratories, where he worked on the UNIX System Voperating system and its derivatives. - Bourne was awarded theACM Software System Award in 1983 for his work on the Bourne shell. - He is also a recipient of the USENIX Lifetime Achievement Award (2001) and the IEEE Computer Pioneer Award (2010). - Bourne is now retired and continues to be involved in the computer science community. | Agent 2: . - Stephen R. Bourne is a computer scientist known for his development of the Unix shell, or command-line interface, known as the Bourne shell. - He earned a bachelor's degree in mathematics and a doctorate in computer science from Cambridge University. - Bourne worked at Bell Labs, where he helped to create the Unix operating system and its command- line interface. - In addition to the Bourne shell, he also created the Bourne-Again shell (bash) and was involved in the creation of the Korn shell. - Bourne was awarded the USENIX Lifetime Achievement Award in 1999 and was elected as a Fellow of the Association for Computing Machinery in 2013. - He has authored and co-authored numerous technical papers and books, including \"The Unix System,\" a widely used textbook on Unix programming. |\n\nInstruction: Here are  some bullet point biographies from other agents: (Copy Agent 2's reply) Using the biographies as additional information, can you give an updated  bullet point biography.\n\nInstruction: Here are  some bullet point biographies from other agents: (Copy Agent 1's reply) Using the biographies as additional information, can you give an updated  bullet point biography.\n\n## Round 2\n\n## Agent 2:\n\n- -Stephen R. Bourne is a highly respected computer scientist and mathematician who revolutionized the computing field with his development of the Unix shell, popularly known as the Bourne shell.\n- -He earned his bachelor's degree in mathematics and a doctorate in computer science from Cambridge University, and began his career at Bell Labs where he played an integral role in the creation of the Unix operating system.\n- -During his tenure, Bourne developed the Bourne shell, which became the foundation for the Unix commandline interface.\n- -Bourne was not only a prolific developer, but he also contributed to the development of several other command-line interfaces, including the Bourne-Again shell (bash) and the Korn shell.\n- -As a testament to his significant contributions to the field of computer science, Bourne was honored with the ACM Software System Award in 1983, and later the USENIX Lifetime Achievement Award in 1999.\n- -In recognition of his substantial contributions, he was elected as a Fellow of the Association for Computing Machinery in 2013.\n- -Bourne is also an accomplished author and co-author of several technical papers and books, including \"The Unix System,\" a widely used textbook on Unix programming.\n- -Despite his retirement, Bourne continues to be actively involved in the computer science community, sharing his expertise and experiences with younger generations of aspiring computer scientists.\n\nFigure 27: Example of Biography Debate. While we found that generated biographies after debate to be more accurate, many facts remain incorrect.\n\n## Agent 1:\n\n- -Stephen R. Bourne is a computer scientist known for his development of the Unix shell, or command-line interface, known as the Bourne shell.\n- -He earned a bachelor's degree in mathematics and a doctorate in computer science from Cambridge University.\n- -Bourne worked at Bell Labs, where he played a key role in the creation of the Unix operating system, and was involved in the development of its command-line interfaces.\n- -In addition to the Bourne shell, he also created the Bourne-Again shell (bash) and contributed to the development of the Korn shell.\n- -Bourne was awarded the ACM Software System Award in 1983 for his work on the Bourne shell, and the USENIX Lifetime Achievement Award in 1999 for his contributions to the field of computer science.\n- -He was also elected as a Fellow of the Association for Computing Machinery in 2013 in recognition of his significant contributions to the field.\n- -Bourne has authored and co-authored numerous technical papers and books, including \"The Unix System,\" a widely used textbook on Unix programming, and continues to be involved in the computer science community after his retirement.\n\nInstruction: Here is the current sequence of moves in a chess game: 1. e4 c6 2. d4 d5 3. Nd2 Qc7 4. Bd3 dxe4 5. Nxe4 Bf5 6. Nf3 Nd7 7. O-O e6 8. c4 Bg6 9. d5 Bxe4 10. Bxe4 Ndf6 11. Re1 Nxe4 12. Rxe4 Nf6 13. Re1 O-O-O . What is the best chess move I should execute next? Give a single move suggestion of the form 14. &lt;XXX&gt; and make sure the chess move is valid in the current board state.\n\nFigure 28: Example of Chess Debate.\n\n<!-- image -->\n\n| Round 1                                                                                                                                                                                                                                           | Round 1                                                                                                                                                                                         |\n|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Agent 1: 14. dxe6                                                                                                                                                                                                                                 | Agent 2: 14. Be3                                                                                                                                                                                |\n| Instruction: Using the solutions from other agents as additional information. (Copy Agent 2's reply)                                                                                                                                              | Instruction: Using the solutions from other agents as additional information. (Copy Agent 1's reply)                                                                                            |\n| Round 2                                                                                                                                                                                                                                           | Round 2                                                                                                                                                                                         |\n| Agent 1: Based on the current board state and the suggested moves, I would suggest the move: 14. Qa4. This move attacks the undefended bishop on f5 and puts pressure on black's position.                                                        | Agent 2: I would still suggest the move 14. Be3. It develops a piece and prepares to put pressure on black's position. Additionally, it reinforces the e4 pawn and prepares to castle kingside. |\n| Instruction: Using the solutions from other agents as additional information. (Copy Agent 2's reply)                                                                                                                                              | Instruction: Using the solutions from other agents as additional information. (Copy Agent 1's reply)                                                                                            |\n| Round 3                                                                                                                                                                                                                                           | Round 3                                                                                                                                                                                         |\n| Agent 1: After considering the suggestions of other agents, I still believe that the move 14. Qa4 is the best move in the current board state. It attacks the bishop on f5, prepares to develop the queen, and puts pressure on Black's position. | Agent 2: After considering the suggestions of other agents, I would suggest the move 14. Qa4. It attacks the bishop on f5, prepares to develop the queen and puts pressure on Black's position. |",
  "tables": [
    {
      "index": 0,
      "markdown": "| Debate Length   | Prompt                                                                                                                                                                       |\n|-----------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Short           | \" These are the solutions to the problem from other agents: [other answers] Based off the opinion of other agents, can you give an updated response . . . \"                  |\n| Long            | \" These are the solutions to the problem from other agents: [other answers] Using the opinion of other agents as additional advice, can you give an updated response . . . \" |"
    },
    {
      "index": 1,
      "markdown": "| Model                     | Arithmetic (%) ↑   | Grade School Math (%) ↑   | Chess ( ∆ PS) ↑   |\n|---------------------------|--------------------|---------------------------|-------------------|\n| Single Agent              | 67.0 ± 4.7         | 77.0 ± 4.2                | 91.4 ± 10.6       |\n| Single Agent (Reflection) | 72.1 ± 4.5         | 75.0 ± 4.3                | 102.1 ± 11.9      |\n| Multi-Agent (Majority)    | 69.0 ± 4.6         | 81.0 ± 3.9                | 102.2 ± 6.2       |\n| Multi-Agent (Debate)      | 81.8 ± 2.3         | 85.0 ± 3.5                | 122.9 ± 7.6       |"
    },
    {
      "index": 2,
      "markdown": "| Model                     | Biographies   | MMLU       | Chess Move Validity   |\n|---------------------------|---------------|------------|-----------------------|\n| Single Agent              | 66.0 ± 2.2    | 63.9 ± 4.8 | 29.3 ± 2.6            |\n| Single Agent (Reflection) | 68.3 ± 2.9    | 57.7 ± 5.0 | 38.8 ± 2.9            |\n| Multi-Agent (Debate)      | 73.8 ± 2.3    | 71.1 ± 4.6 | 45.2 ± 2.9            |"
    },
    {
      "index": 3,
      "markdown": "| Task           | Type     | Prompt                                                                                                                                                                                                                                                                                                                                                                                                                    |\n|----------------|----------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Arithmetic     | Starting | What is the result of {}+{}*{}+{}-{}*{}? Make sure to state your answer at the end of the response.                                                                                                                                                                                                                                                                                                                       |\n| Arithmetic     | Debate   | These are the recent/updated opinions from other agents: <other agent responses> Use these opinions carefully as additional advice, can you provide an updated answer? Make sure to state your answer at the end of the response.                                                                                                                                                                                         |\n| GSM8K          | Starting | Can you solve the following math problem? <Problem> Explain your reasoning. Your final answer should be a single numerical number, in the form \\boxed{{answer}}, at the end of your response.                                                                                                                                                                                                                             |\n| GSM8K          | Debate   | These are the solutions to the problem from other agents: <other agent responses> Using the solutions from other agents as additional information, can you provide your answer to the math problem? The original math problem is <Problem>. Your final answer should be a single numerical number, in the form \\boxed{{answer}}, at the end of your response.                                                             |\n| Chess          | Starting | Here is the current sequence of moves in a chess game: <moves>. What is the best chess move I should execute next? Give a single move suggestion of the form 14. <XXX> and make sure the chess move is valid in the current board state.                                                                                                                                                                                  |\n| Chess          | Debate   | Here are other chess move suggestions from other agents: <other agent responses> Using the chess suggestions from other agents as additional advice and your earlier generated solution, can you give me your updated thoughts on the best next chess move I should play given the chess sequence ? Give a single move suggestion of the form 14. <XXX> and make sure the chess move is valid in the current board state. |\n| Biographies    | Starting | Give a bullet point biography of highlighting their contributions and achievements as a computer scientist, with each fact separated with a new line character.                                                                                                                                                                                                                                                           |\n| Biographies    | Debate   | Here are some bullet point biographies of <person> given by other agents: <other agent response> Closely examine your biography and the biography of other agents and provide an updated bullet point biography.                                                                                                                                                                                                          |\n| MMLU           | Starting | Can you answer the following question as accurately as possible? : A) , B) , C) , D) Explain your answer, putting the answer in the form (X) at the end of your response.                                                                                                                                                                                                                                                 |\n| MMLU           | Debate   | These are the solutions to the problem from other agents: <other agent responses> Using the reasoning from other agents as additional advice, can you give an updated answer? Examine your solution and that other agents. Put your answer in the form (X) at the end of your response.                                                                                                                                   |\n| Chess Validity | Starting | Given the chess game , give one valid destination square for the chess piece at . State the destination square in the form (X), where X follows the regex [a-h][1-8], for example (e5). Give a one line explanation of why your destination square is a valid move.                                                                                                                                                       |\n| Chess Validity | Debate   | Here are destination square suggestions from other agents: <other agent responses> Can you double check that your destination square is a valid move? Check the valid move justifications from other agents. State your final answer in a newline with a 2 letter response following the regex [a-h][1-8].                                                                                                                |"
    },
    {
      "index": 4,
      "markdown": "| Round 1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | Round 1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Agent 1: - Stephen R. Bourne is a British-born American computer scientist. - He is best known for creating the Bourne shell (sh) for the Unix operating system in 1979.\\n- The Bourne shell was the default Unix shell for many years and is still in use today. - Bourne also worked on the development of the UNIX System III and IV operating systems. - He later joinedAT&T Bell Laboratories, where he worked on the UNIX System Voperating system and its derivatives. - Bourne was awarded theACM Software System Award in 1983 for his work on the Bourne shell. - He is also a recipient of the USENIX Lifetime Achievement Award (2001) and the IEEE Computer Pioneer Award (2010). - Bourne is now retired and continues to be involved in the computer science community. | Agent 2: . - Stephen R. Bourne is a computer scientist known for his development of the Unix shell, or command-line interface, known as the Bourne shell. - He earned a bachelor's degree in mathematics and a doctorate in computer science from Cambridge University. - Bourne worked at Bell Labs, where he helped to create the Unix operating system and its command- line interface. - In addition to the Bourne shell, he also created the Bourne-Again shell (bash) and was involved in the creation of the Korn shell. - Bourne was awarded the USENIX Lifetime Achievement Award in 1999 and was elected as a Fellow of the Association for Computing Machinery in 2013. - He has authored and co-authored numerous technical papers and books, including \"The Unix System,\" a widely used textbook on Unix programming. |"
    },
    {
      "index": 5,
      "markdown": "| Round 1                                                                                                                                                                                                                                           | Round 1                                                                                                                                                                                         |\n|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Agent 1: 14. dxe6                                                                                                                                                                                                                                 | Agent 2: 14. Be3                                                                                                                                                                                |\n| Instruction: Using the solutions from other agents as additional information. (Copy Agent 2's reply)                                                                                                                                              | Instruction: Using the solutions from other agents as additional information. (Copy Agent 1's reply)                                                                                            |\n| Round 2                                                                                                                                                                                                                                           | Round 2                                                                                                                                                                                         |\n| Agent 1: Based on the current board state and the suggested moves, I would suggest the move: 14. Qa4. This move attacks the undefended bishop on f5 and puts pressure on black's position.                                                        | Agent 2: I would still suggest the move 14. Be3. It develops a piece and prepares to put pressure on black's position. Additionally, it reinforces the e4 pawn and prepares to castle kingside. |\n| Instruction: Using the solutions from other agents as additional information. (Copy Agent 2's reply)                                                                                                                                              | Instruction: Using the solutions from other agents as additional information. (Copy Agent 1's reply)                                                                                            |\n| Round 3                                                                                                                                                                                                                                           | Round 3                                                                                                                                                                                         |\n| Agent 1: After considering the suggestions of other agents, I still believe that the move 14. Qa4 is the best move in the current board state. It attacks the bishop on f5, prepares to develop the queen, and puts pressure on Black's position. | Agent 2: After considering the suggestions of other agents, I would suggest the move 14. Qa4. It attacks the bishop on f5, prepares to develop the queen and puts pressure on Black's position. |"
    }
  ],
  "stats": {
    "pages": 27,
    "chunksCreated": 87,
    "totalCharacters": 60695,
    "totalWords": 8151,
    "numTables": 6,
    "processingTimeMs": 22083
  }
}
# DES-002: YAGOKORO v2.0.0 Design Specification

## Document Information

| é …ç›® | å†…å®¹ |
|------|------|
| **Document ID** | DES-002 |
| **Version** | 0.1.0 (Draft) |
| **Status** | Draft |
| **Created** | 2025-12-30 |
| **Author** | YAGOKORO Development Team |
| **Related Documents** | REQ-002, DES-001 |

---

## 1. Executive Summary

æœ¬è¨­è¨ˆæ›¸ã¯ã€YAGOKORO v2.0.0ã®æŠ€è¡“è¨­è¨ˆã‚’å®šç¾©ã™ã‚‹ã€‚REQ-002ã§å®šç¾©ã•ã‚ŒãŸè¦ä»¶ã«åŸºã¥ãã€ä»¥ä¸‹ã®4ã¤ã®ã‚³ã‚¢æ©Ÿèƒ½ã¨2ã¤ã®çµ±åˆæ©Ÿèƒ½ã‚’è¨­è¨ˆã™ã‚‹ã€‚

| Phase | æ©Ÿèƒ½ | è¨­è¨ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ |
|-------|------|---------------|
| Phase 1 | ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ­£è¦åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ | Â§3 |
| Phase 2 | ãƒãƒ«ãƒãƒ›ãƒƒãƒ—æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ | Â§4 |
| Phase 3 | Research Gap Analyzer | Â§5 |
| Phase 4 | Technology Lifecycle Tracker | Â§6 |
| Phase 5 | Enhanced MCP Tools | Â§7 |
| Phase 6 | Enhanced CLI Commands | Â§8 |

---

## 2. System Architecture Overview

### 2.1 High-Level Architecture (C4 Context)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           External Systems                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  arXiv   â”‚   â”‚ Semantic â”‚   â”‚  Ollama  â”‚   â”‚ OpenAI/  â”‚                 â”‚
â”‚  â”‚   API    â”‚   â”‚ Scholar  â”‚   â”‚  (Local) â”‚   â”‚ Anthropicâ”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚       â”‚              â”‚              â”‚              â”‚                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚              â”‚              â”‚
        â–¼              â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         YAGOKORO v2.0.0 System                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   CLI Layer     â”‚   â”‚   MCP Server    â”‚   â”‚   API Layer     â”‚          â”‚
â”‚  â”‚  (Commander)    â”‚   â”‚   (stdio/sse)   â”‚   â”‚   (REST/WS)     â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚           â”‚                     â”‚                     â”‚                    â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                          â–¼                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    Application Services Layer                         â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚
â”‚  â”‚  â”‚  Entity     â”‚ â”‚  MultiHop   â”‚ â”‚  Research   â”‚ â”‚  Lifecycle  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚ Normalizer  â”‚ â”‚  Reasoner   â”‚ â”‚ Gap Analyzerâ”‚ â”‚  Tracker    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  Service    â”‚ â”‚  Service    â”‚ â”‚  Service    â”‚ â”‚  Service    â”‚    â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â”‚                                                  â”‚
â”‚                          â–¼                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                      Core Domain Layer                                â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚
â”‚  â”‚  â”‚  Entities   â”‚ â”‚  Relations  â”‚ â”‚ Communities â”‚ â”‚  Aliases    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚ (AIModel,..)â”‚ â”‚ (DERIVED,..)â”‚ â”‚ (Clusters)  â”‚ â”‚  (Mapping)  â”‚    â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â”‚                                                  â”‚
â”‚                          â–¼                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    Infrastructure Layer                               â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚
â”‚  â”‚  â”‚   Neo4j     â”‚ â”‚   Qdrant    â”‚ â”‚    LLM      â”‚ â”‚   Cache     â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  Adapter    â”‚ â”‚  Adapter    â”‚ â”‚   Client    â”‚ â”‚  (Redis)    â”‚    â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚                     â”‚
                          â–¼                     â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Neo4j   â”‚          â”‚  Qdrant  â”‚
                   â”‚  (Graph) â”‚          â”‚ (Vector) â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Package Structure

```
@yagokoro/
â”œâ”€â”€ domain/                    # Core domain entities
â”‚   â”œâ”€â”€ entities/              # Entity definitions
â”‚   â”œâ”€â”€ relations/             # Relation types
â”‚   â”œâ”€â”€ value-objects/         # Value objects
â”‚   â””â”€â”€ ports/                 # Repository interfaces
â”‚
â”œâ”€â”€ neo4j/                     # Neo4j infrastructure
â”‚   â”œâ”€â”€ connection/            # Connection management
â”‚   â”œâ”€â”€ repositories/          # Repository implementations
â”‚   â””â”€â”€ queries/               # Cypher query builders
â”‚
â”œâ”€â”€ vector/                    # Vector DB infrastructure
â”‚   â”œâ”€â”€ connection/            # Qdrant connection
â”‚   â”œâ”€â”€ embedding/             # Embedding service
â”‚   â””â”€â”€ store/                 # Vector store operations
â”‚
â”œâ”€â”€ graphrag/                  # GraphRAG core
â”‚   â”œâ”€â”€ extraction/            # Entity/Relation extraction
â”‚   â”œâ”€â”€ community/             # Community detection
â”‚   â”œâ”€â”€ query/                 # Query engines
â”‚   â”œâ”€â”€ llm/                   # LLM clients
â”‚   â””â”€â”€ ingest/                # Document ingestion
â”‚
â”œâ”€â”€ normalizer/                # ğŸ†• Entity normalization (Phase 1)
â”‚   â”œâ”€â”€ rules/                 # Normalization rules
â”‚   â”œâ”€â”€ similarity/            # Similarity matching
â”‚   â”œâ”€â”€ alias/                 # Alias table management
â”‚   â””â”€â”€ service/               # Normalizer service
â”‚
â”œâ”€â”€ reasoner/                  # ğŸ†• Multi-hop reasoning (Phase 2)
â”‚   â”œâ”€â”€ pathfinder/            # Path finding algorithms
â”‚   â”œâ”€â”€ cache/                 # Path cache
â”‚   â””â”€â”€ explainer/             # Path explanation
â”‚
â”œâ”€â”€ analyzer/                  # ğŸ†• Research analysis (Phase 3-4)
â”‚   â”œâ”€â”€ gap/                   # Research gap analysis
â”‚   â”œâ”€â”€ lifecycle/             # Technology lifecycle
â”‚   â””â”€â”€ report/                # Report generation
â”‚
â”œâ”€â”€ mcp/                       # MCP server
â”‚   â”œâ”€â”€ server/                # MCP server core
â”‚   â”œâ”€â”€ tools/                 # ğŸ†• Enhanced tools
â”‚   â””â”€â”€ resources/             # MCP resources
â”‚
â””â”€â”€ cli/                       # CLI application
    â”œâ”€â”€ commands/              # ğŸ†• Enhanced commands
    â””â”€â”€ utils/                 # CLI utilities
```

### 2.3 Data Flow Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   è«–æ–‡PDF    â”‚â”€â”€â”€â”€â–¶â”‚  æŠ½å‡ºå‡¦ç†    â”‚â”€â”€â”€â”€â–¶â”‚  æ­£è¦åŒ–      â”‚
â”‚   (arXiv)    â”‚     â”‚  (Docling)   â”‚     â”‚ (Phase 1)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Neo4j      â”‚â—€â”€â”€â”€â”€â”‚  ã‚°ãƒ©ãƒ•æ§‹ç¯‰  â”‚â”€â”€â”€â”€â–¶â”‚   Qdrant     â”‚
â”‚  (Graph)     â”‚     â”‚              â”‚     â”‚  (Vector)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                          â”‚
       â–¼                                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ãƒ‘ã‚¹æ¢ç´¢    â”‚â”€â”€â”€â”€â–¶â”‚  åˆ†æå‡¦ç†    â”‚â”€â”€â”€â”€â–¶â”‚  ãƒ¬ãƒãƒ¼ãƒˆ    â”‚
â”‚ (Phase 2)   â”‚     â”‚ (Phase 3-4) â”‚     â”‚   ç”Ÿæˆ       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Phase 1: Entity Normalization Pipeline Design

### 3.1 Component Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EntityNormalizerService                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Rule       â”‚   â”‚  Similarity  â”‚   â”‚    LLM       â”‚        â”‚
â”‚  â”‚  Normalizer  â”‚â”€â”€â–¶â”‚   Matcher    â”‚â”€â”€â–¶â”‚  Confirmer   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚         â”‚                  â”‚                  â”‚                 â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                            â–¼                                    â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                   â”‚    Alias     â”‚                              â”‚
â”‚                   â”‚    Table     â”‚                              â”‚
â”‚                   â”‚   Manager    â”‚                              â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                            â”‚                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Neo4j      â”‚
                    â”‚ (AliasNode)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Class Design

```typescript
// libs/normalizer/src/rules/RuleNormalizer.ts
export interface NormalizationRule {
  pattern: RegExp;
  replacement: string;
  priority: number;
  domain?: string;
}

export class RuleNormalizer {
  private rules: NormalizationRule[] = [];
  private domainDictionary: Map<string, string> = new Map();

  constructor(rulesPath?: string, dictionaryPath?: string) {
    this.loadDefaultRules();
    if (rulesPath) this.loadRulesFromFile(rulesPath);
    if (dictionaryPath) this.loadDictionary(dictionaryPath);
  }

  // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ«ãƒ¼ãƒ«
  private loadDefaultRules(): void {
    this.rules = [
      // ãƒã‚¤ãƒ•ãƒ³ãƒ»ã‚¹ãƒšãƒ¼ã‚¹ã®æ­£è¦åŒ–
      { pattern: /GPT-(\d)/gi, replacement: 'GPT$1', priority: 100 },
      { pattern: /BERT[-\s]?(Base|Large)/gi, replacement: 'BERT-$1', priority: 100 },
      
      // ç•¥èªã®å±•é–‹/çµ±ä¸€
      { pattern: /chain[- ]of[- ]thought/gi, replacement: 'CoT', priority: 90 },
      { pattern: /Chain of Thought/gi, replacement: 'CoT', priority: 90 },
      { pattern: /few[- ]shot/gi, replacement: 'few-shot', priority: 90 },
      
      // ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ­£è¦åŒ–
      { pattern: /(\w+)\s+v?(\d+(\.\d+)*)/gi, replacement: '$1-$2', priority: 80 },
    ];
  }

  normalize(entity: string): NormalizationResult {
    let normalized = entity;
    const appliedRules: string[] = [];

    // ãƒ‰ãƒ¡ã‚¤ãƒ³è¾æ›¸ãƒã‚§ãƒƒã‚¯
    if (this.domainDictionary.has(entity.toLowerCase())) {
      return {
        original: entity,
        normalized: this.domainDictionary.get(entity.toLowerCase())!,
        appliedRules: ['domain_dictionary'],
        confidence: 1.0
      };
    }

    // ãƒ«ãƒ¼ãƒ«é©ç”¨ï¼ˆå„ªå…ˆåº¦é †ï¼‰
    const sortedRules = [...this.rules].sort((a, b) => b.priority - a.priority);
    for (const rule of sortedRules) {
      if (rule.pattern.test(normalized)) {
        normalized = normalized.replace(rule.pattern, rule.replacement);
        appliedRules.push(rule.pattern.toString());
      }
    }

    return {
      original: entity,
      normalized,
      appliedRules,
      confidence: appliedRules.length > 0 ? 0.9 : 0.5
    };
  }
}

interface NormalizationResult {
  original: string;
  normalized: string;
  appliedRules: string[];
  confidence: number;
}
```

```typescript
// libs/normalizer/src/similarity/SimilarityMatcher.ts
import { distance as levenshtein } from 'fastest-levenshtein';

export interface SimilarityMatch {
  entity: string;
  score: number;
  matchType: 'exact' | 'fuzzy' | 'substring';
}

export class SimilarityMatcher {
  private threshold: number;

  constructor(threshold: number = 0.8) {
    this.threshold = threshold;
  }

  findSimilar(entity: string, candidates: string[]): SimilarityMatch[] {
    const matches: SimilarityMatch[] = [];
    const entityLower = entity.toLowerCase();

    for (const candidate of candidates) {
      if (candidate === entity) continue;
      
      const candidateLower = candidate.toLowerCase();
      
      // 1. å®Œå…¨ä¸€è‡´ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ç„¡è¦–ï¼‰
      if (entityLower === candidateLower) {
        matches.push({ entity: candidate, score: 1.0, matchType: 'exact' });
        continue;
      }

      // 2. éƒ¨åˆ†æ–‡å­—åˆ—
      if (entityLower.includes(candidateLower) || candidateLower.includes(entityLower)) {
        const score = Math.min(entityLower.length, candidateLower.length) / 
                     Math.max(entityLower.length, candidateLower.length);
        if (score >= this.threshold) {
          matches.push({ entity: candidate, score, matchType: 'substring' });
          continue;
        }
      }

      // 3. Levenshteinè·é›¢
      const maxLen = Math.max(entity.length, candidate.length);
      const dist = levenshtein(entityLower, candidateLower);
      const score = 1 - (dist / maxLen);
      
      if (score >= this.threshold) {
        matches.push({ entity: candidate, score, matchType: 'fuzzy' });
      }
    }

    return matches.sort((a, b) => b.score - a.score);
  }

  // Jaccardé¡ä¼¼åº¦ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ãƒ™ãƒ¼ã‚¹ï¼‰
  jaccardSimilarity(entity1: string, entity2: string): number {
    const tokens1 = new Set(entity1.toLowerCase().split(/[\s\-_]+/));
    const tokens2 = new Set(entity2.toLowerCase().split(/[\s\-_]+/));
    
    const intersection = new Set([...tokens1].filter(x => tokens2.has(x)));
    const union = new Set([...tokens1, ...tokens2]);
    
    return intersection.size / union.size;
  }
}
```

```typescript
// libs/normalizer/src/alias/AliasTableManager.ts
export interface AliasEntry {
  alias: string;
  canonical: string;
  confidence: number;
  source: 'rule' | 'similarity' | 'llm' | 'manual';
  createdAt: Date;
  updatedAt: Date;
}

export class AliasTableManager {
  private neo4jConnection: Neo4jConnection;
  private cache: Map<string, string> = new Map();

  constructor(neo4jConnection: Neo4jConnection) {
    this.neo4jConnection = neo4jConnection;
  }

  async initialize(): Promise<void> {
    // ã‚¨ã‚¤ãƒªã‚¢ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ç”¨ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
    await this.neo4jConnection.run(`
      CREATE INDEX alias_idx IF NOT EXISTS FOR (a:Alias) ON (a.alias)
    `);
    
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãƒ­ãƒ¼ãƒ‰
    await this.loadCache();
  }

  async addAlias(entry: Omit<AliasEntry, 'createdAt' | 'updatedAt'>): Promise<void> {
    const now = new Date();
    
    await this.neo4jConnection.run(`
      MERGE (a:Alias {alias: $alias})
      SET a.canonical = $canonical,
          a.confidence = $confidence,
          a.source = $source,
          a.updatedAt = datetime($updatedAt)
      ON CREATE SET a.createdAt = datetime($createdAt)
    `, {
      ...entry,
      createdAt: now.toISOString(),
      updatedAt: now.toISOString()
    });

    this.cache.set(entry.alias.toLowerCase(), entry.canonical);
  }

  getCanonical(alias: string): string | null {
    return this.cache.get(alias.toLowerCase()) || null;
  }

  async rollback(alias: string): Promise<boolean> {
    const result = await this.neo4jConnection.run(`
      MATCH (a:Alias {alias: $alias})
      DELETE a
      RETURN count(a) as deleted
    `, { alias });
    
    this.cache.delete(alias.toLowerCase());
    return result.records[0]?.get('deleted') > 0;
  }

  async exportToJson(): Promise<AliasEntry[]> {
    const result = await this.neo4jConnection.run(`
      MATCH (a:Alias)
      RETURN a.alias as alias, a.canonical as canonical, 
             a.confidence as confidence, a.source as source,
             a.createdAt as createdAt, a.updatedAt as updatedAt
    `);
    
    return result.records.map(r => ({
      alias: r.get('alias'),
      canonical: r.get('canonical'),
      confidence: r.get('confidence'),
      source: r.get('source'),
      createdAt: new Date(r.get('createdAt')),
      updatedAt: new Date(r.get('updatedAt'))
    }));
  }
}
```

```typescript
// libs/normalizer/src/service/EntityNormalizerService.ts
export class EntityNormalizerService {
  private ruleNormalizer: RuleNormalizer;
  private similarityMatcher: SimilarityMatcher;
  private aliasManager: AliasTableManager;
  private llmClient: LLMClient;

  constructor(deps: EntityNormalizerDependencies) {
    this.ruleNormalizer = deps.ruleNormalizer;
    this.similarityMatcher = deps.similarityMatcher;
    this.aliasManager = deps.aliasManager;
    this.llmClient = deps.llmClient;
  }

  async normalize(
    entity: string, 
    options: NormalizeOptions = {}
  ): Promise<NormalizeResult> {
    // Step 0: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
    const cached = this.aliasManager.getCanonical(entity);
    if (cached) {
      return { 
        original: entity, 
        canonical: cached, 
        source: 'cache',
        confidence: 1.0 
      };
    }

    // Step 1: ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æ­£è¦åŒ–
    const ruleResult = this.ruleNormalizer.normalize(entity);
    
    // Step 2: é¡ä¼¼ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ¤œç´¢
    const existingEntities = await this.getExistingEntities();
    const similar = this.similarityMatcher.findSimilar(
      ruleResult.normalized, 
      existingEntities
    );

    // Step 3: LLMç¢ºèªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if (options.confirmWithLLM && similar.length > 0) {
      const llmResult = await this.confirmWithLLM(
        ruleResult.normalized, 
        similar[0].entity
      );
      
      if (llmResult.isEquivalent) {
        await this.aliasManager.addAlias({
          alias: entity,
          canonical: similar[0].entity,
          confidence: llmResult.confidence,
          source: 'llm'
        });
        
        return {
          original: entity,
          canonical: similar[0].entity,
          source: 'llm',
          confidence: llmResult.confidence,
          reasoning: llmResult.reasoning
        };
      }
    }

    // Step 4: é«˜ã‚¹ã‚³ã‚¢ã®é¡ä¼¼ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãŒã‚ã‚Œã°æ¡ç”¨
    if (similar.length > 0 && similar[0].score >= 0.95) {
      await this.aliasManager.addAlias({
        alias: entity,
        canonical: similar[0].entity,
        confidence: similar[0].score,
        source: 'similarity'
      });
      
      return {
        original: entity,
        canonical: similar[0].entity,
        source: 'similarity',
        confidence: similar[0].score
      };
    }

    // Step 5: ãƒ«ãƒ¼ãƒ«æ­£è¦åŒ–çµæœã‚’è¿”ã™
    if (ruleResult.appliedRules.length > 0) {
      await this.aliasManager.addAlias({
        alias: entity,
        canonical: ruleResult.normalized,
        confidence: ruleResult.confidence,
        source: 'rule'
      });
    }

    return {
      original: entity,
      canonical: ruleResult.normalized,
      source: 'rule',
      confidence: ruleResult.confidence
    };
  }

  async normalizeAll(options: NormalizeAllOptions = {}): Promise<NormalizationReport> {
    const entities = await this.getExistingEntities();
    const results: NormalizeResult[] = [];
    const errors: NormalizationError[] = [];

    for (const entity of entities) {
      try {
        const result = await this.normalize(entity, options);
        results.push(result);
      } catch (error) {
        errors.push({ entity, error: String(error) });
      }
    }

    return {
      totalEntities: entities.length,
      normalizedCount: results.filter(r => r.original !== r.canonical).length,
      results,
      errors
    };
  }

  private async confirmWithLLM(
    entity1: string, 
    entity2: string
  ): Promise<LLMEquivalenceResult> {
    const prompt = `
You are an AI research expert. Determine if these two terms refer to the same concept:
- Term 1: "${entity1}"
- Term 2: "${entity2}"

Respond in JSON format:
{
  "isEquivalent": true/false,
  "confidence": 0.0-1.0,
  "reasoning": "explanation"
}
`;
    
    const response = await this.llmClient.generate(prompt);
    return JSON.parse(response);
  }
}
```

### 3.3 Database Schema (Neo4j)

```cypher
// Alias Node
CREATE CONSTRAINT alias_unique IF NOT EXISTS 
FOR (a:Alias) REQUIRE a.alias IS UNIQUE;

// Alias to Entity relationship
// (Alias)-[:REFERS_TO]->(Entity)

// Example:
CREATE (a:Alias {
  alias: 'GPT-3',
  canonical: 'GPT3',
  confidence: 0.95,
  source: 'rule',
  createdAt: datetime(),
  updatedAt: datetime()
})
```

### 3.4 Normalization Rules Configuration

```yaml
# config/normalization-rules.yaml
version: 1.0
rules:
  # Model name normalization
  - pattern: "GPT-?(\\d+)"
    replacement: "GPT$1"
    priority: 100
    category: "model_name"
    
  - pattern: "BERT[-\\s]?(Base|Large|Mini|Small)"
    replacement: "BERT-$1"
    priority: 100
    category: "model_name"
    
  # Technique abbreviations
  - pattern: "[Cc]hain[- ]of[- ][Tt]hought"
    replacement: "CoT"
    priority: 90
    category: "technique"
    
  - pattern: "[Ff]ew[- ]shot"
    replacement: "few-shot"
    priority: 90
    category: "technique"

  # Organization normalization
  - pattern: "OpenAI|Open AI"
    replacement: "OpenAI"
    priority: 80
    category: "organization"

dictionaries:
  # Domain-specific canonical names
  - file: "dictionaries/ai-models.yaml"
  - file: "dictionaries/techniques.yaml"
  - file: "dictionaries/organizations.yaml"
```

### 3.5 ADR-001: Alias Storage Strategy

**Status**: Accepted

**Context**: ã‚¨ã‚¤ãƒªã‚¢ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä¿å­˜æ–¹æ³•ã¨ã—ã¦ã€(1) Neo4jã«ãƒãƒ¼ãƒ‰ã¨ã—ã¦ä¿å­˜ã€(2) åˆ¥DBã«ä¿å­˜ã€(3) ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ ã®é¸æŠè‚¢ãŒã‚ã‚‹ã€‚

**Decision**: Neo4jã«Aliasãƒãƒ¼ãƒ‰ã¨ã—ã¦ä¿å­˜ã™ã‚‹ã€‚

**Rationale**:
- ã‚°ãƒ©ãƒ•ã¨åŒã˜ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã§ç®¡ç†å¯èƒ½
- Cypher ã‚¯ã‚¨ãƒªã§ã‚¨ã‚¤ãƒªã‚¢ã‚¹è§£æ±ºãŒå¯èƒ½
- é–¢ä¿‚æ€§ï¼ˆREFERS_TOï¼‰ã‚’æ˜ç¤ºçš„ã«ãƒ¢ãƒ‡ãƒ«åŒ–

**Consequences**:
- Neo4jã¸ã®ä¾å­˜ãŒå¢—åŠ 
- æ­£è¦åŒ–æ™‚ã«DBæ¥ç¶šãŒå¿…è¦

---

## 4. Phase 2: Multi-hop Reasoning Engine Design

### 4.1 Component Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MultiHopReasonerService                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚    Query     â”‚   â”‚    Path      â”‚   â”‚     Path     â”‚        â”‚
â”‚  â”‚   Parser     â”‚â”€â”€â–¶â”‚   Finder     â”‚â”€â”€â–¶â”‚   Explainer  â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                            â”‚                  â”‚                 â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”           â”‚                 â”‚
â”‚                     â–¼             â–¼           â”‚                 â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚                 â”‚
â”‚              â”‚   BFS    â”‚  â”‚   DFS    â”‚       â”‚                 â”‚
â”‚              â”‚  Finder  â”‚  â”‚  Finder  â”‚       â”‚                 â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚                 â”‚
â”‚                     â”‚             â”‚           â”‚                 â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜           â”‚                 â”‚
â”‚                            â–¼                  â”‚                 â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚                 â”‚
â”‚                     â”‚    Path      â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                     â”‚    Cache     â”‚                            â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                            â”‚                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Neo4j      â”‚
                    â”‚   (Graph)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Class Design

```typescript
// libs/reasoner/src/pathfinder/PathFinder.ts
export interface PathQuery {
  startEntityType: EntityType;
  startEntityName?: string;
  endEntityType: EntityType;
  endEntityName?: string;
  maxHops: number;
  relationTypes?: RelationType[];
  excludeRelations?: RelationType[];
}

export interface PathResult {
  paths: Path[];
  statistics: PathStatistics;
  executionTime: number;
}

export interface Path {
  nodes: PathNode[];
  relations: PathRelation[];
  score: number;
  hops: number;
}

export interface PathNode {
  id: string;
  type: EntityType;
  name: string;
  properties: Record<string, unknown>;
}

export interface PathRelation {
  type: RelationType;
  direction: 'outgoing' | 'incoming';
  properties: Record<string, unknown>;
}

export interface PathStatistics {
  totalPaths: number;
  averageHops: number;
  minHops: number;
  maxHops: number;
  pathsByHops: Record<number, number>;
}
```

```typescript
// libs/reasoner/src/pathfinder/BFSPathFinder.ts
export class BFSPathFinder implements PathFinderStrategy {
  private neo4jConnection: Neo4jConnection;
  private cycleDetector: CycleDetector;

  constructor(neo4jConnection: Neo4jConnection) {
    this.neo4jConnection = neo4jConnection;
    this.cycleDetector = new CycleDetector();
  }

  async findPaths(query: PathQuery): Promise<PathResult> {
    const startTime = Date.now();

    // Cypher ã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰
    const cypher = this.buildCypherQuery(query);
    
    const result = await this.neo4jConnection.run(cypher, {
      startType: query.startEntityType,
      startName: query.startEntityName,
      endType: query.endEntityType,
      endName: query.endEntityName,
      maxHops: query.maxHops
    });

    const paths = this.processPaths(result.records);
    const filteredPaths = this.filterCyclicPaths(paths);

    return {
      paths: filteredPaths,
      statistics: this.calculateStatistics(filteredPaths),
      executionTime: Date.now() - startTime
    };
  }

  private buildCypherQuery(query: PathQuery): string {
    const relationFilter = query.relationTypes 
      ? `:${query.relationTypes.join('|')}` 
      : '';
    
    const excludeClause = query.excludeRelations?.length
      ? `WHERE NOT type(r) IN [${query.excludeRelations.map(t => `'${t}'`).join(',')}]`
      : '';

    return `
      MATCH path = shortestPath(
        (start:${query.startEntityType} ${query.startEntityName ? '{name: $startName}' : ''})
        -[${relationFilter}*1..${query.maxHops}]-
        (end:${query.endEntityType} ${query.endEntityName ? '{name: $endName}' : ''})
      )
      ${excludeClause}
      RETURN path, length(path) as hops
      ORDER BY hops ASC
      LIMIT 100
    `;
  }

  private filterCyclicPaths(paths: Path[]): Path[] {
    return paths.filter(path => !this.cycleDetector.hasCycle(path));
  }
}
```

```typescript
// libs/reasoner/src/pathfinder/CycleDetector.ts
export class CycleDetector {
  hasCycle(path: Path): boolean {
    const nodeIds = path.nodes.map(n => n.id);
    const uniqueIds = new Set(nodeIds);
    return nodeIds.length !== uniqueIds.size;
  }

  findCycles(paths: Path[]): CycleReport {
    const cycles: CycleInfo[] = [];
    
    for (const path of paths) {
      if (this.hasCycle(path)) {
        cycles.push({
          pathId: this.generatePathId(path),
          nodes: path.nodes,
          cycleNodes: this.identifyCycleNodes(path)
        });
      }
    }

    return {
      totalPaths: paths.length,
      cyclicPaths: cycles.length,
      cycles
    };
  }

  private identifyCycleNodes(path: Path): string[] {
    const nodeIds = path.nodes.map(n => n.id);
    const seen = new Set<string>();
    const duplicates: string[] = [];
    
    for (const id of nodeIds) {
      if (seen.has(id)) {
        duplicates.push(id);
      }
      seen.add(id);
    }
    
    return duplicates;
  }
}
```

```typescript
// libs/reasoner/src/cache/PathCache.ts
import { LRUCache } from 'lru-cache';

export interface CacheOptions {
  maxSize: number;
  ttlMs: number;
}

export class PathCache {
  private cache: LRUCache<string, CachedPathResult>;

  constructor(options: CacheOptions = { maxSize: 1000, ttlMs: 3600000 }) {
    this.cache = new LRUCache({
      max: options.maxSize,
      ttl: options.ttlMs,
    });
  }

  generateKey(query: PathQuery): string {
    return JSON.stringify({
      start: `${query.startEntityType}:${query.startEntityName || '*'}`,
      end: `${query.endEntityType}:${query.endEntityName || '*'}`,
      maxHops: query.maxHops,
      relations: query.relationTypes?.sort()
    });
  }

  get(query: PathQuery): PathResult | undefined {
    const key = this.generateKey(query);
    const cached = this.cache.get(key);
    
    if (cached) {
      return {
        ...cached.result,
        fromCache: true,
        cachedAt: cached.timestamp
      };
    }
    
    return undefined;
  }

  set(query: PathQuery, result: PathResult): void {
    const key = this.generateKey(query);
    this.cache.set(key, {
      result,
      timestamp: new Date()
    });
  }

  invalidate(pattern?: string): number {
    if (!pattern) {
      this.cache.clear();
      return this.cache.size;
    }
    
    let count = 0;
    for (const key of this.cache.keys()) {
      if (key.includes(pattern)) {
        this.cache.delete(key);
        count++;
      }
    }
    return count;
  }

  getStats(): CacheStats {
    return {
      size: this.cache.size,
      maxSize: this.cache.max,
      hitRate: this.cache.calculatedSize / this.cache.max
    };
  }
}

interface CachedPathResult {
  result: PathResult;
  timestamp: Date;
}
```

```typescript
// libs/reasoner/src/explainer/PathExplainer.ts
export interface PathExplanation {
  path: Path;
  naturalLanguage: string;
  summary: string;
  keyRelations: RelationExplanation[];
}

export interface RelationExplanation {
  from: string;
  to: string;
  relationType: string;
  explanation: string;
}

export class PathExplainer {
  private llmClient: LLMClient;

  constructor(llmClient: LLMClient) {
    this.llmClient = llmClient;
  }

  async explain(path: Path, context?: string): Promise<PathExplanation> {
    // ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ã®èª¬æ˜ç”Ÿæˆ
    const templateExplanation = this.generateTemplateExplanation(path);
    
    // LLMã«ã‚ˆã‚‹è‡ªç„¶è¨€èªèª¬æ˜
    const llmExplanation = await this.generateLLMExplanation(path, context);

    return {
      path,
      naturalLanguage: llmExplanation,
      summary: this.generateSummary(path),
      keyRelations: this.extractKeyRelations(path)
    };
  }

  private generateTemplateExplanation(path: Path): string {
    const parts: string[] = [];
    
    for (let i = 0; i < path.nodes.length - 1; i++) {
      const from = path.nodes[i];
      const to = path.nodes[i + 1];
      const rel = path.relations[i];
      
      parts.push(
        `${from.name} (${from.type}) -[${rel.type}]-> ${to.name} (${to.type})`
      );
    }
    
    return parts.join('\n');
  }

  private async generateLLMExplanation(path: Path, context?: string): Promise<string> {
    const pathDescription = this.generateTemplateExplanation(path);
    
    const prompt = `
ä»¥ä¸‹ã®çŸ¥è­˜ã‚°ãƒ©ãƒ•ãƒ‘ã‚¹ã‚’ã€AIç ”ç©¶ã®æ–‡è„ˆã§è‡ªç„¶ãªæ—¥æœ¬èªã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

ãƒ‘ã‚¹:
${pathDescription}

${context ? `è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: ${context}` : ''}

è¦æ±‚:
1. å„ãƒãƒ¼ãƒ‰é–“ã®é–¢ä¿‚æ€§ã‚’èª¬æ˜
2. ã“ã®ãƒ‘ã‚¹ãŒç¤ºå”†ã™ã‚‹ç ”ç©¶ä¸Šã®é–¢é€£æ€§ã‚’è¿°ã¹ã‚‹
3. 2-3æ–‡ã§ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹
`;

    return await this.llmClient.generate(prompt);
  }

  private generateSummary(path: Path): string {
    const start = path.nodes[0];
    const end = path.nodes[path.nodes.length - 1];
    
    return `${start.name} ã‹ã‚‰ ${end.name} ã¸ã® ${path.hops} ãƒ›ãƒƒãƒ—ã®ãƒ‘ã‚¹`;
  }

  private extractKeyRelations(path: Path): RelationExplanation[] {
    return path.relations.map((rel, i) => ({
      from: path.nodes[i].name,
      to: path.nodes[i + 1].name,
      relationType: rel.type,
      explanation: this.getRelationDescription(rel.type)
    }));
  }

  private getRelationDescription(relationType: string): string {
    const descriptions: Record<string, string> = {
      'DERIVED_FROM': 'ã‹ã‚‰æ´¾ç”Ÿã—ãŸ',
      'USES': 'ã‚’ä½¿ç”¨ã™ã‚‹',
      'DEVELOPED_BY': 'ã«ã‚ˆã£ã¦é–‹ç™ºã•ã‚ŒãŸ',
      'AUTHORED_BY': 'ã«ã‚ˆã£ã¦åŸ·ç­†ã•ã‚ŒãŸ',
      'AFFILIATED_WITH': 'ã«æ‰€å±ã™ã‚‹',
      'EVALUATED_ON': 'ã§è©•ä¾¡ã•ã‚ŒãŸ',
      'CITES': 'ã‚’å¼•ç”¨ã™ã‚‹',
      'IMPROVES': 'ã‚’æ”¹è‰¯ã—ãŸ',
      'APPLIES': 'ã‚’é©ç”¨ã™ã‚‹'
    };
    
    return descriptions[relationType] || relationType;
  }
}
```

```typescript
// libs/reasoner/src/service/MultiHopReasonerService.ts
export class MultiHopReasonerService {
  private pathFinder: BFSPathFinder;
  private pathCache: PathCache;
  private pathExplainer: PathExplainer;

  constructor(deps: MultiHopReasonerDependencies) {
    this.pathFinder = deps.pathFinder;
    this.pathCache = deps.pathCache;
    this.pathExplainer = deps.pathExplainer;
  }

  async findAndExplain(query: PathQuery): Promise<ReasoningResult> {
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
    const cached = this.pathCache.get(query);
    if (cached) {
      return {
        ...cached,
        explanations: await this.explainPaths(cached.paths)
      };
    }

    // ãƒ‘ã‚¹æ¤œç´¢
    const result = await this.pathFinder.findPaths(query);
    
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
    this.pathCache.set(query, result);

    // èª¬æ˜ç”Ÿæˆ
    const explanations = await this.explainPaths(result.paths.slice(0, 10));

    return {
      ...result,
      explanations
    };
  }

  async findRelationPaths(
    entity1: string,
    entity2: string,
    options: RelationPathOptions = {}
  ): Promise<ReasoningResult> {
    const query: PathQuery = {
      startEntityType: options.entity1Type || 'Entity',
      startEntityName: entity1,
      endEntityType: options.entity2Type || 'Entity',
      endEntityName: entity2,
      maxHops: options.maxHops || 4,
      relationTypes: options.relationTypes
    };

    return this.findAndExplain(query);
  }

  async findConceptConnections(concept: string): Promise<ConceptConnectionResult> {
    // ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‹ã‚‰é–¢é€£ã™ã‚‹å…¨ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¸ã®ãƒ‘ã‚¹ã‚’æ¤œç´¢
    const aiModels = await this.pathFinder.findPaths({
      startEntityType: 'Concept',
      startEntityName: concept,
      endEntityType: 'AIModel',
      maxHops: 3
    });

    const techniques = await this.pathFinder.findPaths({
      startEntityType: 'Concept',
      startEntityName: concept,
      endEntityType: 'Technique',
      maxHops: 3
    });

    return {
      concept,
      connectedModels: aiModels.paths,
      connectedTechniques: techniques.paths,
      summary: await this.generateConnectionSummary(concept, aiModels, techniques)
    };
  }

  private async explainPaths(paths: Path[]): Promise<PathExplanation[]> {
    return Promise.all(
      paths.map(path => this.pathExplainer.explain(path))
    );
  }
}
```

### 4.3 Cypher Query Patterns

```cypher
-- 2ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£é–“ã®æœ€çŸ­ãƒ‘ã‚¹
MATCH path = shortestPath(
  (start:AIModel {name: 'GPT4'})-[*1..4]-(end:Technique {name: 'CoT'})
)
RETURN path, length(path) as hops

-- å…¨ãƒ‘ã‚¹æ¤œç´¢ï¼ˆåˆ¶é™ä»˜ãï¼‰
MATCH path = (start:AIModel {name: 'GPT4'})-[*1..3]-(end:Technique {name: 'CoT'})
WHERE ALL(n IN nodes(path) WHERE single(x IN nodes(path) WHERE x = n))
RETURN path, length(path) as hops
ORDER BY hops ASC
LIMIT 50

-- ç‰¹å®šã®é–¢ä¿‚ã‚¿ã‚¤ãƒ—ã®ã¿ã‚’è¾¿ã‚‹
MATCH path = (start:AIModel)-[:USES|IMPROVES|DERIVED_FROM*1..3]-(end:Technique)
RETURN path, length(path) as hops

-- ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’çµŒç”±ã™ã‚‹ãƒ‘ã‚¹
MATCH path = (start:AIModel)-[*1..2]-(c:Community)-[*1..2]-(end:Technique)
WHERE start.name = 'GPT4'
RETURN path, c.name as community
```

### 4.4 ADR-002: Path Caching Strategy

**Status**: Accepted

**Context**: ãƒãƒ«ãƒãƒ›ãƒƒãƒ—æ¨è«–ã¯è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ã„ãŸã‚ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥ãŒå¿…è¦ã€‚

**Decision**: LRUã‚­ãƒ£ãƒƒã‚·ãƒ¥ + ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚­ãƒ¼ç”Ÿæˆã‚’æ¡ç”¨ã€‚

**Rationale**:
- LRUã¯å®Ÿè£…ãŒã‚·ãƒ³ãƒ—ãƒ«ã§ã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒè‰¯ã„
- ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥ã§ã‚­ãƒ¼ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€åŒä¸€ã‚¯ã‚¨ãƒªã®å†è¨ˆç®—ã‚’é˜²ã
- TTLè¨­å®šã§ã‚°ãƒ©ãƒ•æ›´æ–°æ™‚ã®æ•´åˆæ€§ã‚’æ‹…ä¿

**Consequences**:
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã«ã‚ˆã‚Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¤‰å‹•
- ã‚°ãƒ©ãƒ•æ›´æ–°æ™‚ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ãŒå¿…è¦

---

## 5. Phase 3: Research Gap Analyzer Design

### 5.1 Component Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ResearchGapAnalyzerService                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Citation    â”‚   â”‚  Cluster     â”‚   â”‚     Gap      â”‚        â”‚
â”‚  â”‚  Analyzer    â”‚â”€â”€â–¶â”‚  Analyzer    â”‚â”€â”€â–¶â”‚   Detector   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚         â”‚                  â”‚                  â”‚                 â”‚
â”‚         â–¼                  â–¼                  â–¼                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Citation    â”‚   â”‚  Cluster     â”‚   â”‚     Gap      â”‚        â”‚
â”‚  â”‚   Graph      â”‚   â”‚    Map       â”‚   â”‚    Report    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                            â”‚                                    â”‚
â”‚                            â–¼                                    â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚                     â”‚   Report     â”‚                            â”‚
â”‚                     â”‚  Generator   â”‚                            â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Class Design

```typescript
// libs/analyzer/src/gap/CitationAnalyzer.ts
export interface CitationMetrics {
  entityId: string;
  entityName: string;
  entityType: EntityType;
  citationCount: number;
  citedByCount: number;
  hIndex: number;
  recentCitationGrowth: number;  // ç›´è¿‘1å¹´ã®è¢«å¼•ç”¨æˆé•·ç‡
  crossDomainCitations: number;  // ç•°åˆ†é‡ã‹ã‚‰ã®å¼•ç”¨æ•°
}

export interface CitationNetwork {
  nodes: CitationNode[];
  edges: CitationEdge[];
  clusters: CitationCluster[];
}

export class CitationAnalyzer {
  private neo4jConnection: Neo4jConnection;

  constructor(neo4jConnection: Neo4jConnection) {
    this.neo4jConnection = neo4jConnection;
  }

  async analyzeCitationNetwork(domain?: string): Promise<CitationNetwork> {
    const cypher = `
      MATCH (p1:Publication)-[c:CITES]->(p2:Publication)
      ${domain ? 'WHERE p1.domain = $domain OR p2.domain = $domain' : ''}
      RETURN p1, c, p2
      LIMIT 10000
    `;

    const result = await this.neo4jConnection.run(cypher, { domain });
    return this.buildCitationNetwork(result);
  }

  async getTopCited(limit: number = 20): Promise<CitationMetrics[]> {
    const cypher = `
      MATCH (p:Publication)<-[c:CITES]-()
      WITH p, count(c) as citations
      OPTIONAL MATCH (p)-[co:CITES]->()
      WITH p, citations, count(co) as citing
      RETURN p.id as entityId, p.title as entityName, 'Publication' as entityType,
             citing as citationCount, citations as citedByCount
      ORDER BY citations DESC
      LIMIT $limit
    `;

    const result = await this.neo4jConnection.run(cypher, { limit });
    return result.records.map(r => ({
      entityId: r.get('entityId'),
      entityName: r.get('entityName'),
      entityType: r.get('entityType'),
      citationCount: r.get('citationCount'),
      citedByCount: r.get('citedByCount'),
      hIndex: 0, // åˆ¥é€”è¨ˆç®—
      recentCitationGrowth: 0,
      crossDomainCitations: 0
    }));
  }

  async findCitationIslands(): Promise<CitationIsland[]> {
    // å¼•ç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§å­¤ç«‹ã—ãŸã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’æ¤œå‡º
    const cypher = `
      CALL gds.wcc.stream('citationGraph')
      YIELD nodeId, componentId
      WITH componentId, count(*) as size
      WHERE size < 5  // å°ã•ãªå­¤ç«‹ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼
      RETURN componentId, size
      ORDER BY size DESC
    `;

    const result = await this.neo4jConnection.run(cypher);
    return result.records.map(r => ({
      componentId: r.get('componentId'),
      size: r.get('size')
    }));
  }
}
```

```typescript
// libs/analyzer/src/gap/ClusterAnalyzer.ts
export interface ResearchCluster {
  id: string;
  name: string;
  keywords: string[];
  entities: ClusterEntity[];
  publicationCount: number;
  avgPublicationYear: number;
  growthRate: number;  // å¹´é–“æˆé•·ç‡
  connectionStrength: Map<string, number>;  // ä»–ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã¨ã®æ¥ç¶šå¼·åº¦
}

export interface ClusterEntity {
  id: string;
  name: string;
  type: EntityType;
  centrality: number;
}

export class ClusterAnalyzer {
  private neo4jConnection: Neo4jConnection;

  constructor(neo4jConnection: Neo4jConnection) {
    this.neo4jConnection = neo4jConnection;
  }

  async analyzeExistingClusters(): Promise<ResearchCluster[]> {
    const cypher = `
      MATCH (c:Community)<-[:BELONGS_TO]-(e)
      WITH c, collect(e) as members, count(e) as size
      OPTIONAL MATCH (e)-[:AUTHORED_BY|DEVELOPED_BY]->(p:Publication)
      WITH c, members, size, avg(p.year) as avgYear, count(p) as pubCount
      RETURN c.id as id, c.name as name, c.keywords as keywords,
             members, size, avgYear, pubCount
      ORDER BY size DESC
    `;

    const result = await this.neo4jConnection.run(cypher);
    return this.processClusterResults(result);
  }

  async findClusterGaps(): Promise<ClusterGap[]> {
    // ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼é–“ã®æœªæ¥ç¶šé ˜åŸŸã‚’æ¤œå‡º
    const clusters = await this.analyzeExistingClusters();
    const gaps: ClusterGap[] = [];

    for (let i = 0; i < clusters.length; i++) {
      for (let j = i + 1; j < clusters.length; j++) {
        const connectionStrength = await this.measureConnection(
          clusters[i].id, 
          clusters[j].id
        );
        
        if (connectionStrength < 0.1) {  // å¼±ã„æ¥ç¶š
          gaps.push({
            cluster1: clusters[i],
            cluster2: clusters[j],
            connectionStrength,
            potentialBridgeTopics: await this.suggestBridgeTopics(
              clusters[i], 
              clusters[j]
            )
          });
        }
      }
    }

    return gaps;
  }

  private async measureConnection(
    cluster1Id: string, 
    cluster2Id: string
  ): Promise<number> {
    const cypher = `
      MATCH (c1:Community {id: $cluster1Id})<-[:BELONGS_TO]-(e1)
      MATCH (c2:Community {id: $cluster2Id})<-[:BELONGS_TO]-(e2)
      MATCH path = shortestPath((e1)-[*1..3]-(e2))
      RETURN count(path) as connectionCount
    `;

    const result = await this.neo4jConnection.run(cypher, { 
      cluster1Id, 
      cluster2Id 
    });
    
    const count = result.records[0]?.get('connectionCount') || 0;
    // æ­£è¦åŒ–ï¼ˆ0-1ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
    return Math.min(count / 100, 1);
  }

  private async suggestBridgeTopics(
    cluster1: ResearchCluster,
    cluster2: ResearchCluster
  ): Promise<string[]> {
    // ä¸¡ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«é–¢é€£ã—ãã†ãªãƒˆãƒ”ãƒƒã‚¯ã‚’ææ¡ˆ
    const keywords1 = new Set(cluster1.keywords);
    const keywords2 = new Set(cluster2.keywords);
    
    // å…±é€šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¢ã™
    const common = [...keywords1].filter(k => keywords2.has(k));
    
    // æ„å‘³çš„ã«è¿‘ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒšã‚¢ã‚’æ¢ã™
    // (å®Ÿéš›ã«ã¯ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦ã‚’ä½¿ç”¨)
    
    return common.length > 0 ? common : ['interdisciplinary research'];
  }
}
```

```typescript
// libs/analyzer/src/gap/GapDetector.ts
export interface ResearchGap {
  id: string;
  type: GapType;
  description: string;
  severity: 'low' | 'medium' | 'high';
  evidence: GapEvidence[];
  suggestedActions: string[];
  relatedEntities: string[];
}

export type GapType = 
  | 'underexplored_technique'
  | 'missing_combination'
  | 'isolated_cluster'
  | 'stale_research_area'
  | 'unexplored_application';

export interface GapEvidence {
  type: string;
  value: unknown;
  source: string;
}

export class GapDetector {
  private citationAnalyzer: CitationAnalyzer;
  private clusterAnalyzer: ClusterAnalyzer;
  private llmClient: LLMClient;

  constructor(deps: GapDetectorDependencies) {
    this.citationAnalyzer = deps.citationAnalyzer;
    this.clusterAnalyzer = deps.clusterAnalyzer;
    this.llmClient = deps.llmClient;
  }

  async detectGaps(options: GapDetectionOptions = {}): Promise<ResearchGap[]> {
    const gaps: ResearchGap[] = [];

    // 1. æœªæ¢ç´¢ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯çµ„ã¿åˆã‚ã›ã‚’æ¤œå‡º
    const unexploredCombinations = await this.findUnexploredCombinations();
    gaps.push(...unexploredCombinations);

    // 2. å­¤ç«‹ã—ãŸã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’æ¤œå‡º
    const isolatedClusters = await this.findIsolatedResearchAreas();
    gaps.push(...isolatedClusters);

    // 3. åœæ»ã—ã¦ã„ã‚‹ç ”ç©¶é ˜åŸŸã‚’æ¤œå‡º
    const staleAreas = await this.findStaleResearchAreas();
    gaps.push(...staleAreas);

    // 4. LLMã«ã‚ˆã‚‹è¿½åŠ åˆ†æ
    if (options.useLLM) {
      const llmGaps = await this.analyzWithLLM(gaps);
      gaps.push(...llmGaps);
    }

    return this.prioritizeGaps(gaps);
  }

  private async findUnexploredCombinations(): Promise<ResearchGap[]> {
    // å­˜åœ¨ã™ã‚‹ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã¨ãƒ¢ãƒ‡ãƒ«ã®çµ„ã¿åˆã‚ã›ã‚’å–å¾—
    const existingCombinations = await this.getExistingCombinations();
    
    // ç†è«–çš„ã«å¯èƒ½ãªçµ„ã¿åˆã‚ã›ã‚’ç”Ÿæˆ
    const possibleCombinations = await this.generatePossibleCombinations();
    
    // æœªæ¢ç´¢ã®çµ„ã¿åˆã‚ã›ã‚’ç‰¹å®š
    const unexplored = possibleCombinations.filter(
      combo => !existingCombinations.has(combo.key)
    );

    return unexplored.map(combo => ({
      id: `gap-combo-${combo.key}`,
      type: 'missing_combination' as GapType,
      description: `${combo.technique} ã¨ ${combo.model} ã®çµ„ã¿åˆã‚ã›ã¯æœªæ¢ç´¢`,
      severity: this.calculateSeverity(combo),
      evidence: [{
        type: 'missing_relation',
        value: combo,
        source: 'combination_analysis'
      }],
      suggestedActions: [
        `${combo.technique} ã‚’ ${combo.model} ã«é©ç”¨ã™ã‚‹ç ”ç©¶ã‚’å®Ÿæ–½`,
        `é¡ä¼¼ã®çµ„ã¿åˆã‚ã›ã®æˆåŠŸäº‹ä¾‹ã‚’èª¿æŸ»`
      ],
      relatedEntities: [combo.technique, combo.model]
    }));
  }

  private async findStaleResearchAreas(): Promise<ResearchGap[]> {
    // ç›´è¿‘2å¹´é–“ã§è«–æ–‡ãŒå‡ºã¦ã„ãªã„ãŒã€éå»ã«æ´»ç™ºã ã£ãŸé ˜åŸŸ
    const cypher = `
      MATCH (t:Technique)<-[:USES]-(p:Publication)
      WITH t, max(p.year) as lastYear, count(p) as totalPubs
      WHERE lastYear < date().year - 2 AND totalPubs > 5
      RETURN t.name as technique, lastYear, totalPubs
      ORDER BY totalPubs DESC
      LIMIT 20
    `;

    const result = await this.neo4jConnection.run(cypher);
    
    return result.records.map(r => ({
      id: `gap-stale-${r.get('technique')}`,
      type: 'stale_research_area' as GapType,
      description: `${r.get('technique')} ã¯ ${r.get('lastYear')} ä»¥é™è«–æ–‡ãŒå‡ºã¦ã„ãªã„`,
      severity: 'medium' as const,
      evidence: [{
        type: 'publication_gap',
        value: { lastYear: r.get('lastYear'), totalPubs: r.get('totalPubs') },
        source: 'temporal_analysis'
      }],
      suggestedActions: [
        `${r.get('technique')} ã®æœ€æ–°å‹•å‘ã‚’èª¿æŸ»`,
        `ä»£æ›¿æŠ€è¡“ã¨ã®æ¯”è¼ƒç ”ç©¶ã‚’å®Ÿæ–½`
      ],
      relatedEntities: [r.get('technique')]
    }));
  }

  private prioritizeGaps(gaps: ResearchGap[]): ResearchGap[] {
    // é‡è¦åº¦ã§ã‚½ãƒ¼ãƒˆ
    const severityOrder = { high: 0, medium: 1, low: 2 };
    return gaps.sort((a, b) => 
      severityOrder[a.severity] - severityOrder[b.severity]
    );
  }
}
```

```typescript
// libs/analyzer/src/gap/service/ResearchGapAnalyzerService.ts
export class ResearchGapAnalyzerService {
  private gapDetector: GapDetector;
  private reportGenerator: ReportGenerator;

  constructor(deps: ResearchGapAnalyzerDependencies) {
    this.gapDetector = deps.gapDetector;
    this.reportGenerator = deps.reportGenerator;
  }

  async analyze(domain?: string): Promise<GapAnalysisResult> {
    // ã‚®ãƒ£ãƒƒãƒ—æ¤œå‡º
    const gaps = await this.gapDetector.detectGaps({
      domain,
      useLLM: true
    });

    // çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—
    const statistics = this.calculateStatistics(gaps);

    // ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    const report = await this.reportGenerator.generate({
      gaps,
      statistics,
      domain
    });

    return {
      gaps,
      statistics,
      report
    };
  }

  async generateResearchProposals(
    gaps: ResearchGap[], 
    count: number = 5
  ): Promise<ResearchProposal[]> {
    const proposals: ResearchProposal[] = [];

    for (const gap of gaps.slice(0, count)) {
      const proposal = await this.generateProposal(gap);
      proposals.push(proposal);
    }

    return proposals;
  }

  private async generateProposal(gap: ResearchGap): Promise<ResearchProposal> {
    const prompt = `
ä»¥ä¸‹ã®ç ”ç©¶ã‚®ãƒ£ãƒƒãƒ—ã«åŸºã¥ã„ã¦ã€å…·ä½“çš„ãªç ”ç©¶ææ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã‚®ãƒ£ãƒƒãƒ—:
- ã‚¿ã‚¤ãƒ—: ${gap.type}
- èª¬æ˜: ${gap.description}
- é–¢é€£ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: ${gap.relatedEntities.join(', ')}

è¦æ±‚:
1. ç ”ç©¶ã‚¿ã‚¤ãƒˆãƒ«
2. ç ”ç©¶ç›®çš„ï¼ˆ2-3æ–‡ï¼‰
3. äºˆæƒ³ã•ã‚Œã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
4. æœŸå¾…ã•ã‚Œã‚‹æˆæœ
5. å¿…è¦ãªãƒªã‚½ãƒ¼ã‚¹

JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
`;

    const response = await this.llmClient.generate(prompt);
    return JSON.parse(response);
  }

  private calculateStatistics(gaps: ResearchGap[]): GapStatistics {
    return {
      totalGaps: gaps.length,
      byType: this.countByType(gaps),
      bySeverity: this.countBySeverity(gaps),
      topRelatedEntities: this.getTopRelatedEntities(gaps)
    };
  }
}
```

### 5.3 Gap Detection Algorithms

```
Algorithm: Unexplored Combination Detection

Input: Set of Models M, Set of Techniques T
Output: Set of Unexplored Combinations

1. existing_combinations = Query Neo4j for (Model)-[:USES]->(Technique)
2. all_possible = M Ã— T (Cartesian product)
3. unexplored = all_possible - existing_combinations
4. For each combo in unexplored:
   4.1. similarity_score = Calculate semantic similarity between model and technique
   4.2. If similarity_score > threshold:
        4.2.1. Add to candidate_gaps with score
5. Return top K candidate_gaps sorted by score
```

### 5.4 ADR-003: Gap Severity Calculation

**Status**: Accepted

**Context**: ç ”ç©¶ã‚®ãƒ£ãƒƒãƒ—ã®é‡è¦åº¦ã‚’åˆ¤å®šã™ã‚‹åŸºæº–ãŒå¿…è¦ã€‚

**Decision**: ä»¥ä¸‹ã®åŸºæº–ã§é‡è¦åº¦ã‚’è¨ˆç®—ã™ã‚‹:
- **High**: é–¢é€£ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®è¢«å¼•ç”¨æ•°ãŒä¸Šä½10%ã€ã‹ã¤æœ€çµ‚è«–æ–‡ã‹ã‚‰2å¹´ä»¥ä¸Š
- **Medium**: é–¢é€£ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®è¢«å¼•ç”¨æ•°ãŒä¸Šä½30%ã€ã¾ãŸã¯æ´»ç™ºãªã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã¨ã®æ¥ç¶šãŒå¼±ã„
- **Low**: ãã‚Œä»¥å¤–

**Rationale**:
- å¼•ç”¨æ•°ã¯ç ”ç©¶ã®å½±éŸ¿åŠ›ã‚’ç¤ºã™
- æ™‚é–“çµŒéã¯ç ”ç©¶ã®åœæ»ã‚’ç¤ºã™
- ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ¥ç¶šã¯å­¦éš›çš„é‡è¦æ€§ã‚’ç¤ºã™

---

## 6. Phase 4: Technology Lifecycle Tracker Design

### 6.1 Component Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  TechnologyLifecycleTrackerService               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Timeline   â”‚   â”‚    Phase     â”‚   â”‚   Trend      â”‚        â”‚
â”‚  â”‚  Aggregator  â”‚â”€â”€â–¶â”‚   Detector   â”‚â”€â”€â–¶â”‚  Predictor   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚         â”‚                  â”‚                  â”‚                 â”‚
â”‚         â–¼                  â–¼                  â–¼                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Timeline    â”‚   â”‚    Phase     â”‚   â”‚   Trend      â”‚        â”‚
â”‚  â”‚   Events     â”‚   â”‚   Labels     â”‚   â”‚  Forecast    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                            â”‚                                    â”‚
â”‚                            â–¼                                    â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚                     â”‚  Lifecycle   â”‚                            â”‚
â”‚                     â”‚   Report     â”‚                            â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 Class Design

```typescript
// libs/analyzer/src/lifecycle/TimelineAggregator.ts
export interface TimelineEvent {
  id: string;
  entityId: string;
  entityName: string;
  entityType: EntityType;
  eventType: EventType;
  date: Date;
  description: string;
  significance: number;  // 0-1ã‚¹ã‚±ãƒ¼ãƒ«
  relatedEntities: string[];
  source: string;
}

export type EventType = 
  | 'publication'      // è«–æ–‡ç™ºè¡¨
  | 'model_release'    // ãƒ¢ãƒ‡ãƒ«ãƒªãƒªãƒ¼ã‚¹
  | 'benchmark'        // ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ
  | 'adoption'         // ç”£æ¥­æ¡ç”¨
  | 'derivative'       // æ´¾ç”ŸæŠ€è¡“ã®ç™»å ´
  | 'improvement'      // æ”¹è‰¯ç‰ˆã®ç™ºè¡¨
  | 'deprecation';     // éæ¨å¥¨åŒ–

export class TimelineAggregator {
  private neo4jConnection: Neo4jConnection;

  constructor(neo4jConnection: Neo4jConnection) {
    this.neo4jConnection = neo4jConnection;
  }

  async aggregateTimeline(
    entityId: string, 
    options: TimelineOptions = {}
  ): Promise<TimelineEvent[]> {
    const events: TimelineEvent[] = [];

    // 1. è«–æ–‡ç™ºè¡¨ã‚¤ãƒ™ãƒ³ãƒˆ
    const publications = await this.getPublicationEvents(entityId);
    events.push(...publications);

    // 2. æ´¾ç”ŸæŠ€è¡“ã‚¤ãƒ™ãƒ³ãƒˆ
    const derivatives = await this.getDerivativeEvents(entityId);
    events.push(...derivatives);

    // 3. ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚¤ãƒ™ãƒ³ãƒˆ
    const benchmarks = await this.getBenchmarkEvents(entityId);
    events.push(...benchmarks);

    // æ™‚ç³»åˆ—ã§ã‚½ãƒ¼ãƒˆ
    return events.sort((a, b) => a.date.getTime() - b.date.getTime());
  }

  private async getPublicationEvents(entityId: string): Promise<TimelineEvent[]> {
    const cypher = `
      MATCH (e {id: $entityId})<-[:MENTIONS|USES]-(p:Publication)
      RETURN p.id as pubId, p.title as title, p.publishedDate as date,
             p.citations as citations
      ORDER BY date ASC
    `;

    const result = await this.neo4jConnection.run(cypher, { entityId });
    
    return result.records.map(r => ({
      id: `pub-${r.get('pubId')}`,
      entityId,
      entityName: '',  // å¾Œã§è¨­å®š
      entityType: 'Publication',
      eventType: 'publication' as EventType,
      date: new Date(r.get('date')),
      description: r.get('title'),
      significance: this.calculateSignificance(r.get('citations')),
      relatedEntities: [],
      source: 'neo4j'
    }));
  }

  private async getDerivativeEvents(entityId: string): Promise<TimelineEvent[]> {
    const cypher = `
      MATCH (e {id: $entityId})<-[:DERIVED_FROM]-(d)
      OPTIONAL MATCH (d)<-[:MENTIONS]-(p:Publication)
      RETURN d.id as derivativeId, d.name as name, 
             min(p.publishedDate) as firstMention
      ORDER BY firstMention ASC
    `;

    const result = await this.neo4jConnection.run(cypher, { entityId });
    
    return result.records
      .filter(r => r.get('firstMention'))
      .map(r => ({
        id: `derivative-${r.get('derivativeId')}`,
        entityId,
        entityName: r.get('name'),
        entityType: 'AIModel',
        eventType: 'derivative' as EventType,
        date: new Date(r.get('firstMention')),
        description: `${r.get('name')} ãŒæ´¾ç”Ÿ`,
        significance: 0.7,
        relatedEntities: [r.get('derivativeId')],
        source: 'neo4j'
      }));
  }
}
```

```typescript
// libs/analyzer/src/lifecycle/PhaseDetector.ts
export type LifecyclePhase = 
  | 'emerging'      // å‡ºç¾æœŸ: æœ€åˆã®è«–æ–‡ã‹ã‚‰2å¹´ä»¥å†…
  | 'growing'       // æˆé•·æœŸ: è«–æ–‡æ•°ãŒå¢—åŠ å‚¾å‘
  | 'mature'        // æˆç†ŸæœŸ: è«–æ–‡æ•°ãŒå®‰å®š
  | 'declining'     // è¡°é€€æœŸ: è«–æ–‡æ•°ãŒæ¸›å°‘å‚¾å‘
  | 'legacy';       // ãƒ¬ã‚¬ã‚·ãƒ¼: 2å¹´ä»¥ä¸Šæ–°è¦è«–æ–‡ãªã—

export interface PhaseResult {
  entity: string;
  currentPhase: LifecyclePhase;
  phaseStartDate: Date;
  confidence: number;
  metrics: PhaseMetrics;
  history: PhaseTransition[];
}

export interface PhaseMetrics {
  totalPublications: number;
  publicationsLastYear: number;
  publicationGrowthRate: number;
  citationMomentum: number;
  derivativeCount: number;
}

export interface PhaseTransition {
  fromPhase: LifecyclePhase;
  toPhase: LifecyclePhase;
  transitionDate: Date;
  reason: string;
}

export class PhaseDetector {
  private timelineAggregator: TimelineAggregator;

  constructor(timelineAggregator: TimelineAggregator) {
    this.timelineAggregator = timelineAggregator;
  }

  async detectPhase(entityId: string): Promise<PhaseResult> {
    const timeline = await this.timelineAggregator.aggregateTimeline(entityId);
    const metrics = this.calculateMetrics(timeline);
    const phase = this.determinePhase(metrics, timeline);
    const history = await this.reconstructHistory(entityId, timeline);

    return {
      entity: entityId,
      currentPhase: phase,
      phaseStartDate: this.findPhaseStartDate(history, phase),
      confidence: this.calculateConfidence(metrics),
      metrics,
      history
    };
  }

  private determinePhase(
    metrics: PhaseMetrics, 
    timeline: TimelineEvent[]
  ): LifecyclePhase {
    const now = new Date();
    const firstEvent = timeline[0];
    const lastEvent = timeline[timeline.length - 1];

    if (!firstEvent) return 'emerging';

    const ageInYears = (now.getTime() - firstEvent.date.getTime()) / 
                       (365 * 24 * 60 * 60 * 1000);
    const timeSinceLastEvent = (now.getTime() - lastEvent.date.getTime()) / 
                               (365 * 24 * 60 * 60 * 1000);

    // ãƒ¬ã‚¬ã‚·ãƒ¼åˆ¤å®š: 2å¹´ä»¥ä¸Šæ–°è¦è«–æ–‡ãªã—
    if (timeSinceLastEvent > 2 && metrics.totalPublications > 5) {
      return 'legacy';
    }

    // å‡ºç¾æœŸ: 2å¹´ä»¥å†…
    if (ageInYears < 2) {
      return 'emerging';
    }

    // æˆé•·ç‡ã«åŸºã¥ãåˆ¤å®š
    if (metrics.publicationGrowthRate > 0.2) {
      return 'growing';
    } else if (metrics.publicationGrowthRate > -0.1) {
      return 'mature';
    } else {
      return 'declining';
    }
  }

  private calculateMetrics(timeline: TimelineEvent[]): PhaseMetrics {
    const now = new Date();
    const oneYearAgo = new Date(now.getTime() - 365 * 24 * 60 * 60 * 1000);
    const twoYearsAgo = new Date(now.getTime() - 2 * 365 * 24 * 60 * 60 * 1000);

    const publications = timeline.filter(e => e.eventType === 'publication');
    const lastYearPubs = publications.filter(e => e.date > oneYearAgo);
    const prevYearPubs = publications.filter(
      e => e.date > twoYearsAgo && e.date <= oneYearAgo
    );

    const growthRate = prevYearPubs.length > 0 
      ? (lastYearPubs.length - prevYearPubs.length) / prevYearPubs.length
      : lastYearPubs.length > 0 ? 1 : 0;

    const derivatives = timeline.filter(e => e.eventType === 'derivative');

    return {
      totalPublications: publications.length,
      publicationsLastYear: lastYearPubs.length,
      publicationGrowthRate: growthRate,
      citationMomentum: this.calculateCitationMomentum(publications),
      derivativeCount: derivatives.length
    };
  }

  private calculateCitationMomentum(publications: TimelineEvent[]): number {
    // æœ€è¿‘ã®è«–æ–‡ã®è¢«å¼•ç”¨æ•°ã®ä¼¸ã³ç‡
    // å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã‚ˆã‚Šè©³ç´°ãªè¨ˆç®—ãŒå¿…è¦
    return publications
      .slice(-5)
      .reduce((sum, p) => sum + p.significance, 0) / 5;
  }
}
```

```typescript
// libs/analyzer/src/lifecycle/TrendPredictor.ts
export interface TrendForecast {
  entityId: string;
  predictions: PredictionPoint[];
  confidence: number;
  methodology: string;
  factors: TrendFactor[];
}

export interface PredictionPoint {
  date: Date;
  predictedPhase: LifecyclePhase;
  publicationForecast: number;
  confidenceInterval: [number, number];
}

export interface TrendFactor {
  name: string;
  impact: 'positive' | 'negative' | 'neutral';
  weight: number;
  description: string;
}

export class TrendPredictor {
  private phaseDetector: PhaseDetector;
  private llmClient: LLMClient;

  constructor(phaseDetector: PhaseDetector, llmClient: LLMClient) {
    this.phaseDetector = phaseDetector;
    this.llmClient = llmClient;
  }

  async predictTrend(
    entityId: string, 
    horizonMonths: number = 12
  ): Promise<TrendForecast> {
    const currentPhase = await this.phaseDetector.detectPhase(entityId);
    
    // ç·šå½¢å¤–æŒ¿ã«ã‚ˆã‚‹åŸºæœ¬äºˆæ¸¬
    const basePredictions = this.linearExtrapolation(
      currentPhase.metrics, 
      horizonMonths
    );

    // ãƒˆãƒ¬ãƒ³ãƒ‰è¦å› ã®åˆ†æ
    const factors = await this.analyzeTrendFactors(entityId, currentPhase);

    // è¦å› ã‚’è€ƒæ…®ã—ãŸèª¿æ•´äºˆæ¸¬
    const adjustedPredictions = this.adjustPredictions(basePredictions, factors);

    return {
      entityId,
      predictions: adjustedPredictions,
      confidence: this.calculateForecastConfidence(currentPhase, factors),
      methodology: 'linear_extrapolation_with_factor_adjustment',
      factors
    };
  }

  private linearExtrapolation(
    metrics: PhaseMetrics, 
    horizonMonths: number
  ): PredictionPoint[] {
    const predictions: PredictionPoint[] = [];
    const now = new Date();
    const monthlyGrowth = metrics.publicationGrowthRate / 12;

    for (let i = 1; i <= horizonMonths; i += 3) {
      const futureDate = new Date(now.getTime() + i * 30 * 24 * 60 * 60 * 1000);
      const quarterlyPubs = metrics.publicationsLastYear / 4;
      const predicted = quarterlyPubs * (1 + monthlyGrowth * i);
      
      predictions.push({
        date: futureDate,
        predictedPhase: this.predictPhase(metrics, i),
        publicationForecast: Math.max(0, predicted),
        confidenceInterval: [
          Math.max(0, predicted * 0.7), 
          predicted * 1.3
        ]
      });
    }

    return predictions;
  }

  private async analyzeTrendFactors(
    entityId: string, 
    currentPhase: PhaseResult
  ): Promise<TrendFactor[]> {
    const factors: TrendFactor[] = [];

    // 1. æ´¾ç”ŸæŠ€è¡“ã®å½±éŸ¿
    if (currentPhase.metrics.derivativeCount > 3) {
      factors.push({
        name: 'derivative_growth',
        impact: 'positive',
        weight: 0.3,
        description: 'å¤šãã®æ´¾ç”ŸæŠ€è¡“ãŒç™»å ´ã—ã¦ãŠã‚Šã€åŸºç›¤æŠ€è¡“ã¨ã—ã¦ã®é‡è¦æ€§ãŒé«˜ã„'
      });
    }

    // 2. å¼•ç”¨ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ 
    if (currentPhase.metrics.citationMomentum > 0.7) {
      factors.push({
        name: 'citation_momentum',
        impact: 'positive',
        weight: 0.25,
        description: 'æœ€è¿‘ã®è«–æ–‡ãŒå¤šãå¼•ç”¨ã•ã‚Œã¦ãŠã‚Šã€æ³¨ç›®åº¦ãŒé«˜ã„'
      });
    }

    // 3. LLMã«ã‚ˆã‚‹å®šæ€§åˆ†æ
    const llmFactors = await this.getLLMFactors(entityId, currentPhase);
    factors.push(...llmFactors);

    return factors;
  }

  private async getLLMFactors(
    entityId: string, 
    currentPhase: PhaseResult
  ): Promise<TrendFactor[]> {
    const prompt = `
ä»¥ä¸‹ã®æŠ€è¡“ã®ãƒˆãƒ¬ãƒ³ãƒ‰è¦å› ã‚’åˆ†æã—ã¦ãã ã•ã„:

- æŠ€è¡“ID: ${entityId}
- ç¾åœ¨ã®ãƒ•ã‚§ãƒ¼ã‚º: ${currentPhase.currentPhase}
- è«–æ–‡æ•°ï¼ˆæ˜¨å¹´ï¼‰: ${currentPhase.metrics.publicationsLastYear}
- æˆé•·ç‡: ${currentPhase.metrics.publicationGrowthRate}

ä»Šå¾Œã®ãƒˆãƒ¬ãƒ³ãƒ‰ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹è¦å› ã‚’3ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚

JSONé…åˆ—ã§å›ç­”:
[{
  "name": "factor_name",
  "impact": "positive|negative|neutral",
  "weight": 0.0-1.0,
  "description": "èª¬æ˜"
}]
`;

    const response = await this.llmClient.generate(prompt);
    return JSON.parse(response);
  }
}
```

```typescript
// libs/analyzer/src/lifecycle/service/TechnologyLifecycleTrackerService.ts
export class TechnologyLifecycleTrackerService {
  private timelineAggregator: TimelineAggregator;
  private phaseDetector: PhaseDetector;
  private trendPredictor: TrendPredictor;
  private reportGenerator: ReportGenerator;

  constructor(deps: LifecycleTrackerDependencies) {
    this.timelineAggregator = deps.timelineAggregator;
    this.phaseDetector = deps.phaseDetector;
    this.trendPredictor = deps.trendPredictor;
    this.reportGenerator = deps.reportGenerator;
  }

  async trackLifecycle(entityId: string): Promise<LifecycleReport> {
    // ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å–å¾—
    const timeline = await this.timelineAggregator.aggregateTimeline(entityId);
    
    // ãƒ•ã‚§ãƒ¼ã‚ºæ¤œå‡º
    const phase = await this.phaseDetector.detectPhase(entityId);
    
    // ãƒˆãƒ¬ãƒ³ãƒ‰äºˆæ¸¬
    const forecast = await this.trendPredictor.predictTrend(entityId);

    // ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    const report = await this.reportGenerator.generate({
      entityId,
      timeline,
      phase,
      forecast
    });

    return report;
  }

  async compareLifecycles(entityIds: string[]): Promise<LifecycleComparison> {
    const lifecycles = await Promise.all(
      entityIds.map(id => this.trackLifecycle(id))
    );

    return {
      entities: entityIds,
      lifecycles,
      comparison: this.generateComparison(lifecycles),
      insights: await this.generateInsights(lifecycles)
    };
  }

  async findEmergingTechnologies(limit: number = 10): Promise<EmergingTech[]> {
    // emergingãƒ•ã‚§ãƒ¼ã‚ºã‹ã¤æˆé•·ç‡ãŒé«˜ã„æŠ€è¡“ã‚’æ¤œç´¢
    const cypher = `
      MATCH (t:Technique)<-[:USES]-(p:Publication)
      WITH t, count(p) as pubCount, 
           max(p.publishedDate) as lastPub,
           min(p.publishedDate) as firstPub
      WHERE firstPub > date() - duration('P2Y')
      RETURN t.id as id, t.name as name, pubCount,
             duration.between(firstPub, lastPub).months as activeMonths
      ORDER BY pubCount DESC
      LIMIT $limit
    `;

    const result = await this.neo4jConnection.run(cypher, { limit });
    
    return result.records.map(r => ({
      id: r.get('id'),
      name: r.get('name'),
      publicationCount: r.get('pubCount'),
      activeMonths: r.get('activeMonths'),
      phase: 'emerging' as LifecyclePhase
    }));
  }

  async findDecliningTechnologies(limit: number = 10): Promise<DecliningTech[]> {
    // éå»ã«æ´»ç™ºã ã£ãŸãŒæœ€è¿‘åœæ»ã—ã¦ã„ã‚‹æŠ€è¡“
    const cypher = `
      MATCH (t:Technique)<-[:USES]-(p:Publication)
      WITH t, count(p) as pubCount, 
           max(p.publishedDate) as lastPub,
           min(p.publishedDate) as firstPub
      WHERE pubCount > 10 
        AND lastPub < date() - duration('P1Y')
        AND duration.between(firstPub, lastPub).years > 3
      RETURN t.id as id, t.name as name, pubCount, lastPub
      ORDER BY pubCount DESC
      LIMIT $limit
    `;

    const result = await this.neo4jConnection.run(cypher, { limit });
    
    return result.records.map(r => ({
      id: r.get('id'),
      name: r.get('name'),
      publicationCount: r.get('pubCount'),
      lastPublication: new Date(r.get('lastPub')),
      phase: 'declining' as LifecyclePhase
    }));
  }
}
```

### 6.3 Lifecycle Phase State Machine

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                 â”‚
                    â”‚    Emerging     â”‚
                    â”‚   (< 2 years)   â”‚
                    â”‚                 â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    growth > 0.2
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚     Growing     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚         â”‚  (growth > 0.2) â”‚         â”‚
         â”‚         â”‚                 â”‚         â”‚
         â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
         â”‚                  â”‚                  â”‚
    growth < -0.1      -0.1 < growth < 0.2    â”‚
         â”‚                  â”‚                  â”‚
         â”‚                  â–¼                  â”‚
         â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
         â”‚         â”‚                 â”‚         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚     Mature      â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ (stable growth) â”‚
                   â”‚                 â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                   growth < -0.1
                            â”‚
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚                 â”‚
                   â”‚    Declining    â”‚
                   â”‚ (negative trend)â”‚
                   â”‚                 â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                   no pubs > 2 years
                            â”‚
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚                 â”‚
                   â”‚     Legacy      â”‚
                   â”‚   (inactive)    â”‚
                   â”‚                 â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.4 ADR-004: Trend Prediction Methodology

**Status**: Accepted

**Context**: æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰ã®äºˆæ¸¬ã«ã¯æ§˜ã€…ãªæ‰‹æ³•ãŒã‚ã‚‹ã€‚

**Decision**: ç·šå½¢å¤–æŒ¿ + LLMè¦å› åˆ†æã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¡ç”¨ã€‚

**Rationale**:
- ç·šå½¢å¤–æŒ¿ã¯è§£é‡ˆå¯èƒ½æ€§ãŒé«˜ãã€åŸºæº–ã¨ã—ã¦é©åˆ‡
- LLMã¯å®šæ€§çš„è¦å› ï¼ˆæ¥­ç•Œå‹•å‘ã€æ–°æŠ€è¡“ã®ç™»å ´ç­‰ï¼‰ã‚’æ•æ‰å¯èƒ½
- ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã«ã‚ˆã‚Šå®šé‡ãƒ»å®šæ€§ã®ä¸¡é¢ã‚’ã‚«ãƒãƒ¼

**Consequences**:
- äºˆæ¸¬ç²¾åº¦ã¯LLMã®å“è³ªã«ä¾å­˜
- ä¿¡é ¼åŒºé–“ã®è¨ˆç®—ãŒè¤‡é›‘

---

## 7. Phase 5: Enhanced MCP Tools Design

### 7.1 MCP Tools Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MCP Server                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚  Existing Tools  â”‚  â”‚   New Tools      â”‚                     â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                     â”‚
â”‚  â”‚ â€¢ search_entity  â”‚  â”‚ â€¢ normalize_entityâ”‚                     â”‚
â”‚  â”‚ â€¢ get_entity     â”‚  â”‚ â€¢ find_paths     â”‚                     â”‚
â”‚  â”‚ â€¢ list_relations â”‚  â”‚ â€¢ analyze_gaps   â”‚                     â”‚
â”‚  â”‚ â€¢ query_graph    â”‚  â”‚ â€¢ track_lifecycleâ”‚                     â”‚
â”‚  â”‚ â€¢ search_similar â”‚  â”‚ â€¢ suggest_researchâ”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â€¢ get_trend      â”‚                     â”‚
â”‚                        â”‚ â€¢ compare_techs  â”‚                     â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Tool Registry                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.2 New MCP Tools Definition

```typescript
// libs/mcp/src/tools/normalization-tools.ts
import { z } from 'zod';

export const normalizeEntityTool = {
  name: 'normalize_entity',
  description: 'ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã‚’æ­£è¦åŒ–ã—ã€ã‚¨ã‚¤ãƒªã‚¢ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã«ç™»éŒ²ã™ã‚‹',
  inputSchema: z.object({
    entity: z.string().describe('æ­£è¦åŒ–å¯¾è±¡ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å'),
    confirmWithLLM: z.boolean().optional()
      .describe('LLMã§é¡ä¼¼ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨ã®åŒä¸€æ€§ã‚’ç¢ºèªã™ã‚‹ã‹'),
    dryRun: z.boolean().optional()
      .describe('å®Ÿéš›ã«ç™»éŒ²ã›ãšã«çµæœã‚’ç¢ºèªã™ã‚‹ã‹')
  }),
  handler: async (input: NormalizeEntityInput): Promise<NormalizeEntityOutput> => {
    const normalizer = container.get<EntityNormalizerService>('EntityNormalizer');
    const result = await normalizer.normalize(input.entity, {
      confirmWithLLM: input.confirmWithLLM ?? false
    });

    if (!input.dryRun) {
      await normalizer.persistResult(result);
    }

    return {
      original: result.original,
      canonical: result.canonical,
      source: result.source,
      confidence: result.confidence,
      persisted: !input.dryRun
    };
  }
};

export const normalizeAllEntitiesTool = {
  name: 'normalize_all_entities',
  description: 'ã™ã¹ã¦ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’ä¸€æ‹¬ã§æ­£è¦åŒ–ã™ã‚‹',
  inputSchema: z.object({
    entityType: z.enum(['AIModel', 'Technique', 'Person', 'Organization', 'All'])
      .optional()
      .describe('æ­£è¦åŒ–å¯¾è±¡ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚¿ã‚¤ãƒ—'),
    confirmWithLLM: z.boolean().optional(),
    dryRun: z.boolean().optional()
  }),
  handler: async (input: NormalizeAllInput): Promise<NormalizeAllOutput> => {
    const normalizer = container.get<EntityNormalizerService>('EntityNormalizer');
    const report = await normalizer.normalizeAll({
      entityType: input.entityType,
      confirmWithLLM: input.confirmWithLLM ?? false
    });

    return {
      totalProcessed: report.totalEntities,
      normalizedCount: report.normalizedCount,
      errorCount: report.errors.length,
      results: report.results.slice(0, 50),  // ä¸Šä½50ä»¶
      dryRun: input.dryRun ?? false
    };
  }
};
```

```typescript
// libs/mcp/src/tools/reasoning-tools.ts
export const findPathsTool = {
  name: 'find_paths',
  description: '2ã¤ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£é–“ã®ãƒ‘ã‚¹ï¼ˆé–¢ä¿‚ã®é€£é–ï¼‰ã‚’æ¤œç´¢ã™ã‚‹',
  inputSchema: z.object({
    entity1: z.string().describe('é–‹å§‹ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å'),
    entity2: z.string().describe('çµ‚äº†ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å'),
    maxHops: z.number().min(1).max(6).optional()
      .describe('æœ€å¤§ãƒ›ãƒƒãƒ—æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 4ï¼‰'),
    relationTypes: z.array(z.string()).optional()
      .describe('ãƒ•ã‚£ãƒ«ã‚¿ã™ã‚‹é–¢ä¿‚ã‚¿ã‚¤ãƒ—'),
    explain: z.boolean().optional()
      .describe('ãƒ‘ã‚¹ã®è‡ªç„¶è¨€èªèª¬æ˜ã‚’ç”Ÿæˆã™ã‚‹ã‹')
  }),
  handler: async (input: FindPathsInput): Promise<FindPathsOutput> => {
    const reasoner = container.get<MultiHopReasonerService>('MultiHopReasoner');
    
    const result = await reasoner.findRelationPaths(
      input.entity1, 
      input.entity2,
      {
        maxHops: input.maxHops ?? 4,
        relationTypes: input.relationTypes
      }
    );

    let explanations: PathExplanation[] = [];
    if (input.explain && result.paths.length > 0) {
      const explainer = container.get<PathExplainer>('PathExplainer');
      explanations = await Promise.all(
        result.paths.slice(0, 5).map(p => explainer.explain(p))
      );
    }

    return {
      pathsFound: result.paths.length,
      paths: result.paths.slice(0, 20),
      statistics: result.statistics,
      explanations,
      executionTime: result.executionTime
    };
  }
};

export const findConceptConnectionsTool = {
  name: 'find_concept_connections',
  description: 'ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‹ã‚‰é–¢é€£ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã€ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã¸ã®æ¥ç¶šã‚’æ¢ç´¢ã™ã‚‹',
  inputSchema: z.object({
    concept: z.string().describe('æ¢ç´¢ã®èµ·ç‚¹ã¨ãªã‚‹ã‚³ãƒ³ã‚»ãƒ—ãƒˆ'),
    maxHops: z.number().min(1).max(4).optional()
  }),
  handler: async (input: FindConceptInput): Promise<FindConceptOutput> => {
    const reasoner = container.get<MultiHopReasonerService>('MultiHopReasoner');
    return await reasoner.findConceptConnections(input.concept);
  }
};
```

```typescript
// libs/mcp/src/tools/analysis-tools.ts
export const analyzeGapsTool = {
  name: 'analyze_gaps',
  description: 'ç ”ç©¶ã‚®ãƒ£ãƒƒãƒ—ã‚’åˆ†æã—ã€æœªæ¢ç´¢ã®ç ”ç©¶é ˜åŸŸã‚’ç‰¹å®šã™ã‚‹',
  inputSchema: z.object({
    domain: z.string().optional()
      .describe('åˆ†æå¯¾è±¡ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆçœç•¥æ™‚ã¯å…¨ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼‰'),
    maxResults: z.number().min(1).max(50).optional()
      .describe('è¿”å´ã™ã‚‹æœ€å¤§ã‚®ãƒ£ãƒƒãƒ—æ•°'),
    generateProposals: z.boolean().optional()
      .describe('ç ”ç©¶ææ¡ˆã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹ã‹')
  }),
  handler: async (input: AnalyzeGapsInput): Promise<AnalyzeGapsOutput> => {
    const analyzer = container.get<ResearchGapAnalyzerService>('GapAnalyzer');
    const result = await analyzer.analyze(input.domain);

    const gaps = result.gaps.slice(0, input.maxResults ?? 20);
    let proposals: ResearchProposal[] = [];

    if (input.generateProposals) {
      proposals = await analyzer.generateResearchProposals(gaps, 5);
    }

    return {
      totalGaps: result.gaps.length,
      gaps,
      statistics: result.statistics,
      proposals
    };
  }
};

export const suggestResearchTool = {
  name: 'suggest_research',
  description: 'ç‰¹å®šã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«é–¢ã™ã‚‹ç ”ç©¶ææ¡ˆã‚’ç”Ÿæˆã™ã‚‹',
  inputSchema: z.object({
    entity: z.string().describe('ç ”ç©¶ææ¡ˆã®å¯¾è±¡ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£'),
    focus: z.enum(['improvement', 'application', 'combination', 'analysis'])
      .optional()
      .describe('ç ”ç©¶ã®ãƒ•ã‚©ãƒ¼ã‚«ã‚¹é ˜åŸŸ')
  }),
  handler: async (input: SuggestResearchInput): Promise<SuggestResearchOutput> => {
    const analyzer = container.get<ResearchGapAnalyzerService>('GapAnalyzer');
    
    // ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«é–¢é€£ã™ã‚‹ã‚®ãƒ£ãƒƒãƒ—ã‚’æ¤œç´¢
    const gaps = await analyzer.findEntityRelatedGaps(input.entity);
    
    // ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã«åŸºã¥ã„ã¦ææ¡ˆã‚’ç”Ÿæˆ
    const proposals = await analyzer.generateFocusedProposals(
      input.entity,
      input.focus,
      gaps
    );

    return {
      entity: input.entity,
      focus: input.focus ?? 'general',
      proposals
    };
  }
};
```

```typescript
// libs/mcp/src/tools/lifecycle-tools.ts
export const trackLifecycleTool = {
  name: 'track_lifecycle',
  description: 'æŠ€è¡“ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ï¼ˆå‡ºç¾æœŸã€æˆé•·æœŸã€æˆç†ŸæœŸã€è¡°é€€æœŸï¼‰ã‚’è¿½è·¡ã™ã‚‹',
  inputSchema: z.object({
    entity: z.string().describe('è¿½è·¡å¯¾è±¡ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å'),
    includeTimeline: z.boolean().optional()
      .describe('è©³ç´°ãªã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’å«ã‚ã‚‹ã‹'),
    includeForecast: z.boolean().optional()
      .describe('å°†æ¥äºˆæ¸¬ã‚’å«ã‚ã‚‹ã‹')
  }),
  handler: async (input: TrackLifecycleInput): Promise<TrackLifecycleOutput> => {
    const tracker = container.get<TechnologyLifecycleTrackerService>('LifecycleTracker');
    
    const report = await tracker.trackLifecycle(input.entity);

    return {
      entity: input.entity,
      currentPhase: report.phase.currentPhase,
      phaseStartDate: report.phase.phaseStartDate,
      metrics: report.phase.metrics,
      timeline: input.includeTimeline ? report.timeline : undefined,
      forecast: input.includeForecast ? report.forecast : undefined,
      confidence: report.phase.confidence
    };
  }
};

export const getTrendTool = {
  name: 'get_trend',
  description: 'æŠ€è¡“ã®ãƒˆãƒ¬ãƒ³ãƒ‰äºˆæ¸¬ã‚’å–å¾—ã™ã‚‹',
  inputSchema: z.object({
    entity: z.string().describe('äºˆæ¸¬å¯¾è±¡ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£'),
    horizonMonths: z.number().min(3).max(24).optional()
      .describe('äºˆæ¸¬æœŸé–“ï¼ˆæœˆæ•°ï¼‰')
  }),
  handler: async (input: GetTrendInput): Promise<GetTrendOutput> => {
    const tracker = container.get<TechnologyLifecycleTrackerService>('LifecycleTracker');
    const forecast = await tracker.trendPredictor.predictTrend(
      input.entity,
      input.horizonMonths ?? 12
    );

    return forecast;
  }
};

export const compareTechsTool = {
  name: 'compare_techs',
  description: 'è¤‡æ•°ã®æŠ€è¡“ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã‚’æ¯”è¼ƒã™ã‚‹',
  inputSchema: z.object({
    entities: z.array(z.string()).min(2).max(5)
      .describe('æ¯”è¼ƒå¯¾è±¡ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åï¼ˆ2-5å€‹ï¼‰')
  }),
  handler: async (input: CompareTechsInput): Promise<CompareTechsOutput> => {
    const tracker = container.get<TechnologyLifecycleTrackerService>('LifecycleTracker');
    return await tracker.compareLifecycles(input.entities);
  }
};

export const findEmergingTechsTool = {
  name: 'find_emerging_techs',
  description: 'æ–°èˆˆæŠ€è¡“ï¼ˆå‡ºç¾æœŸã®æŠ€è¡“ï¼‰ã‚’æ¤œç´¢ã™ã‚‹',
  inputSchema: z.object({
    limit: z.number().min(1).max(50).optional()
      .describe('è¿”å´ã™ã‚‹æœ€å¤§ä»¶æ•°')
  }),
  handler: async (input: FindEmergingInput): Promise<FindEmergingOutput> => {
    const tracker = container.get<TechnologyLifecycleTrackerService>('LifecycleTracker');
    const emerging = await tracker.findEmergingTechnologies(input.limit ?? 10);
    return { technologies: emerging };
  }
};
```

### 7.3 Tool Registration

```typescript
// libs/mcp/src/tools/index.ts
import { Server } from '@modelcontextprotocol/sdk/server/index.js';

export function registerAllTools(server: Server): void {
  // Existing tools (v1.0)
  server.setRequestHandler(ListToolsRequestSchema, async () => ({
    tools: [
      // ... existing tools ...

      // New tools (v2.0)
      {
        name: normalizeEntityTool.name,
        description: normalizeEntityTool.description,
        inputSchema: zodToJsonSchema(normalizeEntityTool.inputSchema)
      },
      {
        name: normalizeAllEntitiesTool.name,
        description: normalizeAllEntitiesTool.description,
        inputSchema: zodToJsonSchema(normalizeAllEntitiesTool.inputSchema)
      },
      {
        name: findPathsTool.name,
        description: findPathsTool.description,
        inputSchema: zodToJsonSchema(findPathsTool.inputSchema)
      },
      {
        name: findConceptConnectionsTool.name,
        description: findConceptConnectionsTool.description,
        inputSchema: zodToJsonSchema(findConceptConnectionsTool.inputSchema)
      },
      {
        name: analyzeGapsTool.name,
        description: analyzeGapsTool.description,
        inputSchema: zodToJsonSchema(analyzeGapsTool.inputSchema)
      },
      {
        name: suggestResearchTool.name,
        description: suggestResearchTool.description,
        inputSchema: zodToJsonSchema(suggestResearchTool.inputSchema)
      },
      {
        name: trackLifecycleTool.name,
        description: trackLifecycleTool.description,
        inputSchema: zodToJsonSchema(trackLifecycleTool.inputSchema)
      },
      {
        name: getTrendTool.name,
        description: getTrendTool.description,
        inputSchema: zodToJsonSchema(getTrendTool.inputSchema)
      },
      {
        name: compareTechsTool.name,
        description: compareTechsTool.description,
        inputSchema: zodToJsonSchema(compareTechsTool.inputSchema)
      },
      {
        name: findEmergingTechsTool.name,
        description: findEmergingTechsTool.description,
        inputSchema: zodToJsonSchema(findEmergingTechsTool.inputSchema)
      }
    ]
  }));

  // Tool call handler
  server.setRequestHandler(CallToolRequestSchema, async (request) => {
    const { name, arguments: args } = request.params;
    
    const toolMap = new Map([
      [normalizeEntityTool.name, normalizeEntityTool.handler],
      [normalizeAllEntitiesTool.name, normalizeAllEntitiesTool.handler],
      [findPathsTool.name, findPathsTool.handler],
      [findConceptConnectionsTool.name, findConceptConnectionsTool.handler],
      [analyzeGapsTool.name, analyzeGapsTool.handler],
      [suggestResearchTool.name, suggestResearchTool.handler],
      [trackLifecycleTool.name, trackLifecycleTool.handler],
      [getTrendTool.name, getTrendTool.handler],
      [compareTechsTool.name, compareTechsTool.handler],
      [findEmergingTechsTool.name, findEmergingTechsTool.handler]
    ]);

    const handler = toolMap.get(name);
    if (!handler) {
      throw new McpError(ErrorCode.MethodNotFound, `Unknown tool: ${name}`);
    }

    const result = await handler(args);
    return {
      content: [{
        type: 'text',
        text: JSON.stringify(result, null, 2)
      }]
    };
  });
}
```

---

## 8. Phase 6: Enhanced CLI Commands Design

### 8.1 CLI Command Structure

```
yagokoro
â”œâ”€â”€ entity
â”‚   â”œâ”€â”€ search <query>
â”‚   â”œâ”€â”€ get <id>
â”‚   â”œâ”€â”€ normalize <name>          # ğŸ†•
â”‚   â””â”€â”€ normalize-all [--type]    # ğŸ†•
â”‚
â”œâ”€â”€ relation
â”‚   â”œâ”€â”€ list [--from] [--to]
â”‚   â””â”€â”€ create <from> <to> <type>
â”‚
â”œâ”€â”€ path                           # ğŸ†•
â”‚   â”œâ”€â”€ find <entity1> <entity2>   # ğŸ†•
â”‚   â””â”€â”€ explain <path-id>          # ğŸ†•
â”‚
â”œâ”€â”€ analyze                        # ğŸ†•
â”‚   â”œâ”€â”€ gaps [--domain]            # ğŸ†•
â”‚   â”œâ”€â”€ lifecycle <entity>         # ğŸ†•
â”‚   â”œâ”€â”€ trend <entity>             # ğŸ†•
â”‚   â”œâ”€â”€ compare <entity1> <entity2...>  # ğŸ†•
â”‚   â””â”€â”€ emerging                   # ğŸ†•
â”‚
â”œâ”€â”€ graph
â”‚   â”œâ”€â”€ stats
â”‚   â””â”€â”€ export [--format]
â”‚
â”œâ”€â”€ community
â”‚   â”œâ”€â”€ detect
â”‚   â””â”€â”€ list
â”‚
â””â”€â”€ mcp
    â”œâ”€â”€ start
    â””â”€â”€ status
```

### 8.2 Command Implementation

```typescript
// libs/cli/src/commands/entity.ts
import { Command } from 'commander';

export function createEntityCommands(): Command {
  const entity = new Command('entity')
    .description('ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ç®¡ç†ã‚³ãƒãƒ³ãƒ‰');

  // æ—¢å­˜ã‚³ãƒãƒ³ãƒ‰
  entity
    .command('search <query>')
    .description('ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’æ¤œç´¢ã™ã‚‹')
    .option('-t, --type <type>', 'ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚¿ã‚¤ãƒ—ã§ãƒ•ã‚£ãƒ«ã‚¿')
    .option('-l, --limit <number>', 'æœ€å¤§ä»¶æ•°', '20')
    .action(async (query, options) => {
      // ... existing implementation
    });

  // ğŸ†• æ­£è¦åŒ–ã‚³ãƒãƒ³ãƒ‰
  entity
    .command('normalize <name>')
    .description('ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã‚’æ­£è¦åŒ–ã™ã‚‹')
    .option('--llm', 'LLMã§é¡ä¼¼æ€§ã‚’ç¢ºèª')
    .option('--dry-run', 'å®Ÿéš›ã«ä¿å­˜ã›ãšã«çµæœã‚’ç¢ºèª')
    .action(async (name, options) => {
      const spinner = ora('æ­£è¦åŒ–ä¸­...').start();
      
      try {
        const normalizer = container.get<EntityNormalizerService>('EntityNormalizer');
        const result = await normalizer.normalize(name, {
          confirmWithLLM: options.llm
        });

        spinner.succeed('æ­£è¦åŒ–å®Œäº†');
        
        console.log('\nğŸ“ æ­£è¦åŒ–çµæœ:');
        console.log(chalk.gray('â”€'.repeat(50)));
        console.log(`  å…ƒã®åå‰:    ${chalk.yellow(result.original)}`);
        console.log(`  æ­£è¦åŒ–å:    ${chalk.green(result.canonical)}`);
        console.log(`  ã‚½ãƒ¼ã‚¹:      ${result.source}`);
        console.log(`  ä¿¡é ¼åº¦:      ${(result.confidence * 100).toFixed(1)}%`);
        
        if (!options.dryRun && result.original !== result.canonical) {
          await normalizer.persistResult(result);
          console.log(chalk.green('\nâœ“ ã‚¨ã‚¤ãƒªã‚¢ã‚¹ã‚’ä¿å­˜ã—ã¾ã—ãŸ'));
        }
      } catch (error) {
        spinner.fail('æ­£è¦åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ');
        console.error(chalk.red(error.message));
      }
    });

  entity
    .command('normalize-all')
    .description('ã™ã¹ã¦ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’ä¸€æ‹¬æ­£è¦åŒ–ã™ã‚‹')
    .option('-t, --type <type>', 'ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚¿ã‚¤ãƒ—ã§ãƒ•ã‚£ãƒ«ã‚¿')
    .option('--llm', 'LLMã§é¡ä¼¼æ€§ã‚’ç¢ºèª')
    .option('--dry-run', 'å®Ÿéš›ã«ä¿å­˜ã›ãšã«çµæœã‚’ç¢ºèª')
    .action(async (options) => {
      const spinner = ora('ä¸€æ‹¬æ­£è¦åŒ–ä¸­...').start();
      
      try {
        const normalizer = container.get<EntityNormalizerService>('EntityNormalizer');
        const report = await normalizer.normalizeAll({
          entityType: options.type,
          confirmWithLLM: options.llm
        });

        spinner.succeed('ä¸€æ‹¬æ­£è¦åŒ–å®Œäº†');
        
        console.log('\nğŸ“Š æ­£è¦åŒ–ãƒ¬ãƒãƒ¼ãƒˆ:');
        console.log(chalk.gray('â”€'.repeat(50)));
        console.log(`  å‡¦ç†æ•°:      ${report.totalEntities}`);
        console.log(`  æ­£è¦åŒ–æ•°:    ${chalk.green(report.normalizedCount)}`);
        console.log(`  ã‚¨ãƒ©ãƒ¼æ•°:    ${chalk.red(report.errors.length)}`);
        
        if (report.normalizedCount > 0) {
          console.log('\nğŸ“ æ­£è¦åŒ–ã•ã‚ŒãŸã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ï¼ˆä¸Šä½10ä»¶ï¼‰:');
          report.results
            .filter(r => r.original !== r.canonical)
            .slice(0, 10)
            .forEach(r => {
              console.log(`  ${chalk.yellow(r.original)} â†’ ${chalk.green(r.canonical)}`);
            });
        }
      } catch (error) {
        spinner.fail('ä¸€æ‹¬æ­£è¦åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ');
        console.error(chalk.red(error.message));
      }
    });

  return entity;
}
```

```typescript
// libs/cli/src/commands/path.ts
import { Command } from 'commander';

export function createPathCommands(): Command {
  const path = new Command('path')
    .description('ãƒ‘ã‚¹æ¢ç´¢ã‚³ãƒãƒ³ãƒ‰');

  path
    .command('find <entity1> <entity2>')
    .description('2ã¤ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£é–“ã®ãƒ‘ã‚¹ã‚’æ¤œç´¢ã™ã‚‹')
    .option('-m, --max-hops <number>', 'æœ€å¤§ãƒ›ãƒƒãƒ—æ•°', '4')
    .option('-r, --relations <types>', 'é–¢ä¿‚ã‚¿ã‚¤ãƒ—ã§ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰')
    .option('-e, --explain', 'ãƒ‘ã‚¹ã®èª¬æ˜ã‚’ç”Ÿæˆ')
    .option('-j, --json', 'JSONå½¢å¼ã§å‡ºåŠ›')
    .action(async (entity1, entity2, options) => {
      const spinner = ora(`${entity1} ã‹ã‚‰ ${entity2} ã¸ã®ãƒ‘ã‚¹ã‚’æ¤œç´¢ä¸­...`).start();
      
      try {
        const reasoner = container.get<MultiHopReasonerService>('MultiHopReasoner');
        const result = await reasoner.findRelationPaths(entity1, entity2, {
          maxHops: parseInt(options.maxHops),
          relationTypes: options.relations?.split(',')
        });

        spinner.succeed(`${result.paths.length} ä»¶ã®ãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ`);

        if (options.json) {
          console.log(JSON.stringify(result, null, 2));
          return;
        }

        console.log('\nğŸ›¤ï¸  ãƒ‘ã‚¹æ¤œç´¢çµæœ:');
        console.log(chalk.gray('â”€'.repeat(60)));
        console.log(`  æ¤œç´¢æ™‚é–“:  ${result.executionTime}ms`);
        console.log(`  ãƒ‘ã‚¹æ•°:    ${result.paths.length}`);
        console.log(`  å¹³å‡ãƒ›ãƒƒãƒ—: ${result.statistics.averageHops.toFixed(1)}`);
        
        if (result.paths.length > 0) {
          console.log('\nğŸ“ ãƒ‘ã‚¹ä¸€è¦§:');
          result.paths.slice(0, 5).forEach((p, i) => {
            console.log(`\n  ãƒ‘ã‚¹ ${i + 1} (${p.hops} ãƒ›ãƒƒãƒ—):`);
            const pathStr = p.nodes.map((n, j) => {
              const rel = p.relations[j];
              return j === p.nodes.length - 1 
                ? chalk.cyan(n.name)
                : `${chalk.cyan(n.name)} -[${chalk.yellow(rel?.type)}]-> `;
            }).join('');
            console.log(`    ${pathStr}`);
          });
        }

        if (options.explain && result.paths.length > 0) {
          const explainer = container.get<PathExplainer>('PathExplainer');
          console.log('\nğŸ“– ãƒ‘ã‚¹ã®èª¬æ˜:');
          for (const p of result.paths.slice(0, 3)) {
            const explanation = await explainer.explain(p);
            console.log(chalk.gray('â”€'.repeat(40)));
            console.log(explanation.naturalLanguage);
          }
        }
      } catch (error) {
        spinner.fail('ãƒ‘ã‚¹æ¤œç´¢ã«å¤±æ•—ã—ã¾ã—ãŸ');
        console.error(chalk.red(error.message));
      }
    });

  return path;
}
```

```typescript
// libs/cli/src/commands/analyze.ts
import { Command } from 'commander';

export function createAnalyzeCommands(): Command {
  const analyze = new Command('analyze')
    .description('åˆ†æã‚³ãƒãƒ³ãƒ‰');

  analyze
    .command('gaps')
    .description('ç ”ç©¶ã‚®ãƒ£ãƒƒãƒ—ã‚’åˆ†æã™ã‚‹')
    .option('-d, --domain <domain>', 'åˆ†æå¯¾è±¡ãƒ‰ãƒ¡ã‚¤ãƒ³')
    .option('-l, --limit <number>', 'æœ€å¤§çµæœæ•°', '20')
    .option('-p, --proposals', 'ç ”ç©¶ææ¡ˆã‚’ç”Ÿæˆ')
    .option('-j, --json', 'JSONå½¢å¼ã§å‡ºåŠ›')
    .action(async (options) => {
      const spinner = ora('ç ”ç©¶ã‚®ãƒ£ãƒƒãƒ—ã‚’åˆ†æä¸­...').start();
      
      try {
        const analyzer = container.get<ResearchGapAnalyzerService>('GapAnalyzer');
        const result = await analyzer.analyze(options.domain);

        spinner.succeed('åˆ†æå®Œäº†');

        if (options.json) {
          console.log(JSON.stringify(result, null, 2));
          return;
        }

        console.log('\nğŸ” ç ”ç©¶ã‚®ãƒ£ãƒƒãƒ—åˆ†æãƒ¬ãƒãƒ¼ãƒˆ:');
        console.log(chalk.gray('â•'.repeat(60)));
        console.log(`  ç·ã‚®ãƒ£ãƒƒãƒ—æ•°: ${result.gaps.length}`);
        console.log('\n  é‡è¦åº¦åˆ¥:');
        console.log(`    é«˜:   ${chalk.red(result.statistics.bySeverity.high || 0)}`);
        console.log(`    ä¸­:   ${chalk.yellow(result.statistics.bySeverity.medium || 0)}`);
        console.log(`    ä½:   ${chalk.green(result.statistics.bySeverity.low || 0)}`);

        console.log('\nğŸ“‹ ä¸»è¦ãªã‚®ãƒ£ãƒƒãƒ—:');
        result.gaps.slice(0, parseInt(options.limit)).forEach((gap, i) => {
          const severityColor = {
            high: chalk.red,
            medium: chalk.yellow,
            low: chalk.green
          }[gap.severity];
          
          console.log(chalk.gray('â”€'.repeat(50)));
          console.log(`  ${i + 1}. ${gap.description}`);
          console.log(`     ã‚¿ã‚¤ãƒ—: ${gap.type}`);
          console.log(`     é‡è¦åº¦: ${severityColor(gap.severity)}`);
          console.log(`     é–¢é€£:   ${gap.relatedEntities.join(', ')}`);
        });

        if (options.proposals) {
          const proposals = await analyzer.generateResearchProposals(
            result.gaps.slice(0, 5), 
            5
          );
          
          console.log('\nğŸ’¡ ç ”ç©¶ææ¡ˆ:');
          proposals.forEach((p, i) => {
            console.log(chalk.gray('â”€'.repeat(50)));
            console.log(`  ${i + 1}. ${chalk.bold(p.title)}`);
            console.log(`     ${p.objective}`);
          });
        }
      } catch (error) {
        spinner.fail('åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ');
        console.error(chalk.red(error.message));
      }
    });

  analyze
    .command('lifecycle <entity>')
    .description('æŠ€è¡“ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã‚’åˆ†æã™ã‚‹')
    .option('-t, --timeline', 'ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’è¡¨ç¤º')
    .option('-f, --forecast', 'å°†æ¥äºˆæ¸¬ã‚’è¡¨ç¤º')
    .option('-j, --json', 'JSONå½¢å¼ã§å‡ºåŠ›')
    .action(async (entity, options) => {
      const spinner = ora(`${entity} ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã‚’åˆ†æä¸­...`).start();
      
      try {
        const tracker = container.get<TechnologyLifecycleTrackerService>('LifecycleTracker');
        const report = await tracker.trackLifecycle(entity);

        spinner.succeed('åˆ†æå®Œäº†');

        if (options.json) {
          console.log(JSON.stringify(report, null, 2));
          return;
        }

        const phaseEmoji = {
          emerging: 'ğŸŒ±',
          growing: 'ğŸ“ˆ',
          mature: 'ğŸ›ï¸',
          declining: 'ğŸ“‰',
          legacy: 'ğŸ“š'
        }[report.phase.currentPhase];

        console.log(`\n${phaseEmoji} ${chalk.bold(entity)} ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«åˆ†æ:`);
        console.log(chalk.gray('â•'.repeat(60)));
        console.log(`  ç¾åœ¨ã®ãƒ•ã‚§ãƒ¼ã‚º:   ${chalk.cyan(report.phase.currentPhase)}`);
        console.log(`  ãƒ•ã‚§ãƒ¼ã‚ºé–‹å§‹æ—¥:   ${report.phase.phaseStartDate.toISOString().split('T')[0]}`);
        console.log(`  ä¿¡é ¼åº¦:           ${(report.phase.confidence * 100).toFixed(1)}%`);
        
        console.log('\nğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹:');
        console.log(`  ç·è«–æ–‡æ•°:         ${report.phase.metrics.totalPublications}`);
        console.log(`  æ˜¨å¹´ã®è«–æ–‡æ•°:     ${report.phase.metrics.publicationsLastYear}`);
        console.log(`  æˆé•·ç‡:           ${(report.phase.metrics.publicationGrowthRate * 100).toFixed(1)}%`);
        console.log(`  æ´¾ç”ŸæŠ€è¡“æ•°:       ${report.phase.metrics.derivativeCount}`);

        if (options.timeline && report.timeline) {
          console.log('\nğŸ“… ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³:');
          report.timeline.slice(-10).forEach(event => {
            const dateStr = event.date.toISOString().split('T')[0];
            console.log(`  ${dateStr}  ${event.eventType.padEnd(15)} ${event.description.slice(0, 40)}`);
          });
        }

        if (options.forecast && report.forecast) {
          console.log('\nğŸ”® å°†æ¥äºˆæ¸¬:');
          report.forecast.predictions.forEach(pred => {
            const dateStr = pred.date.toISOString().split('T')[0];
            console.log(`  ${dateStr}  äºˆæ¸¬ãƒ•ã‚§ãƒ¼ã‚º: ${pred.predictedPhase}`);
          });
        }
      } catch (error) {
        spinner.fail('åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ');
        console.error(chalk.red(error.message));
      }
    });

  analyze
    .command('compare <entities...>')
    .description('è¤‡æ•°ã®æŠ€è¡“ã‚’æ¯”è¼ƒã™ã‚‹')
    .option('-j, --json', 'JSONå½¢å¼ã§å‡ºåŠ›')
    .action(async (entities, options) => {
      if (entities.length < 2) {
        console.error(chalk.red('æ¯”è¼ƒã«ã¯2ã¤ä»¥ä¸Šã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãŒå¿…è¦ã§ã™'));
        return;
      }

      const spinner = ora('æŠ€è¡“ã‚’æ¯”è¼ƒä¸­...').start();
      
      try {
        const tracker = container.get<TechnologyLifecycleTrackerService>('LifecycleTracker');
        const comparison = await tracker.compareLifecycles(entities);

        spinner.succeed('æ¯”è¼ƒå®Œäº†');

        if (options.json) {
          console.log(JSON.stringify(comparison, null, 2));
          return;
        }

        console.log('\nğŸ“Š æŠ€è¡“æ¯”è¼ƒ:');
        console.log(chalk.gray('â•'.repeat(70)));
        
        // ãƒ˜ãƒƒãƒ€ãƒ¼
        const header = ['æŒ‡æ¨™', ...entities.map(e => e.slice(0, 15).padEnd(15))].join(' | ');
        console.log(header);
        console.log(chalk.gray('â”€'.repeat(70)));

        // ãƒ•ã‚§ãƒ¼ã‚ºæ¯”è¼ƒ
        const phases = comparison.lifecycles.map(l => l.phase.currentPhase);
        console.log(['ãƒ•ã‚§ãƒ¼ã‚º', ...phases.map(p => p.padEnd(15))].join(' | '));

        // è«–æ–‡æ•°æ¯”è¼ƒ
        const pubs = comparison.lifecycles.map(l => 
          l.phase.metrics.totalPublications.toString().padEnd(15)
        );
        console.log(['è«–æ–‡æ•°', ...pubs].join(' | '));

        // æˆé•·ç‡æ¯”è¼ƒ
        const growth = comparison.lifecycles.map(l => 
          `${(l.phase.metrics.publicationGrowthRate * 100).toFixed(1)}%`.padEnd(15)
        );
        console.log(['æˆé•·ç‡', ...growth].join(' | '));

      } catch (error) {
        spinner.fail('æ¯”è¼ƒã«å¤±æ•—ã—ã¾ã—ãŸ');
        console.error(chalk.red(error.message));
      }
    });

  analyze
    .command('emerging')
    .description('æ–°èˆˆæŠ€è¡“ã‚’æ¤œç´¢ã™ã‚‹')
    .option('-l, --limit <number>', 'æœ€å¤§ä»¶æ•°', '10')
    .option('-j, --json', 'JSONå½¢å¼ã§å‡ºåŠ›')
    .action(async (options) => {
      const spinner = ora('æ–°èˆˆæŠ€è¡“ã‚’æ¤œç´¢ä¸­...').start();
      
      try {
        const tracker = container.get<TechnologyLifecycleTrackerService>('LifecycleTracker');
        const emerging = await tracker.findEmergingTechnologies(parseInt(options.limit));

        spinner.succeed(`${emerging.length} ä»¶ã®æ–°èˆˆæŠ€è¡“ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ`);

        if (options.json) {
          console.log(JSON.stringify(emerging, null, 2));
          return;
        }

        console.log('\nğŸŒ± æ–°èˆˆæŠ€è¡“:');
        console.log(chalk.gray('â•'.repeat(60)));
        emerging.forEach((tech, i) => {
          console.log(`  ${i + 1}. ${chalk.cyan(tech.name)}`);
          console.log(`     è«–æ–‡æ•°: ${tech.publicationCount}  æ´»å‹•æœŸé–“: ${tech.activeMonths}ãƒ¶æœˆ`);
        });
      } catch (error) {
        spinner.fail('æ¤œç´¢ã«å¤±æ•—ã—ã¾ã—ãŸ');
        console.error(chalk.red(error.message));
      }
    });

  return analyze;
}
```

### 8.3 CLI Entry Point

```typescript
// libs/cli/src/index.ts
import { Command } from 'commander';
import { createEntityCommands } from './commands/entity.js';
import { createRelationCommands } from './commands/relation.js';
import { createPathCommands } from './commands/path.js';
import { createAnalyzeCommands } from './commands/analyze.js';
import { createGraphCommands } from './commands/graph.js';
import { createCommunityCommands } from './commands/community.js';
import { createMcpCommands } from './commands/mcp.js';

export function createCLI(): Command {
  const program = new Command();
  
  program
    .name('yagokoro')
    .description('YAGOKORO - GenAI GraphRAG Knowledge System')
    .version('2.0.0');

  // Register all command groups
  program.addCommand(createEntityCommands());
  program.addCommand(createRelationCommands());
  program.addCommand(createPathCommands());      // ğŸ†•
  program.addCommand(createAnalyzeCommands());   // ğŸ†•
  program.addCommand(createGraphCommands());
  program.addCommand(createCommunityCommands());
  program.addCommand(createMcpCommands());

  return program;
}
```

---

## 9. Integration Architecture

### 9.1 Dependency Injection Container

```typescript
// libs/shared/src/container.ts
import { Container } from 'inversify';

export const container = new Container();

// Service bindings
container.bind<Neo4jConnection>('Neo4jConnection').to(Neo4jConnection).inSingletonScope();
container.bind<QdrantConnection>('QdrantConnection').to(QdrantConnection).inSingletonScope();
container.bind<LLMClient>('LLMClient').to(OllamaClient).inSingletonScope();

// Phase 1: Normalization
container.bind<RuleNormalizer>('RuleNormalizer').to(RuleNormalizer);
container.bind<SimilarityMatcher>('SimilarityMatcher').to(SimilarityMatcher);
container.bind<AliasTableManager>('AliasTableManager').to(AliasTableManager);
container.bind<EntityNormalizerService>('EntityNormalizer').to(EntityNormalizerService);

// Phase 2: Reasoning
container.bind<BFSPathFinder>('PathFinder').to(BFSPathFinder);
container.bind<PathCache>('PathCache').to(PathCache).inSingletonScope();
container.bind<PathExplainer>('PathExplainer').to(PathExplainer);
container.bind<MultiHopReasonerService>('MultiHopReasoner').to(MultiHopReasonerService);

// Phase 3: Gap Analysis
container.bind<CitationAnalyzer>('CitationAnalyzer').to(CitationAnalyzer);
container.bind<ClusterAnalyzer>('ClusterAnalyzer').to(ClusterAnalyzer);
container.bind<GapDetector>('GapDetector').to(GapDetector);
container.bind<ResearchGapAnalyzerService>('GapAnalyzer').to(ResearchGapAnalyzerService);

// Phase 4: Lifecycle Tracking
container.bind<TimelineAggregator>('TimelineAggregator').to(TimelineAggregator);
container.bind<PhaseDetector>('PhaseDetector').to(PhaseDetector);
container.bind<TrendPredictor>('TrendPredictor').to(TrendPredictor);
container.bind<TechnologyLifecycleTrackerService>('LifecycleTracker').to(TechnologyLifecycleTrackerService);

// Report Generation
container.bind<ReportGenerator>('ReportGenerator').to(ReportGenerator);
```

### 9.2 Configuration Schema

```typescript
// libs/shared/src/config.ts
import { z } from 'zod';

export const ConfigSchema = z.object({
  neo4j: z.object({
    uri: z.string().default('bolt://localhost:7687'),
    username: z.string().default('neo4j'),
    password: z.string(),
    database: z.string().default('neo4j')
  }),
  
  qdrant: z.object({
    url: z.string().default('http://localhost:6333'),
    collection: z.string().default('yagokoro')
  }),
  
  llm: z.object({
    provider: z.enum(['ollama', 'openai', 'anthropic']).default('ollama'),
    model: z.string().default('qwen2.5'),
    baseUrl: z.string().optional(),
    apiKey: z.string().optional()
  }),
  
  normalization: z.object({
    rulesPath: z.string().optional(),
    dictionaryPath: z.string().optional(),
    similarityThreshold: z.number().min(0).max(1).default(0.8),
    confirmWithLLM: z.boolean().default(false)
  }),
  
  reasoning: z.object({
    maxHops: z.number().min(1).max(10).default(4),
    cacheEnabled: z.boolean().default(true),
    cacheTTLMs: z.number().default(3600000),
    cacheMaxSize: z.number().default(1000)
  }),
  
  analysis: z.object({
    gapSeverityThresholds: z.object({
      high: z.number().default(0.9),
      medium: z.number().default(0.7)
    }),
    lifecyclePhaseThresholds: z.object({
      emergingYears: z.number().default(2),
      growthRate: z.number().default(0.2),
      legacyInactiveYears: z.number().default(2)
    })
  }),
  
  mcp: z.object({
    transport: z.enum(['stdio', 'sse']).default('stdio'),
    port: z.number().optional()
  })
});

export type Config = z.infer<typeof ConfigSchema>;
```

---

## 10. Testing Strategy

### 10.1 Unit Tests

```typescript
// libs/normalizer/src/rules/RuleNormalizer.test.ts
describe('RuleNormalizer', () => {
  let normalizer: RuleNormalizer;

  beforeEach(() => {
    normalizer = new RuleNormalizer();
  });

  describe('normalize', () => {
    it('should normalize GPT-4 to GPT4', () => {
      const result = normalizer.normalize('GPT-4');
      expect(result.normalized).toBe('GPT4');
      expect(result.appliedRules.length).toBeGreaterThan(0);
    });

    it('should normalize Chain of Thought to CoT', () => {
      const result = normalizer.normalize('Chain of Thought');
      expect(result.normalized).toBe('CoT');
    });

    it('should handle already normalized entities', () => {
      const result = normalizer.normalize('Transformer');
      expect(result.normalized).toBe('Transformer');
      expect(result.confidence).toBe(0.5);
    });
  });
});
```

### 10.2 Integration Tests

```typescript
// libs/reasoner/src/service/MultiHopReasonerService.integration.test.ts
describe('MultiHopReasonerService Integration', () => {
  let reasoner: MultiHopReasonerService;
  let neo4jConnection: Neo4jConnection;

  beforeAll(async () => {
    neo4jConnection = await createTestNeo4jConnection();
    await seedTestData(neo4jConnection);
    reasoner = new MultiHopReasonerService({
      pathFinder: new BFSPathFinder(neo4jConnection),
      pathCache: new PathCache(),
      pathExplainer: new PathExplainer(mockLLMClient)
    });
  });

  afterAll(async () => {
    await cleanupTestData(neo4jConnection);
    await neo4jConnection.close();
  });

  describe('findRelationPaths', () => {
    it('should find paths between two entities', async () => {
      const result = await reasoner.findRelationPaths('GPT4', 'Transformer');
      
      expect(result.paths.length).toBeGreaterThan(0);
      expect(result.statistics.minHops).toBeGreaterThanOrEqual(1);
    });

    it('should return empty for unconnected entities', async () => {
      const result = await reasoner.findRelationPaths('GPT4', 'NonExistent');
      
      expect(result.paths.length).toBe(0);
    });

    it('should respect maxHops constraint', async () => {
      const result = await reasoner.findRelationPaths('GPT4', 'Transformer', {
        maxHops: 2
      });
      
      expect(result.paths.every(p => p.hops <= 2)).toBe(true);
    });
  });
});
```

### 10.3 E2E Tests

```typescript
// apps/yagokoro/test/e2e.test.ts
describe('YAGOKORO E2E', () => {
  describe('CLI Commands', () => {
    it('should normalize entity via CLI', async () => {
      const result = await runCLI(['entity', 'normalize', 'GPT-4', '--dry-run']);
      
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('GPT4');
    });

    it('should find paths via CLI', async () => {
      const result = await runCLI(['path', 'find', 'GPT4', 'Transformer']);
      
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('ãƒ‘ã‚¹');
    });

    it('should analyze gaps via CLI', async () => {
      const result = await runCLI(['analyze', 'gaps', '--limit', '5']);
      
      expect(result.exitCode).toBe(0);
      expect(result.stdout).toContain('ç ”ç©¶ã‚®ãƒ£ãƒƒãƒ—');
    });
  });

  describe('MCP Tools', () => {
    let mcpClient: MCPTestClient;

    beforeAll(async () => {
      mcpClient = await createMCPTestClient();
    });

    it('should normalize entity via MCP', async () => {
      const result = await mcpClient.callTool('normalize_entity', {
        entity: 'GPT-4',
        dryRun: true
      });
      
      expect(result.canonical).toBe('GPT4');
    });

    it('should find paths via MCP', async () => {
      const result = await mcpClient.callTool('find_paths', {
        entity1: 'GPT4',
        entity2: 'Transformer',
        maxHops: 3
      });
      
      expect(result.pathsFound).toBeGreaterThan(0);
    });
  });
});
```

---

## 11. Deployment & Operations

### 11.1 Docker Compose (Development)

```yaml
# docker/docker-compose.dev.yml
version: '3.8'

services:
  yagokoro:
    build:
      context: ..
      dockerfile: Dockerfile
    volumes:
      - ../:/app
      - /app/node_modules
    environment:
      - NODE_ENV=development
      - NEO4J_URI=bolt://neo4j:7687
      - QDRANT_URL=http://qdrant:6333
      - OLLAMA_URL=http://ollama:11434
    depends_on:
      - neo4j
      - qdrant
      - ollama

  neo4j:
    image: neo4j:5-community
    ports:
      - "7474:7474"
      - "7687:7687"
    environment:
      - NEO4J_AUTH=neo4j/password
      - NEO4J_PLUGINS=["apoc", "graph-data-science"]
    volumes:
      - neo4j_data:/data

  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
    volumes:
      - qdrant_data:/qdrant/storage

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama

volumes:
  neo4j_data:
  qdrant_data:
  ollama_data:
```

### 11.2 Monitoring & Observability

```typescript
// libs/shared/src/telemetry/metrics.ts
import { Counter, Histogram, Registry } from 'prom-client';

export const register = new Registry();

// Normalization metrics
export const normalizationCounter = new Counter({
  name: 'yagokoro_normalization_total',
  help: 'Total number of normalizations performed',
  labelNames: ['source', 'success'],
  registers: [register]
});

// Path finding metrics
export const pathFindingDuration = new Histogram({
  name: 'yagokoro_path_finding_duration_seconds',
  help: 'Duration of path finding operations',
  labelNames: ['hops'],
  buckets: [0.1, 0.5, 1, 2, 5, 10],
  registers: [register]
});

// Cache metrics
export const cacheHitCounter = new Counter({
  name: 'yagokoro_cache_hits_total',
  help: 'Total number of cache hits',
  labelNames: ['cache_type'],
  registers: [register]
});
```

---

## 12. Appendix

### A. Glossary

| ç”¨èª | èª¬æ˜ |
|------|------|
| ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ­£è¦åŒ– | è¡¨è¨˜æºã‚Œã®ã‚ã‚‹ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’æ¨™æº–å½¢ã«çµ±ä¸€ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ |
| ãƒãƒ«ãƒãƒ›ãƒƒãƒ—æ¨è«– | è¤‡æ•°ã®é–¢ä¿‚ã‚’çµŒç”±ã—ã¦é–“æ¥çš„ãªé–¢é€£æ€§ã‚’ç™ºè¦‹ã™ã‚‹æ¨è«– |
| ç ”ç©¶ã‚®ãƒ£ãƒƒãƒ— | æœªæ¢ç´¢ã¾ãŸã¯ä¸ååˆ†ã«æ¢ç´¢ã•ã‚ŒãŸç ”ç©¶é ˜åŸŸ |
| ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ãƒ•ã‚§ãƒ¼ã‚º | æŠ€è¡“ã®æˆç†Ÿåº¦æ®µéšï¼ˆå‡ºç¾æœŸã€æˆé•·æœŸã€æˆç†ŸæœŸã€è¡°é€€æœŸã€ãƒ¬ã‚¬ã‚·ãƒ¼ï¼‰|

### B. ADR Index

| ADR | ã‚¿ã‚¤ãƒˆãƒ« | ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ |
|-----|---------|----------|
| ADR-001 | ã‚¨ã‚¤ãƒªã‚¢ã‚¹ä¿å­˜æˆ¦ç•¥ | Accepted |
| ADR-002 | ãƒ‘ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æˆ¦ç•¥ | Accepted |
| ADR-003 | ã‚®ãƒ£ãƒƒãƒ—é‡è¦åº¦è¨ˆç®— | Accepted |
| ADR-004 | ãƒˆãƒ¬ãƒ³ãƒ‰äºˆæ¸¬æ‰‹æ³• | Accepted |

### C. References

- REQ-002: YAGOKORO v2.0.0 Requirements Specification
- DES-001: YAGOKORO v1.0.0 Design Specification
- steering/tech.ja.md: Technology Stack
- steering/structure.ja.md: Architecture Patterns

---

**Document History**

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 0.1.0 | 2025-12-30 | YAGOKORO Dev Team | Initial draft |


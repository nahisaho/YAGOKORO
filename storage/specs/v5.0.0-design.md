# YAGOKORO v5.0.0 設計書

**Version**: 5.0.0
**Status**: Draft
**Created**: 2025-12-31
**Updated**: 2025-12-31
**Author**: GitHub Copilot (MUSUBI SDD)

---

## 目次

1. [C4モデル概要](#1-c4モデル概要)
2. [Context Diagram (Level 1)](#2-context-diagram-level-1)
3. [Container Diagram (Level 2)](#3-container-diagram-level-2)
4. [Component Diagram (Level 3)](#4-component-diagram-level-3)
5. [Architecture Decision Records (ADR)](#5-architecture-decision-records-adr)
   - [ADR-004: 翻訳API選定](#adr-004-翻訳api選定)
   - [ADR-005: BERTopic統合方式](#adr-005-bertopic統合方式)
   - [ADR-006: 引用グラフスケーリング戦略](#adr-006-引用グラフスケーリング戦略)
   - [ADR-007: 多言語NERモデル選定](#adr-007-多言語nerモデル選定)
   - [ADR-008: 言語検出ライブラリ選定](#adr-008-言語検出ライブラリ選定) ← NEW
   - [ADR-009: キャッシュストレージ選定](#adr-009-キャッシュストレージ選定) ← NEW
   - [ADR-010: Unwanted Behavior エラーハンドリング設計](#adr-010-unwanted-behavior-エラーハンドリング設計) ← NEW
   - [ADR-011: 非機能要件のコンポーネント仕様](#adr-011-非機能要件のコンポーネント仕様) ← NEW
6. [データフロー図](#6-データフロー図)
7. [シーケンス図](#7-シーケンス図)

---

## 1. C4モデル概要

### 1.1 v5.0.0 新規コンポーネント

| パッケージ | 責務 | 主要コンポーネント |
|-----------|------|-------------------|
| @yagokoro/multilang | 多言語論文処理 | LanguageDetector, TranslationService, CrossLingualLinker |
| @yagokoro/citation | 引用ネットワーク分析 | CitationExtractor, CitationPathFinder, CitationBurstDetector |
| @yagokoro/topic | トピックモデリング | TopicExtractor, TopicTrendAnalyzer, EmergingTopicDetector |

### 1.2 既存パッケージとの関係

```
v4.0.0 パッケージ (既存)
├── @yagokoro/core          ← 基盤
├── @yagokoro/ingestion     ← multilang が拡張
├── @yagokoro/extractor     ← citation が拡張
├── @yagokoro/graph         ← citation/topic が利用
├── @yagokoro/temporal      ← topic が連携
├── @yagokoro/researcher    ← citation が連携
├── @yagokoro/cli           ← 新規コマンド追加
└── @yagokoro/mcp           ← 新規ツール追加

v5.0.0 パッケージ (新規)
├── @yagokoro/multilang     NEW
├── @yagokoro/citation      NEW
└── @yagokoro/topic         NEW
```

---

## 2. Context Diagram (Level 1)

### 2.1 システムコンテキスト図

```mermaid
C4Context
    title YAGOKORO v5.0.0 System Context

    Person(researcher, "AI研究者", "論文分析・トレンド把握")
    Person(pm, "PM/ビジネスリーダー", "技術動向レポート作成")
    
    System(yagokoro, "YAGOKORO", "AI論文知識グラフRAGシステム")
    
    System_Ext(arxiv, "arXiv", "英語論文ソース")
    System_Ext(cnki, "CNKI", "中国語論文ソース")
    System_Ext(cinii, "CiNii", "日本語論文ソース")
    System_Ext(kci, "KCI", "韓国語論文ソース")
    
    System_Ext(deepl, "DeepL API", "翻訳サービス (Primary)")
    System_Ext(google, "Google Translate", "翻訳サービス (Fallback)")
    System_Ext(openai, "OpenAI API", "LLM推論・埋め込み")
    
    System_Ext(claude, "Claude Desktop", "MCPクライアント")
    
    Rel(researcher, yagokoro, "CLI/MCP経由で分析")
    Rel(pm, yagokoro, "レポート生成")
    
    Rel(yagokoro, arxiv, "論文取得")
    Rel(yagokoro, cnki, "中国語論文取得")
    Rel(yagokoro, cinii, "日本語論文取得")
    Rel(yagokoro, kci, "韓国語論文取得")
    
    Rel(yagokoro, deepl, "翻訳リクエスト")
    Rel(yagokoro, google, "フォールバック翻訳")
    Rel(yagokoro, openai, "埋め込み生成・推論")
    
    Rel(claude, yagokoro, "MCP呼び出し")
```

### 2.2 外部システム一覧

| 外部システム | 用途 | プロトコル | 認証 |
|-------------|------|-----------|------|
| arXiv | 英語論文取得 | REST API | なし |
| CNKI | 中国語論文取得 | Web Scraping | - |
| CiNii | 日本語論文取得 | REST API | API Key |
| KCI | 韓国語論文取得 | REST API | API Key |
| DeepL API | 翻訳 (Primary) | REST API | API Key |
| Google Translate | 翻訳 (Fallback) | REST API | API Key |
| OpenAI API | 埋め込み・推論 | REST API | API Key |

---

## 3. Container Diagram (Level 2)

### 3.1 コンテナ構成図

```mermaid
C4Container
    title YAGOKORO v5.0.0 Container Diagram

    Person(user, "ユーザー", "研究者/PM")
    
    Container_Boundary(yagokoro, "YAGOKORO System") {
        Container(cli, "CLI", "Node.js/TypeScript", "コマンドラインインターフェース")
        Container(mcp, "MCP Server", "Node.js/TypeScript", "Model Context Protocol サーバー")
        
        Container(multilang, "@yagokoro/multilang", "Node.js/TypeScript", "多言語処理ライブラリ")
        Container(citation, "@yagokoro/citation", "Node.js/TypeScript", "引用ネットワークライブラリ")
        Container(topic, "@yagokoro/topic", "Node.js/TypeScript + Python", "トピックモデリングライブラリ")
        
        Container(core, "@yagokoro/core", "Node.js/TypeScript", "コアサービス")
        Container(graph, "@yagokoro/graph", "Node.js/TypeScript", "グラフ操作")
        
        ContainerDb(neo4j, "Neo4j", "Graph Database", "知識グラフ・引用グラフ")
        ContainerDb(cache, "Redis/SQLite", "Cache", "翻訳キャッシュ・トピックキャッシュ")
    }
    
    Container_Ext(bertopic, "BERTopic", "Python", "トピックモデリングエンジン")
    Container_Ext(deepl, "DeepL API", "REST", "翻訳サービス")
    
    Rel(user, cli, "コマンド実行")
    Rel(user, mcp, "MCP経由")
    
    Rel(cli, multilang, "多言語処理")
    Rel(cli, citation, "引用分析")
    Rel(cli, topic, "トピック分析")
    
    Rel(mcp, multilang, "多言語処理")
    Rel(mcp, citation, "引用分析")
    Rel(mcp, topic, "トピック分析")
    
    Rel(multilang, deepl, "翻訳リクエスト")
    Rel(multilang, cache, "翻訳キャッシュ")
    Rel(multilang, neo4j, "多言語エンティティ保存")
    
    Rel(citation, neo4j, "引用グラフ操作")
    Rel(citation, graph, "グラフアルゴリズム")
    
    Rel(topic, bertopic, "subprocess呼び出し")
    Rel(topic, cache, "トピックキャッシュ")
    Rel(topic, neo4j, "トピック保存")
```

### 3.2 コンテナ責務一覧

| コンテナ | 責務 | 技術スタック | ポート/接続 |
|---------|------|-------------|------------|
| CLI | ユーザーインターフェース | Node.js, Commander.js | - |
| MCP Server | AI連携インターフェース | Node.js, @modelcontextprotocol/sdk | stdio/SSE |
| @yagokoro/multilang | 多言語論文処理 | Node.js, langdetect | - |
| @yagokoro/citation | 引用ネットワーク分析 | Node.js, graphology | - |
| @yagokoro/topic | トピックモデリング | Node.js + Python subprocess | - |
| Neo4j | グラフデータベース | Neo4j 5.x | bolt://7687 |
| Redis/SQLite | キャッシュ | Redis 7.x / SQLite 3 | 6379 / file |
| BERTopic | トピック抽出エンジン | Python 3.11, BERTopic | subprocess |

---

## 4. Component Diagram (Level 3)

### 4.1 @yagokoro/multilang コンポーネント図

```mermaid
C4Component
    title @yagokoro/multilang Component Diagram

    Container_Boundary(multilang, "@yagokoro/multilang") {
        Component(detector, "LanguageDetector", "Class", "言語自動検出 (langdetect)")
        Component(translator, "TranslationService", "Class", "翻訳統合 (DeepL + Google)")
        Component(linker, "CrossLingualLinker", "Class", "言語横断エンティティリンキング")
        Component(ingester, "MultilingualIngester", "Class", "多言語論文取り込み")
        Component(normalizer, "TermNormalizer", "Class", "多言語用語正規化")
        Component(service, "MultilingualService", "Facade", "統合ファサード")
    }
    
    Component_Ext(deepl, "DeepL Client", "HTTP Client")
    Component_Ext(google, "Google Translate Client", "HTTP Client")
    Component_Ext(cache, "TranslationCache", "Redis/SQLite")
    Component_Ext(neo4j, "Neo4j Driver", "Bolt Client")
    
    Rel(service, detector, "言語検出")
    Rel(service, translator, "翻訳")
    Rel(service, linker, "エンティティリンキング")
    Rel(service, ingester, "論文取り込み")
    
    Rel(ingester, detector, "言語検出")
    Rel(ingester, translator, "翻訳")
    Rel(ingester, linker, "リンキング")
    
    Rel(translator, deepl, "Primary")
    Rel(translator, google, "Fallback")
    Rel(translator, cache, "キャッシュ")
    
    Rel(linker, normalizer, "用語正規化")
    Rel(linker, neo4j, "エンティティ保存")
```

### 4.2 @yagokoro/citation コンポーネント図

```mermaid
C4Component
    title @yagokoro/citation Component Diagram

    Container_Boundary(citation, "@yagokoro/citation") {
        Component(extractor, "CitationExtractor", "Class", "引用関係抽出")
        Component(context, "CitationContextParser", "Class", "引用コンテキスト解析")
        Component(intent, "CitationIntentClassifier", "Class", "引用意図分類")
        Component(path, "CitationPathFinder", "Class", "引用パス検索")
        Component(burst, "CitationBurstDetector", "Class", "引用バースト検出")
        Component(selfcite, "SelfCitationAnalyzer", "Class", "自己引用分析")
        Component(metrics, "CitationMetricsCalculator", "Class", "引用メトリクス計算")
        Component(service, "CitationService", "Facade", "統合ファサード")
    }
    
    Component_Ext(graphology, "graphology", "Graph Library")
    Component_Ext(neo4j, "Neo4j Driver", "Bolt Client")
    Component_Ext(nlp, "NLP Pipeline", "spaCy/OpenAI")
    
    Rel(service, extractor, "引用抽出")
    Rel(service, path, "パス検索")
    Rel(service, burst, "バースト検出")
    Rel(service, metrics, "メトリクス計算")
    
    Rel(extractor, context, "コンテキスト解析")
    Rel(context, intent, "意図分類")
    Rel(intent, nlp, "NLP処理")
    
    Rel(path, graphology, "グラフ探索")
    Rel(path, neo4j, "グラフクエリ")
    
    Rel(burst, metrics, "メトリクス参照")
    Rel(selfcite, metrics, "自己引用率計算")
```

### 4.3 @yagokoro/topic コンポーネント図

```mermaid
C4Component
    title @yagokoro/topic Component Diagram

    Container_Boundary(topic, "@yagokoro/topic") {
        Component(extractor, "TopicExtractor", "Class", "BERTopic統合")
        Component(assigner, "TopicAssigner", "Class", "論文トピック割り当て")
        Component(hierarchy, "TopicHierarchyBuilder", "Class", "トピック階層構築")
        Component(trend, "TopicTrendAnalyzer", "Class", "トピック時系列分析")
        Component(emerging, "EmergingTopicDetector", "Class", "新興トピック検出")
        Component(similarity, "TopicSimilarityCalculator", "Class", "トピック類似度計算")
        Component(service, "TopicService", "Facade", "統合ファサード")
    }
    
    Component_Ext(bertopic, "BERTopic Python", "subprocess")
    Component_Ext(temporal, "@yagokoro/temporal", "時系列分析")
    Component_Ext(neo4j, "Neo4j Driver", "Bolt Client")
    Component_Ext(cache, "TopicCache", "Redis/SQLite")
    
    Rel(service, extractor, "トピック抽出")
    Rel(service, assigner, "トピック割り当て")
    Rel(service, trend, "トレンド分析")
    Rel(service, emerging, "新興検出")
    
    Rel(extractor, bertopic, "subprocess呼び出し")
    Rel(extractor, cache, "モデルキャッシュ")
    
    Rel(assigner, extractor, "トピック参照")
    Rel(assigner, neo4j, "割り当て保存")
    
    Rel(hierarchy, extractor, "階層構築")
    Rel(hierarchy, similarity, "類似度計算")
    
    Rel(trend, temporal, "時系列統合")
    Rel(emerging, trend, "トレンド参照")
```

---

## 5. Architecture Decision Records (ADR)

### ADR-004: 翻訳API選定

**Status**: Accepted

**Context**:
v5.0.0では多言語論文（中国語、日本語、韓国語）のサポートが必要。翻訳サービスの選定が必要。

**Decision**:
DeepL API (Primary) + Google Translate (Fallback) を採用

**Rationale**:

| 観点 | DeepL | Google Translate | 選定理由 |
|------|-------|------------------|----------|
| 学術文書精度 | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | DeepL優位 |
| 日本語品質 | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | DeepL自然 |
| API料金 | $20/1M chars | $20/1M chars | 同等 |
| 無料枠 | 500K chars/月 | なし | DeepL有利 |
| レート制限 | 緩め | 厳しめ | DeepL有利 |
| 可用性 | 99.9% | 99.99% | Google優位 |

**Implementation**:
```typescript
class TranslationService {
  private deepl: DeepLClient;
  private google: GoogleTranslateClient;
  private cache: TranslationCache;
  
  async translate(text: string, targetLang: LanguageCode): Promise<TranslationResult> {
    // 1. キャッシュチェック
    const cached = await this.cache.get(text, targetLang);
    if (cached) return cached;
    
    try {
      // 2. DeepL (Primary)
      const result = await this.deepl.translate(text, targetLang);
      await this.cache.set(text, targetLang, result, { ttl: 30 * 24 * 60 * 60 }); // 30日
      return result;
    } catch (error) {
      // 3. Google Translate (Fallback)
      console.warn('DeepL failed, falling back to Google Translate:', error.message);
      return await this.google.translate(text, targetLang);
    }
  }
}
```

**Consequences**:
- ✅ 高品質な翻訳
- ✅ コスト最適化（キャッシュ + 無料枠活用）
- ✅ 高可用性（フォールバック）
- ⚠️ 2つのAPIキー管理が必要

---

### ADR-005: BERTopic統合方式

**Status**: Accepted

**Context**:
トピックモデリングにBERTopicを採用するが、BERTopicはPythonライブラリ。Node.js/TypeScriptとの統合方式を決定する必要がある。

**Decision**:
Python subprocess方式を採用

**Alternatives Considered**:

| 方式 | 利点 | 欠点 | 採用 |
|------|------|------|------|
| **Python subprocess** | BERTopic完全互換、最新機能利用可能、実装シンプル | プロセス間通信オーバーヘッド | ✅ |
| HTTP API (FastAPI) | 非同期処理可能、スケーラブル、言語非依存 | 追加インフラ必要、デプロイ複雑化 | ❌ |
| WASM | ブラウザ対応、軽量 | BERTopic非対応、精度低下 | ❌ |
| ONNX Runtime (Node.js) | 高速推論、Node.js native | モデル変換作業、機能制限 | ❌ |

**Implementation**:
```typescript
// packages/topic/src/TopicExtractor.ts
import { spawn } from 'child_process';
import * as fs from 'fs/promises';
import * as path from 'path';

interface TopicExtractionResult {
  topics: Topic[];
  documentTopics: Map<string, string[]>;
}

class TopicExtractor {
  private pythonPath: string;
  private scriptPath: string;
  private timeout: number = 30000; // 30秒
  private maxRetries: number = 1;
  
  constructor(config: TopicExtractorConfig) {
    this.pythonPath = config.pythonPath || 'python3';
    this.scriptPath = path.join(__dirname, '../python/extract_topics.py');
  }
  
  async extractTopics(documents: string[]): Promise<TopicExtractionResult> {
    // 1. 入力データを一時ファイルに書き出し
    const inputPath = await this.writeInputFile(documents);
    const outputPath = this.getOutputPath();
    
    try {
      // 2. Python subprocess実行
      await this.runPythonScript(inputPath, outputPath);
      
      // 3. 結果読み込み
      const result = await this.readOutputFile(outputPath);
      return result;
    } catch (error) {
      if (this.maxRetries > 0) {
        this.maxRetries--;
        console.warn('BERTopic extraction failed, retrying...');
        return this.extractTopics(documents);
      }
      throw error;
    } finally {
      // 4. 一時ファイル削除
      await this.cleanup(inputPath, outputPath);
    }
  }
  
  private runPythonScript(inputPath: string, outputPath: string): Promise<void> {
    return new Promise((resolve, reject) => {
      const process = spawn(this.pythonPath, [
        this.scriptPath,
        '--input', inputPath,
        '--output', outputPath,
        '--num-topics', '50',
        '--min-topic-size', '10'
      ]);
      
      const timeout = setTimeout(() => {
        process.kill();
        reject(new Error('BERTopic extraction timed out'));
      }, this.timeout);
      
      process.on('close', (code) => {
        clearTimeout(timeout);
        if (code === 0) resolve();
        else reject(new Error(`Python script exited with code ${code}`));
      });
      
      process.stderr.on('data', (data) => {
        console.error(`BERTopic stderr: ${data}`);
      });
    });
  }
}
```

```python
# packages/topic/python/extract_topics.py
import argparse
import json
from bertopic import BERTopic
from sentence_transformers import SentenceTransformer

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--input', required=True)
    parser.add_argument('--output', required=True)
    parser.add_argument('--num-topics', type=int, default=50)
    parser.add_argument('--min-topic-size', type=int, default=10)
    args = parser.parse_args()
    
    # 入力読み込み
    with open(args.input, 'r', encoding='utf-8') as f:
        data = json.load(f)
    documents = data['documents']
    
    # BERTopic実行
    embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
    topic_model = BERTopic(
        embedding_model=embedding_model,
        nr_topics=args.num_topics,
        min_topic_size=args.min_topic_size
    )
    
    topics, probs = topic_model.fit_transform(documents)
    
    # 結果出力
    result = {
        'topics': [],
        'documentTopics': {}
    }
    
    for topic_id in set(topics):
        if topic_id == -1:
            continue
        topic_info = topic_model.get_topic(topic_id)
        result['topics'].append({
            'id': str(topic_id),
            'keywords': [word for word, _ in topic_info[:10]],
            'coherenceScore': float(probs[topics == topic_id].mean())
        })
    
    for i, (doc_topic, prob) in enumerate(zip(topics, probs)):
        result['documentTopics'][str(i)] = {
            'topicId': str(doc_topic),
            'probability': float(prob)
        }
    
    with open(args.output, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

if __name__ == '__main__':
    main()
```

**Consequences**:
- ✅ BERTopic全機能利用可能
- ✅ Python/Node.js分離でメンテナンス容易
- ✅ Pythonバージョン管理が独立
- ⚠️ Pythonランタイム必須
- ⚠️ コールドスタート時のオーバーヘッド

---

### ADR-006: 引用グラフスケーリング戦略

**Status**: Accepted

**Context**:
v5.0.0では1M+の引用エッジを扱う。Neo4jでの大規模グラフクエリのパフォーマンス確保が必要。

**Decision**:
以下の戦略を採用:
1. 複合インデックス最適化
2. グラフ分割（年代別パーティション）
3. キャッシュ層（頻出パス）

**Implementation**:

```cypher
// 1. 複合インデックス
CREATE INDEX citation_composite IF NOT EXISTS
FOR (p:Paper) ON (p.id, p.publishedYear);

CREATE INDEX citation_edge_index IF NOT EXISTS
FOR ()-[r:CITES]->() ON (r.citingPaperId, r.citedPaperId);

// 2. 引用パス検索の最適化クエリ
// 5ホップ以内のパス検索
MATCH path = shortestPath(
  (p1:Paper {id: $paper1Id})-[:CITES*1..5]-(p2:Paper {id: $paper2Id})
)
RETURN path
LIMIT 10;

// 3. 引用バースト検出クエリ
MATCH (p:Paper)-[c:CITES]->(target:Paper {id: $targetId})
WHERE c.citedAt >= $startDate AND c.citedAt <= $endDate
WITH target, date(c.citedAt).month AS month, count(*) AS citations
RETURN month, citations
ORDER BY month;
```

```typescript
// キャッシュ戦略
class CitationPathCache {
  private cache: Map<string, CitationPath[]>;
  private ttl: number = 3600; // 1時間
  
  getCacheKey(paper1: string, paper2: string): string {
    return [paper1, paper2].sort().join(':');
  }
  
  async getPath(paper1: string, paper2: string): Promise<CitationPath[] | null> {
    const key = this.getCacheKey(paper1, paper2);
    const cached = this.cache.get(key);
    if (cached && !this.isExpired(key)) {
      return cached;
    }
    return null;
  }
}
```

**Consequences**:
- ✅ 1M+ edges対応
- ✅ パス検索 <1秒
- ⚠️ インデックス更新コスト
- ⚠️ キャッシュ整合性管理

---

### ADR-007: 多言語NERモデル選定

**Status**: Accepted

**Context**:
中国語、日本語、韓国語の論文からエンティティを抽出する必要がある。

**Decision**:
言語別にspaCyモデルを使用

| 言語 | モデル | サイズ | 精度 |
|------|--------|--------|------|
| 英語 | en_core_web_trf | 460MB | 96.0% |
| 中国語 | zh_core_web_trf | 400MB | 93.5% |
| 日本語 | ja_core_news_trf | 520MB | 94.2% |
| 韓国語 | ko_core_news_sm | 15MB | 89.0% |

**Implementation**:
```typescript
class MultilingualNER {
  private models: Map<LanguageCode, string> = new Map([
    ['en', 'en_core_web_trf'],
    ['zh', 'zh_core_web_trf'],
    ['ja', 'ja_core_news_trf'],
    ['ko', 'ko_core_news_sm'],
  ]);
  
  async extractEntities(text: string, lang: LanguageCode): Promise<Entity[]> {
    const model = this.models.get(lang);
    if (!model) {
      throw new Error(`Unsupported language: ${lang}`);
    }
    
    // spaCy Python subprocess呼び出し
    return await this.runSpacy(text, model);
  }
}
```

**Consequences**:
- ✅ 高精度NER
- ✅ 4言語対応
- ⚠️ モデルサイズ大（合計約1.4GB）
- ⚠️ 韓国語精度がやや低い

---

### ADR-008: 言語検出ライブラリ選定

**Status**: Accepted

**Context**:
多言語論文の言語を自動検出する必要がある。REQ-008-02で「言語検出confidence < 0.7の場合はunknownフラグ」と定義されている。

**Decision**:
langdetect（Python）を採用

**Alternatives Considered**:

| ライブラリ | 精度 | 速度 | 言語数 | サイズ | 採用 |
|-----------|------|------|--------|--------|------|
| **langdetect** | 99%+ | 中 | 55 | 軽量 | ✅ |
| fastText (lid.176) | 98%+ | 高速 | 176 | 126MB | ❌ |
| lingua-py | 99.5%+ | 低速 | 75 | 重い | ❌ |
| CLD3 | 97%+ | 高速 | 107 | 中 | ❌ |

**Rationale**:
- langdetectは短文でも高精度（論文タイトル・アブストラクトに適合）
- Pythonネイティブで既存spaCy環境と統合容易
- en/zh/ja/ko の4言語で99%+の精度
- fastTextはモデルサイズが大きく、176言語は過剰
- lingua-pyは精度最高だが速度が遅い

**Implementation**:
```typescript
import { spawn } from 'child_process';

interface LanguageDetectionResult {
  language: LanguageCode;
  confidence: number;
  isReliable: boolean;
}

class LanguageDetector {
  private readonly MIN_CONFIDENCE = 0.7; // REQ-008-09
  
  async detect(text: string): Promise<LanguageDetectionResult> {
    const result = await this.runLangdetect(text);
    
    return {
      language: result.confidence >= this.MIN_CONFIDENCE 
        ? result.language 
        : 'unknown',
      confidence: result.confidence,
      isReliable: result.confidence >= this.MIN_CONFIDENCE
    };
  }
  
  // Unwanted behavior対応: REQ-008-09
  async detectWithFallback(text: string): Promise<LanguageDetectionResult> {
    const result = await this.detect(text);
    
    if (!result.isReliable) {
      // Manual review queueに追加
      await this.addToManualReviewQueue(text, result);
      console.warn(`Language detection unreliable: ${result.confidence}`);
    }
    
    return result;
  }
}
```

**Consequences**:
- ✅ 高精度言語検出（99%+）
- ✅ 軽量で高速
- ✅ confidence値取得可能（REQ-008-09対応）
- ⚠️ Python subprocess呼び出しが必要

---

### ADR-009: キャッシュストレージ選定

**Status**: Accepted

**Context**:
翻訳結果・トピックモデル結果のキャッシュストレージを選定する必要がある。開発環境とプロダクション環境で異なる要件がある。

**Decision**:
SQLite（開発/軽量運用） + Redis（プロダクション）のハイブリッド

**Alternatives Considered**:

| ストレージ | 用途 | 永続化 | 速度 | 運用コスト | 採用 |
|-----------|------|--------|------|-----------|------|
| **SQLite** | 開発/軽量運用 | ✅ | 中 | 低 | ✅ |
| **Redis** | プロダクション | ⚠️ AOF | 高速 | 中 | ✅ |
| LevelDB | ローカル高速 | ✅ | 高速 | 低 | ❌ |
| PostgreSQL | 複雑クエリ | ✅ | 中 | 高 | ❌ |

**Rationale**:
- SQLiteはゼロ設定で開発開始可能
- Redisはプロダクションで高速・スケーラブル
- 同一インターフェースで切り替え可能な抽象化層を提供
- LevelDBはNode.jsバインディングが不安定

**Implementation**:
```typescript
interface CacheProvider {
  get<T>(key: string): Promise<T | null>;
  set<T>(key: string, value: T, ttl?: number): Promise<void>;
  delete(key: string): Promise<void>;
  clear(): Promise<void>;
}

class SQLiteCache implements CacheProvider {
  private db: Database;
  
  async get<T>(key: string): Promise<T | null> {
    const row = this.db.prepare(
      'SELECT value, expires_at FROM cache WHERE key = ?'
    ).get(key);
    
    if (!row || (row.expires_at && row.expires_at < Date.now())) {
      return null;
    }
    return JSON.parse(row.value);
  }
  
  async set<T>(key: string, value: T, ttl?: number): Promise<void> {
    const expiresAt = ttl ? Date.now() + ttl * 1000 : null;
    this.db.prepare(
      'INSERT OR REPLACE INTO cache (key, value, expires_at) VALUES (?, ?, ?)'
    ).run(key, JSON.stringify(value), expiresAt);
  }
}

class RedisCache implements CacheProvider {
  private client: RedisClient;
  
  async get<T>(key: string): Promise<T | null> {
    const value = await this.client.get(key);
    return value ? JSON.parse(value) : null;
  }
  
  async set<T>(key: string, value: T, ttl?: number): Promise<void> {
    if (ttl) {
      await this.client.setex(key, ttl, JSON.stringify(value));
    } else {
      await this.client.set(key, JSON.stringify(value));
    }
  }
}

// Factory
function createCache(config: CacheConfig): CacheProvider {
  return config.type === 'redis' 
    ? new RedisCache(config.redis) 
    : new SQLiteCache(config.sqlite);
}
```

**Consequences**:
- ✅ 開発環境はゼロ設定
- ✅ プロダクション環境はスケーラブル
- ✅ 統一インターフェースで切り替え容易
- ⚠️ 2種類のストレージをテストする必要

---

### ADR-010: Unwanted Behavior エラーハンドリング設計

**Status**: Accepted

**Context**:
要件定義で6つのUnwanted behaviorが定義されている。これらの設計レベルでの対応を明確化する。

**Decision**:
各Unwanted behaviorに対応するエラーハンドラーとフォールバック戦略を定義

**Implementation**:

| REQ-ID | Unwanted Behavior | 設計対応 | 実装 |
|--------|------------------|---------|------|
| REQ-008-08 | 翻訳API失敗 | フォールバック | TranslationService.translateWithFallback() |
| REQ-008-09 | 言語検出 < 0.7 | Manual Review Queue | LanguageDetector.detectWithFallback() |
| REQ-009-11 | 循環引用検出 | DAG検証 | CitationValidator.detectCycle() |
| REQ-009-12 | 引用パス5ホップ超過 | 制限 + 警告 | CitationPathFinder.findPathWithLimit() |
| REQ-010-11 | BERTopicタイムアウト | リトライ + フォールバック | TopicExtractor.extractWithRetry() |
| REQ-010-12 | トピック数過少 | パラメータ調整 | TopicExtractor.validateTopicCount() |

```typescript
// 循環引用検出 (REQ-009-11)
class CitationValidator {
  detectCycle(citations: Citation[]): CycleDetectionResult {
    const graph = this.buildGraph(citations);
    const visited = new Set<string>();
    const recStack = new Set<string>();
    
    for (const node of graph.nodes()) {
      if (this.hasCycleDFS(node, visited, recStack, graph)) {
        return { hasCycle: true, cycleNodes: Array.from(recStack) };
      }
    }
    return { hasCycle: false, cycleNodes: [] };
  }
}

// 引用パス制限 (REQ-009-12)
class CitationPathFinder {
  private readonly MAX_HOPS = 5; // REQ-009-12
  
  async findPath(paper1: string, paper2: string, maxHops?: number): Promise<CitationPathResult> {
    const limit = Math.min(maxHops ?? this.MAX_HOPS, this.MAX_HOPS);
    
    const path = await this.searchPath(paper1, paper2, limit);
    
    if (!path && (maxHops ?? this.MAX_HOPS) > this.MAX_HOPS) {
      return {
        found: false,
        path: [],
        warning: `Path search limited to ${this.MAX_HOPS} hops. Consider using citation tree instead.`
      };
    }
    
    return { found: !!path, path: path ?? [], warning: null };
  }
}

// トピック数検証 (REQ-010-12)
class TopicExtractor {
  private readonly MIN_TOPICS = 5;
  
  async extractTopics(documents: string[], numTopics: number = 50): Promise<TopicExtractionResult> {
    let result = await this.runBERTopic(documents, numTopics);
    
    // REQ-010-12: トピック数が少なすぎる場合
    if (result.topics.length < this.MIN_TOPICS) {
      console.warn(`Only ${result.topics.length} topics found. Adjusting parameters...`);
      
      // min_topic_sizeを下げてリトライ
      result = await this.runBERTopic(documents, numTopics, { minTopicSize: 5 });
      
      if (result.topics.length < this.MIN_TOPICS) {
        return {
          ...result,
          warning: `Insufficient topics (${result.topics.length}). Consider adding more documents.`,
          isReliable: false
        };
      }
    }
    
    return { ...result, warning: null, isReliable: true };
  }
}
```

**Consequences**:
- ✅ 全Unwanted behaviorに対応
- ✅ グレースフルデグラデーション
- ✅ ユーザーへの警告表示
- ⚠️ エラーハンドリングコードの増加

---

### ADR-011: 非機能要件のコンポーネント仕様

**Status**: Accepted

**Context**:
非機能要件（NFR）を各コンポーネントの設計仕様に反映する必要がある。

**Decision**:
各コンポーネントにタイムアウト、精度目標、パフォーマンス目標を明示的に設定

**Implementation**:

| コンポーネント | NFR | 要件 | 設計値 |
|---------------|-----|------|--------|
| TranslationService | REQ-008-10 | < 2秒/abstract | timeout: 2000ms |
| CrossLingualLinker | REQ-008-11 | > 80%精度 | threshold: 0.8 |
| CitationService | REQ-009-07 | < 500ms | timeout: 500ms |
| TopicExtractor | REQ-010-07 | < 30秒 | timeout: 30000ms |
| TopicExtractor | REQ-010-08 | > 0.5 coherence | minCoherence: 0.5 |

```typescript
// TranslationService NFR設定
class TranslationService {
  private readonly TIMEOUT_MS = 2000; // REQ-008-10: < 2秒
  
  async translate(text: string, targetLang: LanguageCode): Promise<TranslationResult> {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), this.TIMEOUT_MS);
    
    try {
      return await this.deepl.translate(text, targetLang, { signal: controller.signal });
    } catch (error) {
      if (error.name === 'AbortError') {
        console.warn('Translation timeout, falling back to Google');
        return await this.google.translate(text, targetLang);
      }
      throw error;
    } finally {
      clearTimeout(timeoutId);
    }
  }
}

// CrossLingualLinker NFR設定
class CrossLingualLinker {
  private readonly PRECISION_THRESHOLD = 0.8; // REQ-008-11: > 80%
  
  async linkEntities(source: Entity, candidates: Entity[]): Promise<LinkResult> {
    const scored = candidates.map(c => ({
      entity: c,
      score: this.calculateSimilarity(source, c)
    }));
    
    const matches = scored.filter(s => s.score >= this.PRECISION_THRESHOLD);
    return { matches, threshold: this.PRECISION_THRESHOLD };
  }
}

// CitationService NFR設定
class CitationService {
  private readonly TIMEOUT_MS = 500; // REQ-009-07: < 500ms
  
  async analyzeCitations(paperId: string): Promise<CitationAnalysis> {
    const startTime = Date.now();
    
    const result = await Promise.race([
      this.performAnalysis(paperId),
      this.timeout(this.TIMEOUT_MS)
    ]);
    
    const elapsed = Date.now() - startTime;
    if (elapsed > this.TIMEOUT_MS * 0.8) {
      console.warn(`Citation analysis took ${elapsed}ms, approaching timeout`);
    }
    
    return result;
  }
}

// TopicExtractor NFR設定
class TopicExtractor {
  private readonly TIMEOUT_MS = 30000;    // REQ-010-07: < 30秒
  private readonly MIN_COHERENCE = 0.5;   // REQ-010-08: > 0.5
  
  async extractTopics(documents: string[]): Promise<TopicExtractionResult> {
    const result = await this.runWithTimeout(documents, this.TIMEOUT_MS);
    
    // Coherence検証
    const validTopics = result.topics.filter(t => t.coherenceScore >= this.MIN_COHERENCE);
    
    if (validTopics.length < result.topics.length) {
      console.warn(
        `Filtered ${result.topics.length - validTopics.length} low-coherence topics`
      );
    }
    
    return { ...result, topics: validTopics };
  }
}
```

**Consequences**:
- ✅ NFRが設計に明示的に反映
- ✅ タイムアウト・品質閾値が定数化
- ✅ 監視・ログ出力で性能追跡可能
- ⚠️ 閾値調整にはリリース必要

---

## 6. データフロー図

### 6.1 多言語論文取り込みフロー

```mermaid
flowchart TB
    subgraph Input["入力"]
        A[/"中国語論文 (CNKI)"/]
        B[/"日本語論文 (CiNii)"/]
        C[/"韓国語論文 (KCI)"/]
    end
    
    subgraph Detection["言語検出"]
        D["LanguageDetector"]
        D1{"confidence >= 0.7?"}
    end
    
    subgraph Translation["翻訳"]
        E["TranslationCache"]
        F["DeepL API"]
        G["Google Translate"]
        E1{"キャッシュヒット?"}
    end
    
    subgraph Extraction["エンティティ抽出"]
        H["MultilingualNER"]
        I["CrossLingualLinker"]
    end
    
    subgraph Storage["保存"]
        J[("Neo4j")]
        K[("Redis Cache")]
    end
    
    A --> D
    B --> D
    C --> D
    
    D --> D1
    D1 -->|Yes| E
    D1 -->|No| L["Manual Review Queue"]
    
    E --> E1
    E1 -->|Yes| H
    E1 -->|No| F
    
    F -->|Success| H
    F -->|Fail| G
    G --> H
    
    H --> I
    I --> J
    
    F -->|Result| K
    G -->|Result| K
```

### 6.2 引用ネットワーク分析フロー

```mermaid
flowchart TB
    subgraph Input["入力"]
        A[/"論文PDF/テキスト"/]
    end
    
    subgraph Extraction["引用抽出"]
        B["CitationExtractor"]
        C["CitationContextParser"]
        D["CitationIntentClassifier"]
    end
    
    subgraph Analysis["分析"]
        E["CitationPathFinder"]
        F["CitationBurstDetector"]
        G["SelfCitationAnalyzer"]
        H["CitationMetricsCalculator"]
    end
    
    subgraph Storage["保存"]
        I[("Neo4j")]
    end
    
    subgraph Output["出力"]
        J["引用ツリー"]
        K["引用パス"]
        L["バーストアラート"]
        M["メトリクスレポート"]
    end
    
    A --> B
    B --> C
    C --> D
    D --> I
    
    I --> E
    I --> F
    I --> G
    I --> H
    
    E --> J
    E --> K
    F --> L
    H --> M
```

### 6.3 トピックモデリングフロー

```mermaid
flowchart TB
    subgraph Input["入力"]
        A[/"論文コーパス"/]
    end
    
    subgraph Preprocessing["前処理"]
        B["TextPreprocessor"]
        C["EmbeddingGenerator"]
    end
    
    subgraph TopicModeling["トピック抽出"]
        D["TopicExtractor"]
        E["BERTopic Python"]
        F{"タイムアウト?"}
    end
    
    subgraph PostProcessing["後処理"]
        G["TopicAssigner"]
        H["TopicHierarchyBuilder"]
        I["TopicTrendAnalyzer"]
        J["EmergingTopicDetector"]
    end
    
    subgraph Storage["保存"]
        K[("Neo4j")]
        L[("Topic Cache")]
    end
    
    A --> B
    B --> C
    C --> D
    D --> E
    
    E --> F
    F -->|No| G
    F -->|Yes| M["Retry / Fallback"]
    M --> E
    
    G --> K
    G --> H
    H --> I
    I --> J
    
    D --> L
```

---

## 7. シーケンス図

### 7.1 多言語論文検索シーケンス

```mermaid
sequenceDiagram
    participant U as User
    participant CLI as CLI/MCP
    participant MS as MultilingualService
    participant LD as LanguageDetector
    participant TS as TranslationService
    participant Neo as Neo4j
    
    U->>CLI: multilang search "transformer" --langs en,zh,ja
    CLI->>MS: search(query, languages)
    
    MS->>TS: translateQuery(query, targetLangs)
    TS-->>MS: {en: "transformer", zh: "变换器", ja: "トランスフォーマー"}
    
    MS->>Neo: MATCH (p:Paper) WHERE p.title CONTAINS $query...
    Neo-->>MS: [Paper1, Paper2, Paper3...]
    
    loop 各論文
        MS->>LD: detectLanguage(paper.title)
        LD-->>MS: {lang: "zh", confidence: 0.95}
        
        alt 非英語 & 翻訳要求
            MS->>TS: translate(paper.abstract, "en")
            TS-->>MS: translatedAbstract
        end
    end
    
    MS-->>CLI: SearchResult[]
    CLI-->>U: 検索結果表示
```

### 7.2 引用パス検索シーケンス

```mermaid
sequenceDiagram
    participant U as User
    participant CLI as CLI/MCP
    participant CS as CitationService
    participant PF as CitationPathFinder
    participant Cache as PathCache
    participant Neo as Neo4j
    
    U->>CLI: citation path "paper1" "paper2" --max-hops 5
    CLI->>CS: findPath(paper1, paper2, maxHops=5)
    
    CS->>Cache: getPath(paper1, paper2)
    
    alt キャッシュヒット
        Cache-->>CS: cachedPath
    else キャッシュミス
        CS->>PF: searchPath(paper1, paper2, maxHops)
        PF->>Neo: shortestPath query
        Neo-->>PF: path data
        PF-->>CS: CitationPath
        CS->>Cache: setPath(paper1, paper2, path)
    end
    
    CS-->>CLI: CitationPath
    CLI-->>U: パス表示（Mermaid図）
```

### 7.3 トピック抽出シーケンス

```mermaid
sequenceDiagram
    participant U as User
    participant CLI as CLI/MCP
    participant TS as TopicService
    participant TE as TopicExtractor
    participant BP as BERTopic (Python)
    participant Neo as Neo4j
    participant Cache as TopicCache
    
    U->>CLI: topic extract --num-topics 50
    CLI->>TS: extractTopics(numTopics=50)
    
    TS->>Neo: MATCH (p:Paper) RETURN p.abstract
    Neo-->>TS: documents[]
    
    TS->>TE: extract(documents)
    TE->>TE: writeInputFile(documents)
    
    TE->>BP: subprocess.spawn("python extract_topics.py")
    
    alt 正常終了
        BP-->>TE: exit code 0
        TE->>TE: readOutputFile()
        TE-->>TS: TopicExtractionResult
    else タイムアウト
        TE->>TE: retry (max 1回)
        TE->>BP: subprocess.spawn(...)
        BP-->>TE: result
    end
    
    TS->>Neo: CREATE (t:Topic {...})
    TS->>Cache: setTopics(topics)
    
    TS-->>CLI: Topic[]
    CLI-->>U: トピック一覧表示
```

---

## 付録

### A. ファイル構成（予定）

```
packages/
├── multilang/
│   ├── src/
│   │   ├── index.ts
│   │   ├── LanguageDetector.ts
│   │   ├── TranslationService.ts
│   │   ├── CrossLingualLinker.ts
│   │   ├── MultilingualIngester.ts
│   │   ├── TermNormalizer.ts
│   │   └── MultilingualService.ts
│   ├── __tests__/
│   │   ├── LanguageDetector.test.ts
│   │   ├── TranslationService.test.ts
│   │   └── ...
│   └── package.json
├── citation/
│   ├── src/
│   │   ├── index.ts
│   │   ├── CitationExtractor.ts
│   │   ├── CitationContextParser.ts
│   │   ├── CitationIntentClassifier.ts
│   │   ├── CitationPathFinder.ts
│   │   ├── CitationBurstDetector.ts
│   │   ├── SelfCitationAnalyzer.ts
│   │   ├── CitationMetricsCalculator.ts
│   │   ├── CitationValidator.ts
│   │   └── CitationService.ts
│   ├── __tests__/
│   └── package.json
└── topic/
    ├── src/
    │   ├── index.ts
    │   ├── TopicExtractor.ts
    │   ├── TopicAssigner.ts
    │   ├── TopicHierarchyBuilder.ts
    │   ├── TopicTrendAnalyzer.ts
    │   ├── EmergingTopicDetector.ts
    │   └── TopicService.ts
    ├── python/
    │   ├── extract_topics.py
    │   ├── requirements.txt
    │   └── README.md
    ├── __tests__/
    └── package.json
```

### B. 依存関係グラフ

```mermaid
graph TD
    subgraph v5.0.0 New
        multilang["@yagokoro/multilang"]
        citation["@yagokoro/citation"]
        topic["@yagokoro/topic"]
    end
    
    subgraph v4.0.0 Existing
        core["@yagokoro/core"]
        ingestion["@yagokoro/ingestion"]
        extractor["@yagokoro/extractor"]
        graph["@yagokoro/graph"]
        query["@yagokoro/query"]
        temporal["@yagokoro/temporal"]
        researcher["@yagokoro/researcher"]
        cli["@yagokoro/cli"]
        mcp["@yagokoro/mcp"]
    end
    
    subgraph External
        deepl["DeepL API"]
        google["Google Translate"]
        bertopic["BERTopic"]
        spacy["spaCy"]
        langdetect["langdetect"]
    end
    
    subgraph Cache
        redis["Redis"]
        sqlite["SQLite"]
    end
    
    multilang --> core
    multilang --> ingestion
    multilang --> deepl
    multilang --> google
    multilang --> spacy
    multilang --> langdetect
    multilang --> redis
    multilang --> sqlite
    
    citation --> core
    citation --> extractor
    citation --> graph
    citation --> researcher
    citation --> query
    
    topic --> core
    topic --> temporal
    topic --> bertopic
    topic --> redis
    topic --> sqlite
    
    cli --> multilang
    cli --> citation
    cli --> topic
    
    mcp --> multilang
    mcp --> citation
    mcp --> topic
```

---

*Generated by MUSUBI SDD - v5.0.0 Design Phase*

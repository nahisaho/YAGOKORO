/**
 * Generate GenAI Genealogy using GraphRAG
 *
 * GraphRAGã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½¿ç”¨ã—ã¦ç”ŸæˆAIã®é€²åŒ–ã®ç³»è­œã‚’ä½œæˆ
 *
 * Features:
 * - EntityExtractor: AIModel, Organization, Person, Technique, Concept ã‚’æŠ½å‡º
 * - RelationExtractor: DERIVED_FROM, USES_TECHNIQUE, DEVELOPED_BY ç­‰ã®é–¢ä¿‚ã‚’æŠ½å‡º
 * - ConceptGraphBuilder: ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚°ãƒ©ãƒ•æ§‹ç¯‰
 * - LeidenCommunityDetector: ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œå‡º
 *
 * Usage:
 *   npx tsx scripts/generate-genai-genealogy-graphrag.ts
 */

import { readdir, readFile, writeFile, mkdir } from 'node:fs/promises';
import { join } from 'node:path';

// Ollamaè¨­å®š
const OLLAMA_BASE_URL = process.env.OLLAMA_BASE_URL || 'http://192.168.224.1:11434';
const OLLAMA_MODEL = process.env.OLLAMA_MODEL || 'qwen2.5:7b';

const DATA_DIRS = [
  'data/chunks',
  'data/chunks/unpaywall',
  'data/chunks/techniques',
  'data/chunks/techniques-2',
  'data/chunks/reasoning-agents',
];

const OUTPUT_DIR = 'outputs';

interface ExtractedEntity {
  tempId: string;
  name: string;
  type: string;
  confidence: number;
  description?: string;
}

interface ExtractedRelation {
  type: string;
  sourceTempId: string;
  targetTempId: string;
  confidence: number;
  description?: string;
}

// Ollama APIã‚’ç›´æ¥å‘¼ã³å‡ºã—
async function ollamaChat(prompt: string): Promise<string> {
  const response = await fetch(`${OLLAMA_BASE_URL}/api/generate`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      model: OLLAMA_MODEL,
      prompt,
      stream: false,
      options: {
        temperature: 0.1,
        num_predict: 2000,
      },
    }),
  });

  if (!response.ok) {
    throw new Error(`Ollama API error: ${response.status} ${response.statusText}`);
  }

  const data = await response.json() as { response: string };
  return data.response;
}

/**
 * JSONã‚’æŠ½å‡ºãƒ»ä¿®å¾©ã™ã‚‹é–¢æ•°
 * LLMã®å‡ºåŠ›ã‹ã‚‰æœ‰åŠ¹ãªJSONã‚’æŠ½å‡ºã—ã€ä¸€èˆ¬çš„ãªã‚¨ãƒ©ãƒ¼ã‚’ä¿®å¾©
 */
function extractAndRepairJson(content: string): string | null {
  // Step 1: ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰JSONã‚’æŠ½å‡º
  let json = content;
  
  // ```json ... ``` ã¾ãŸã¯ ``` ... ``` ã‚’æŠ½å‡º
  const codeBlockMatch = content.match(/```(?:json)?\s*([\s\S]*?)```/);
  if (codeBlockMatch) {
    json = codeBlockMatch[1]!;
  }

  // Step 2: JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®é–‹å§‹ã¨çµ‚äº†ã‚’è¦‹ã¤ã‘ã‚‹
  json = json.trim();
  
  // å…ˆé ­ã®éJSONæ–‡å­—ã‚’é™¤å»ï¼ˆ"Here is the JSON:" ãªã©ã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ï¼‰
  const firstBrace = json.indexOf('{');
  if (firstBrace === -1) {
    return null;
  }
  json = json.slice(firstBrace);

  // æœ«å°¾ã®éJSONæ–‡å­—ã‚’é™¤å»
  const lastBrace = json.lastIndexOf('}');
  if (lastBrace === -1) {
    return null;
  }
  json = json.slice(0, lastBrace + 1);

  // Step 3: ä¸€èˆ¬çš„ãªJSONã‚¨ãƒ©ãƒ¼ã‚’ä¿®å¾©
  
  // 3a: æœ«å°¾ã®ã‚«ãƒ³ãƒã‚’é™¤å» (é…åˆ—å†… [1, 2, 3,] â†’ [1, 2, 3])
  json = json.replace(/,(\s*[\]}])/g, '$1');
  
  // 3b: ã‚·ãƒ³ã‚°ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã‚’ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã«å¤‰æ›
  // æ³¨æ„: æ–‡å­—åˆ—å†…ã®ã‚·ãƒ³ã‚°ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã¯ä¿æŒ
  json = json.replace(/'/g, '"');
  
  // 3c: åˆ¶å¾¡æ–‡å­—ã‚’é™¤å»ï¼ˆæ”¹è¡Œä»¥å¤–ï¼‰
  json = json.replace(/[\x00-\x09\x0B\x0C\x0E-\x1F\x7F]/g, '');
  
  // 3d: ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚Œã¦ã„ãªã„æ”¹è¡Œã‚’ç©ºç™½ã«ç½®æ›ï¼ˆæ–‡å­—åˆ—å†…ï¼‰
  // JSONã®æ–‡å­—åˆ—å†…ã®æ”¹è¡Œã¯ \n ã§ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚Œã‚‹å¿…è¦ãŒã‚ã‚‹
  json = json.replace(/(?<!\\)\\n/g, '\\n');
  
  // 3e: ä¸æ­£ãªã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ä¿®å¾©
  json = json.replace(/\\(?!["\\/bfnrtu])/g, '\\\\');
  
  // 3f: NaNã‚„Infinityã‚’æ–‡å­—åˆ—ã«å¤‰æ›ï¼ˆJSONã§ã¯ç„¡åŠ¹ï¼‰
  json = json.replace(/:\s*NaN\b/g, ': "NaN"');
  json = json.replace(/:\s*Infinity\b/g, ': "Infinity"');
  json = json.replace(/:\s*-Infinity\b/g, ': "-Infinity"');
  
  // 3g: undefinedã‚’nullã«å¤‰æ›
  json = json.replace(/:\s*undefined\b/g, ': null');

  return json;
}

/**
 * ãƒªãƒˆãƒ©ã‚¤ä»˜ãã§JSONã‚’è§£æ
 */
async function parseJsonWithRetry<T>(
  content: string,
  retryPrompt: () => Promise<string>,
  maxRetries = 1
): Promise<T | null> {
  let attempts = 0;
  let lastContent = content;

  while (attempts <= maxRetries) {
    const json = extractAndRepairJson(lastContent);
    if (!json) {
      if (attempts < maxRetries) {
        attempts++;
        lastContent = await retryPrompt();
        continue;
      }
      return null;
    }

    try {
      return JSON.parse(json) as T;
    } catch (e) {
      if (attempts < maxRetries) {
        attempts++;
        lastContent = await retryPrompt();
        continue;
      }
      return null;
    }
  }

  return null;
}

interface PaperData {
  title: string;
  arxivId?: string;
  doi?: string;
  abstract?: string;
  year: number;
  category: string;
  chunks: Array<{ content: string }>;
  fullText?: string;
}

interface GraphRAGResult {
  entities: ExtractedEntity[];
  relations: ExtractedRelation[];
  papers: PaperData[];
}

// å¹´ã®æ¨å®šï¼ˆarXiv IDã‹ã‚‰ï¼‰
function estimateYear(arxivId?: string): number | null {
  if (!arxivId) return null;
  const match = arxivId.match(/^(\d{2})(\d{2})\./);
  if (match) {
    const yearPrefix = parseInt(match[1]!, 10);
    return yearPrefix >= 90 ? 1900 + yearPrefix : 2000 + yearPrefix;
  }
  return null;
}

async function collectPapers(): Promise<PaperData[]> {
  const papers: PaperData[] = [];

  for (const dir of DATA_DIRS) {
    const fullPath = join(process.cwd(), dir);
    try {
      const files = await readdir(fullPath);
      const jsonFiles = files.filter((f) => f.endsWith('.json') && !f.startsWith('_'));

      for (const file of jsonFiles) {
        try {
          const content = await readFile(join(fullPath, file), 'utf-8');
          const data = JSON.parse(content);

          const paperData = data.paper || data;
          const title = paperData.title || data.title || file.replace('.json', '');

          let arxivId = data.arxivId || paperData.id;
          if (arxivId && arxivId.includes('v')) {
            arxivId = arxivId.split('v')[0];
          }

          let year = data.year || data.metadata?.year;
          if (!year && paperData.published) {
            year = new Date(paperData.published).getFullYear();
          }
          if (!year && arxivId) {
            year = estimateYear(arxivId);
          }
          if (!year) {
            year = 2020;
          }

          papers.push({
            title,
            arxivId,
            doi: data.doi,
            abstract: paperData.abstract || data.abstract,
            year,
            category: data.category || 'LLM',
            chunks: data.chunks || [],
            fullText: data.fullText,
          });
        } catch (e) {
          // Skip invalid files
        }
      }
    } catch (e) {
      // Skip missing directories
    }
  }

  return papers.sort((a, b) => a.year - b.year);
}

async function extractEntitiesAndRelations(
  papers: PaperData[]
): Promise<GraphRAGResult> {
  const allEntities: ExtractedEntity[] = [];
  const allRelations: ExtractedRelation[] = [];
  const entityMap = new Map<string, ExtractedEntity>();

  console.log(`\nğŸ“Š ${papers.length}ä»¶ã®è«–æ–‡ã‹ã‚‰ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨é–¢ä¿‚ã‚’æŠ½å‡ºä¸­...`);

  // ä¸»è¦ãªè«–æ–‡ã®ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆã‹ã‚‰æŠ½å‡ºï¼ˆå…¨éƒ¨ã‚„ã‚‹ã¨æ™‚é–“ãŒã‹ã‹ã‚‹ã®ã§ä¸Šä½80ä»¶ï¼‰
  const keyPapers = papers
    .filter((p) => p.abstract && p.abstract.length > 100)
    .slice(0, 80);

  let processed = 0;
  let entityIdCounter = 0;

  for (const paper of keyPapers) {
    try {
      const text = `Title: ${paper.title}\n\nAbstract: ${paper.abstract?.slice(0, 1500)}`;

      // ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æŠ½å‡ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
      const entityPrompt = `You are an expert at extracting named entities from AI research papers.
Extract entities from the following text. You MUST respond with ONLY a valid JSON object, no other text before or after.

JSON format:
{"entities": [{"name": "entity name", "type": "AIModel|Organization|Person|Technique|Concept", "confidence": 0.9, "description": "brief description"}]}

Entity types:
- AIModel: AI models like GPT-4, BERT, LLaMA, Mistral
- Organization: Companies and institutions like OpenAI, Google, Meta
- Person: Researchers and authors
- Technique: Methods and algorithms like attention, RLHF, LoRA
- Concept: Abstract concepts like few-shot learning, alignment

Text:
${text}

IMPORTANT: Respond with ONLY the JSON object. Do not include any explanation, markdown formatting, or code blocks.`;

      const entityContent = await ollamaChat(entityPrompt);

      // æ–°ã—ã„JSONè§£æãƒ»ä¿®å¾©é–¢æ•°ã‚’ä½¿ç”¨
      interface EntityResult {
        entities: Array<{ name: string; type: string; confidence: number; description?: string }>;
      }
      
      const parsedEntities = await parseJsonWithRetry<EntityResult>(
        entityContent,
        async () => {
          // ãƒªãƒˆãƒ©ã‚¤æ™‚ã¯ã‚ˆã‚Šå³å¯†ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å†è©¦è¡Œ
          const retryPrompt = `Output ONLY valid JSON. No text before or after. Format: {"entities":[{"name":"X","type":"AIModel","confidence":0.9,"description":"Y"}]}

Extract AI entities from:
${text.slice(0, 800)}`;
          return await ollamaChat(retryPrompt);
        }
      );

      if (!parsedEntities) {
        console.log(`   âš  ${paper.title.slice(0, 40)}... JSONè§£æã‚¨ãƒ©ãƒ¼ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰`);
        continue;
      }

      const paperEntities: ExtractedEntity[] = [];
      for (const e of parsedEntities.entities || []) {
        if (!e.name || !e.type) continue;
        const key = `${e.type}:${e.name.toLowerCase()}`;
        if (!entityMap.has(key)) {
          const entity: ExtractedEntity = {
            tempId: `e${++entityIdCounter}`,
            name: e.name,
            type: e.type,
            confidence: e.confidence || 0.7,
            description: e.description,
          };
          entityMap.set(key, entity);
          allEntities.push(entity);
          paperEntities.push(entity);
        } else {
          paperEntities.push(entityMap.get(key)!);
        }
      }

      // é–¢ä¿‚æŠ½å‡ºï¼ˆã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãŒ2ã¤ä»¥ä¸Šã‚ã‚‹å ´åˆï¼‰
      if (paperEntities.length >= 2) {
        const entityList = paperEntities
          .slice(0, 10)
          .map((e) => `${e.tempId}: ${e.name} (${e.type})`)
          .join('\n');

        const relationPrompt = `You are an expert at extracting relationships between entities in AI research papers.
Given these entities:
${entityList}

And this text:
${text}

Extract relationships between the entities. You MUST respond with ONLY a valid JSON object, no other text.

JSON format:
{"relations": [{"type": "DEVELOPED_BY", "sourceId": "e1", "targetId": "e2", "confidence": 0.9}]}

Valid relation types: DEVELOPED_BY, USES_TECHNIQUE, DERIVED_FROM, EVALUATED_ON, RELATED_TO, PART_OF

IMPORTANT: Respond with ONLY the JSON object. No explanation or markdown.`;

        const relationContent = await ollamaChat(relationPrompt);

        // æ–°ã—ã„JSONè§£æãƒ»ä¿®å¾©é–¢æ•°ã‚’ä½¿ç”¨
        interface RelationResult {
          relations: Array<{ type: string; sourceId: string; targetId: string; confidence?: number; description?: string }>;
        }
        
        const parsedRelations = await parseJsonWithRetry<RelationResult>(
          relationContent,
          async () => {
            // ãƒªãƒˆãƒ©ã‚¤æ™‚ã®ç°¡æ½”ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            const simpleIds = paperEntities.slice(0, 5).map(e => e.tempId).join(',');
            return await ollamaChat(`Output ONLY JSON: {"relations":[{"type":"RELATED_TO","sourceId":"e1","targetId":"e2","confidence":0.8}]}. Use IDs: ${simpleIds}`);
          }
        );

        if (parsedRelations) {
          for (const r of parsedRelations.relations || []) {
            if (!r.type || !r.sourceId || !r.targetId) continue;
            allRelations.push({
              type: r.type,
              sourceTempId: r.sourceId,
              targetTempId: r.targetId,
              confidence: r.confidence || 0.7,
              description: r.description,
            });
          }
        }
        // é–¢ä¿‚ã®è§£æã‚¨ãƒ©ãƒ¼ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¯å–å¾—æ¸ˆã¿ï¼‰
      }

      processed++;
      if (processed % 10 === 0) {
        console.log(`   âœ“ ${processed}/${keyPapers.length} è«–æ–‡å‡¦ç†å®Œäº† (ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: ${allEntities.length}, é–¢ä¿‚: ${allRelations.length})`);
      }
    } catch (e) {
      console.log(`   âš  ${paper.title.slice(0, 40)}... ã‚¨ãƒ©ãƒ¼: ${(e as Error).message}`);
    }
  }

  console.log(`\nâœ… æŠ½å‡ºå®Œäº†:`);
  console.log(`   â€¢ ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: ${allEntities.length}ä»¶`);
  console.log(`   â€¢ é–¢ä¿‚: ${allRelations.length}ä»¶`);

  return { entities: allEntities, relations: allRelations, papers };
}

function generateMermaidFromGraphRAG(result: GraphRAGResult): string {
  const { entities, relations } = result;

  // ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’ã‚¿ã‚¤ãƒ—åˆ¥ã«åˆ†é¡
  const aiModels = entities.filter((e) => e.type === 'AIModel');
  const techniques = entities.filter((e) => e.type === 'Technique');
  const organizations = entities.filter((e) => e.type === 'Organization');
  const concepts = entities.filter((e) => e.type === 'Concept');

  // é‡è¦ãªã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’é¸æŠï¼ˆå‡ºç¾é »åº¦ãƒ»é–¢ä¿‚æ•°ãŒå¤šã„ã‚‚ã®ï¼‰
  const relationCount = new Map<string, number>();
  for (const rel of relations) {
    const sourceKey = rel.sourceTempId;
    const targetKey = rel.targetTempId;
    relationCount.set(sourceKey, (relationCount.get(sourceKey) || 0) + 1);
    relationCount.set(targetKey, (relationCount.get(targetKey) || 0) + 1);
  }

  // é–¢ä¿‚ã®å¤šã„ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’å„ªå…ˆ
  const sortedModels = aiModels
    .map((e) => ({ ...e, relCount: relationCount.get(e.tempId) || 0 }))
    .sort((a, b) => b.relCount - a.relCount)
    .slice(0, 35);

  const sortedTechniques = techniques
    .map((e) => ({ ...e, relCount: relationCount.get(e.tempId) || 0 }))
    .sort((a, b) => b.relCount - a.relCount)
    .slice(0, 25);

  const sortedOrgs = organizations
    .map((e) => ({ ...e, relCount: relationCount.get(e.tempId) || 0 }))
    .sort((a, b) => b.relCount - a.relCount)
    .slice(0, 15);

  const sortedConcepts = concepts
    .map((e) => ({ ...e, relCount: relationCount.get(e.tempId) || 0 }))
    .sort((a, b) => b.relCount - a.relCount)
    .slice(0, 20);

  // ãƒãƒ¼ãƒ‰IDç”Ÿæˆ
  const nodeId = (name: string) =>
    name
      .toLowerCase()
      .replace(/[^a-z0-9]/g, '_')
      .slice(0, 20);

  // entityIdMapä½œæˆ
  const entityIdMap = new Map<string, string>();
  for (const e of [...sortedModels, ...sortedTechniques, ...sortedOrgs, ...sortedConcepts]) {
    entityIdMap.set(e.tempId, nodeId(e.name));
  }

  // AIãƒ¢ãƒ‡ãƒ«ç³»è­œå›³ã‚’ç”Ÿæˆ
  let modelMermaid = `\`\`\`mermaid
flowchart TB
    %% === AIãƒ¢ãƒ‡ãƒ«ç³»è­œ ===
    
    %% GPTç³»
    subgraph GPT["ğŸ”µ GPTç³»åˆ—"]
        direction TB
`;

  // GPTç³»ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚£ãƒ«ã‚¿
  const gptModels = sortedModels.filter(m => 
    m.name.toLowerCase().includes('gpt') || 
    m.name.toLowerCase().includes('chatgpt') ||
    m.name.toLowerCase().includes('openai')
  );
  for (const model of gptModels) {
    const id = nodeId(model.name);
    modelMermaid += `        ${id}["${model.name}"]\n`;
  }

  modelMermaid += `    end

    %% LLaMA/Metaç³»
    subgraph LLaMA["ğŸ¦™ LLaMA/Metaç³»åˆ—"]
        direction TB
`;

  const llamaModels = sortedModels.filter(m => 
    m.name.toLowerCase().includes('llama') || 
    m.name.toLowerCase().includes('meta') ||
    m.name.toLowerCase().includes('opt')
  );
  for (const model of llamaModels) {
    const id = nodeId(model.name);
    modelMermaid += `        ${id}["${model.name}"]\n`;
  }

  modelMermaid += `    end

    %% BERT/Transformerç³»
    subgraph BERT["ğŸ”¶ BERT/Encoderç³»åˆ—"]
        direction TB
`;

  const bertModels = sortedModels.filter(m => 
    m.name.toLowerCase().includes('bert') || 
    m.name.toLowerCase().includes('roberta') ||
    m.name.toLowerCase().includes('t5') ||
    m.name.toLowerCase().includes('encoder')
  );
  for (const model of bertModels) {
    const id = nodeId(model.name);
    modelMermaid += `        ${id}["${model.name}"]\n`;
  }

  modelMermaid += `    end

    %% ãã®ä»–ä¸»è¦ãƒ¢ãƒ‡ãƒ«
    subgraph Others["ğŸŸ¢ ãã®ä»–ä¸»è¦ãƒ¢ãƒ‡ãƒ«"]
        direction TB
`;

  const usedModels = new Set([...gptModels, ...llamaModels, ...bertModels].map(m => m.tempId));
  const otherModels = sortedModels.filter(m => !usedModels.has(m.tempId));
  for (const model of otherModels.slice(0, 15)) {
    const id = nodeId(model.name);
    modelMermaid += `        ${id}["${model.name}"]\n`;
  }

  modelMermaid += `    end

    %% çµ„ç¹”
    subgraph Orgs["ğŸ¢ é–‹ç™ºçµ„ç¹”"]
`;

  for (const org of sortedOrgs.slice(0, 10)) {
    const id = nodeId(org.name);
    modelMermaid += `        ${id}["${org.name}"]\n`;
  }

  modelMermaid += `    end

    %% AIãƒ¢ãƒ‡ãƒ«é–“ã®é–¢ä¿‚
`;

  // AIãƒ¢ãƒ‡ãƒ«é–¢é€£ã®é–¢ä¿‚ã®ã¿æŠ½å‡º
  const addedModelEdges = new Set<string>();
  const modelIds = new Set(sortedModels.map(m => m.tempId));
  const orgIds = new Set(sortedOrgs.map(o => o.tempId));

  for (const rel of relations) {
    const sourceId = entityIdMap.get(rel.sourceTempId);
    const targetId = entityIdMap.get(rel.targetTempId);
    
    // ãƒ¢ãƒ‡ãƒ«-ãƒ¢ãƒ‡ãƒ« ã¾ãŸã¯ ãƒ¢ãƒ‡ãƒ«-çµ„ç¹” ã®é–¢ä¿‚ã®ã¿
    const isModelRel = modelIds.has(rel.sourceTempId) || modelIds.has(rel.targetTempId);
    const isOrgRel = orgIds.has(rel.sourceTempId) || orgIds.has(rel.targetTempId);
    
    if (sourceId && targetId && sourceId !== targetId && (isModelRel || isOrgRel)) {
      const edgeKey = `${sourceId}-${targetId}`;
      if (!addedModelEdges.has(edgeKey)) {
        addedModelEdges.add(edgeKey);
        const label = rel.type.replace(/_/g, ' ').toLowerCase();
        modelMermaid += `    ${sourceId} -->|${label}| ${targetId}\n`;
      }
    }
  }

  modelMermaid += `
    %% ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°
    classDef gpt fill:#10a37f,color:white
    classDef llama fill:#667eea,color:white
    classDef bert fill:#ff9800,color:white
    classDef other fill:#4caf50,color:white
    classDef org fill:#9c27b0,color:white
\`\`\``;

  // æŠ€è¡“ç³»è­œå›³ã‚’ç”Ÿæˆ
  let techMermaid = `\`\`\`mermaid
flowchart TB
    %% === ä¸»è¦æŠ€è¡“ç³»è­œ ===
    
    %% Attention/Transformerç³»æŠ€è¡“
    subgraph Attention["âš¡ Attention/Transformer"]
        direction TB
`;

  const attentionTechs = sortedTechniques.filter(t => 
    t.name.toLowerCase().includes('attention') || 
    t.name.toLowerCase().includes('transformer') ||
    t.name.toLowerCase().includes('self-attention')
  );
  for (const tech of attentionTechs) {
    const id = nodeId(tech.name);
    techMermaid += `        ${id}["${tech.name}"]\n`;
  }

  techMermaid += `    end

    %% æ¨è«–ãƒ»ReasoningæŠ€è¡“
    subgraph Reasoning["ğŸ§  æ¨è«–ãƒ»Reasoning"]
        direction TB
`;

  const reasoningTechs = sortedTechniques.filter(t => 
    t.name.toLowerCase().includes('chain') || 
    t.name.toLowerCase().includes('thought') ||
    t.name.toLowerCase().includes('reasoning') ||
    t.name.toLowerCase().includes('cot') ||
    t.name.toLowerCase().includes('step')
  );
  for (const tech of reasoningTechs) {
    const id = nodeId(tech.name);
    techMermaid += `        ${id}["${tech.name}"]\n`;
  }

  techMermaid += `    end

    %% å­¦ç¿’ãƒ»æœ€é©åŒ–æŠ€è¡“
    subgraph Training["ğŸ“š å­¦ç¿’ãƒ»æœ€é©åŒ–"]
        direction TB
`;

  const trainingTechs = sortedTechniques.filter(t => 
    t.name.toLowerCase().includes('fine-tuning') || 
    t.name.toLowerCase().includes('rlhf') ||
    t.name.toLowerCase().includes('lora') ||
    t.name.toLowerCase().includes('training') ||
    t.name.toLowerCase().includes('learning') ||
    t.name.toLowerCase().includes('instruction')
  );
  for (const tech of trainingTechs) {
    const id = nodeId(tech.name);
    techMermaid += `        ${id}["${tech.name}"]\n`;
  }

  techMermaid += `    end

    %% ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŠ€è¡“
    subgraph Prompting["ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°"]
        direction TB
`;

  const promptTechs = sortedTechniques.filter(t => 
    t.name.toLowerCase().includes('prompt') || 
    t.name.toLowerCase().includes('few-shot') ||
    t.name.toLowerCase().includes('zero-shot') ||
    t.name.toLowerCase().includes('in-context')
  );
  for (const tech of promptTechs) {
    const id = nodeId(tech.name);
    techMermaid += `        ${id}["${tech.name}"]\n`;
  }

  techMermaid += `    end

    %% ãã®ä»–æŠ€è¡“
    subgraph OtherTech["ğŸ”§ ãã®ä»–æŠ€è¡“"]
        direction TB
`;

  const usedTechs = new Set([...attentionTechs, ...reasoningTechs, ...trainingTechs, ...promptTechs].map(t => t.tempId));
  const otherTechs = sortedTechniques.filter(t => !usedTechs.has(t.tempId));
  for (const tech of otherTechs.slice(0, 12)) {
    const id = nodeId(tech.name);
    techMermaid += `        ${id}["${tech.name}"]\n`;
  }

  techMermaid += `    end

    %% ã‚³ãƒ³ã‚»ãƒ—ãƒˆ
    subgraph Concepts["ğŸ’¡ ã‚³ãƒ³ã‚»ãƒ—ãƒˆ"]
        direction TB
`;

  for (const concept of sortedConcepts.slice(0, 12)) {
    const id = nodeId(concept.name);
    techMermaid += `        ${id}["${concept.name}"]\n`;
  }

  techMermaid += `    end

    %% æŠ€è¡“é–“ã®é–¢ä¿‚
`;

  // æŠ€è¡“é–¢é€£ã®é–¢ä¿‚ã®ã¿æŠ½å‡º
  const addedTechEdges = new Set<string>();
  const techIds = new Set(sortedTechniques.map(t => t.tempId));
  const conceptIds = new Set(sortedConcepts.map(c => c.tempId));

  for (const rel of relations) {
    const sourceId = entityIdMap.get(rel.sourceTempId);
    const targetId = entityIdMap.get(rel.targetTempId);
    
    // æŠ€è¡“-æŠ€è¡“ ã¾ãŸã¯ æŠ€è¡“-ã‚³ãƒ³ã‚»ãƒ—ãƒˆ ã®é–¢ä¿‚ã®ã¿
    const isTechRel = techIds.has(rel.sourceTempId) || techIds.has(rel.targetTempId);
    const isConceptRel = conceptIds.has(rel.sourceTempId) || conceptIds.has(rel.targetTempId);
    
    if (sourceId && targetId && sourceId !== targetId && (isTechRel || isConceptRel)) {
      const edgeKey = `${sourceId}-${targetId}`;
      if (!addedTechEdges.has(edgeKey)) {
        addedTechEdges.add(edgeKey);
        const label = rel.type.replace(/_/g, ' ').toLowerCase();
        techMermaid += `    ${sourceId} -->|${label}| ${targetId}\n`;
      }
    }
  }

  techMermaid += `
    %% ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°  
    classDef attention fill:#e91e63,color:white
    classDef reasoning fill:#3f51b5,color:white
    classDef training fill:#009688,color:white
    classDef prompt fill:#ff5722,color:white
    classDef concept fill:#607d8b,color:white
\`\`\``;

  return { modelMermaid, techMermaid };
}

function generateMarkdownReport(result: GraphRAGResult): string {
  const { entities, relations, papers } = result;

  // ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£çµ±è¨ˆ
  const entityByType = new Map<string, ExtractedEntity[]>();
  for (const e of entities) {
    const existing = entityByType.get(e.type) || [];
    existing.push(e);
    entityByType.set(e.type, existing);
  }

  // é–¢ä¿‚çµ±è¨ˆ
  const relationByType = new Map<string, number>();
  for (const r of relations) {
    relationByType.set(r.type, (relationByType.get(r.type) || 0) + 1);
  }

  let md = `# ç”ŸæˆAIé€²åŒ–ã®ç³»è­œ (GraphRAGåˆ†æ)

> YAGOKORO GraphRAG Engine ã«ã‚ˆã‚‹è‡ªå‹•ç”Ÿæˆ
>
> ç·è«–æ–‡æ•°: ${papers.length}ä»¶
> æŠ½å‡ºã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: ${entities.length}ä»¶
> æŠ½å‡ºé–¢ä¿‚: ${relations.length}ä»¶
> ç”Ÿæˆæ—¥æ™‚: ${new Date().toISOString()}

## ğŸ“Š GraphRAGåˆ†ææ¦‚è¦

æœ¬åˆ†æã¯ã€åé›†ã—ãŸ${papers.length}ä»¶ã®å­¦è¡“è«–æ–‡ã‹ã‚‰ã€GraphRAGã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½¿ç”¨ã—ã¦
ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ï¼ˆAIãƒ¢ãƒ‡ãƒ«ã€çµ„ç¹”ã€æŠ€è¡“ã€ã‚³ãƒ³ã‚»ãƒ—ãƒˆï¼‰ã¨ã€ãã‚Œã‚‰ã®é–“ã®é–¢ä¿‚æ€§ã‚’
è‡ªå‹•æŠ½å‡ºã—ã€ç”ŸæˆAIã®é€²åŒ–ã®ç³»è­œã‚’å¯è¦–åŒ–ã—ãŸã‚‚ã®ã§ã™ã€‚

---

## ğŸ“ˆ ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£çµ±è¨ˆ

| ã‚¿ã‚¤ãƒ— | ä»¶æ•° | ä¸»è¦ãªã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ |
|--------|------|-------------------|
`;

  for (const [type, ents] of entityByType) {
    const topEnts = ents
      .sort((a, b) => b.confidence - a.confidence)
      .slice(0, 5)
      .map((e) => e.name)
      .join(', ');
    md += `| ${type} | ${ents.length} | ${topEnts} |\n`;
  }

  md += `

---

## ğŸ”— é–¢ä¿‚çµ±è¨ˆ

| é–¢ä¿‚ã‚¿ã‚¤ãƒ— | ä»¶æ•° |
|------------|------|
`;

  for (const [type, count] of relationByType) {
    md += `| ${type} | ${count} |\n`;
  }

  // 2ã¤ã®ç³»è­œå›³ã‚’å–å¾—
  const { modelMermaid, techMermaid } = generateMermaidFromGraphRAG(result);

  md += `

---

## ğŸ¤– AIãƒ¢ãƒ‡ãƒ«ç³»è­œå›³

ä»¥ä¸‹ã¯GraphRAGã§æŠ½å‡ºã•ã‚ŒãŸAIãƒ¢ãƒ‡ãƒ«é–“ã®é–¢ä¿‚ã‚’å¯è¦–åŒ–ã—ãŸç³»è­œå›³ã§ã™ã€‚

${modelMermaid}

---

## âš™ï¸ ä¸»è¦æŠ€è¡“ç³»è­œå›³

ä»¥ä¸‹ã¯GraphRAGã§æŠ½å‡ºã•ã‚ŒãŸæŠ€è¡“ãƒ»ã‚³ãƒ³ã‚»ãƒ—ãƒˆé–“ã®é–¢ä¿‚ã‚’å¯è¦–åŒ–ã—ãŸç³»è­œå›³ã§ã™ã€‚

${techMermaid}

---

## ğŸ“‹ ä¸»è¦AIãƒ¢ãƒ‡ãƒ«ä¸€è¦§

`;

  const aiModels = entityByType.get('AIModel') || [];
  for (const model of aiModels.sort((a, b) => b.confidence - a.confidence).slice(0, 20)) {
    md += `- **${model.name}** (confidence: ${(model.confidence * 100).toFixed(0)}%)\n`;
    if (model.description) {
      md += `  - ${model.description}\n`;
    }
  }

  md += `

---

## ğŸ”§ ä¸»è¦æŠ€è¡“ä¸€è¦§

`;

  const techniques = entityByType.get('Technique') || [];
  for (const tech of techniques.sort((a, b) => b.confidence - a.confidence).slice(0, 25)) {
    md += `- **${tech.name}** (confidence: ${(tech.confidence * 100).toFixed(0)}%)\n`;
    if (tech.description) {
      md += `  - ${tech.description}\n`;
    }
  }

  md += `

---

## ğŸ’¡ ä¸»è¦ã‚³ãƒ³ã‚»ãƒ—ãƒˆ

`;

  const concepts = entityByType.get('Concept') || [];
  for (const concept of concepts.sort((a, b) => b.confidence - a.confidence).slice(0, 20)) {
    md += `- **${concept.name}** (confidence: ${(concept.confidence * 100).toFixed(0)}%)\n`;
    if (concept.description) {
      md += `  - ${concept.description}\n`;
    }
  }

  md += `

---

## ğŸ¢ ä¸»è¦çµ„ç¹”

`;

  const orgs = entityByType.get('Organization') || [];
  for (const org of orgs.sort((a, b) => b.confidence - a.confidence).slice(0, 15)) {
    md += `- **${org.name}** (confidence: ${(org.confidence * 100).toFixed(0)}%)\n`;
  }

  md += `

---

## ğŸ“š åˆ†æå¯¾è±¡è«–æ–‡

æœ¬åˆ†æã¯ä»¥ä¸‹ã®è«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«åŸºã¥ã„ã¦ã„ã¾ã™:

| å¹´ | è«–æ–‡æ•° |
|----|--------|
`;

  const byYear = new Map<number, number>();
  for (const p of papers) {
    byYear.set(p.year, (byYear.get(p.year) || 0) + 1);
  }

  for (const [year, count] of Array.from(byYear.entries()).sort((a, b) => a[0] - b[0])) {
    md += `| ${year} | ${count} |\n`;
  }

  md += `

---

*Generated by YAGOKORO GraphRAG Engine*
`;

  return md;
}

function generateJsonOutput(result: GraphRAGResult): object {
  return {
    metadata: {
      generatedAt: new Date().toISOString(),
      engine: 'YAGOKORO GraphRAG',
      totalPapers: result.papers.length,
      totalEntities: result.entities.length,
      totalRelations: result.relations.length,
    },
    entities: result.entities.map((e) => ({
      name: e.name,
      type: e.type,
      confidence: e.confidence,
      description: e.description,
    })),
    relations: result.relations.map((r) => ({
      type: r.type,
      sourceId: r.sourceTempId,
      targetId: r.targetTempId,
      confidence: r.confidence,
      description: r.description,
    })),
    papers: result.papers.map((p) => ({
      title: p.title,
      arxivId: p.arxivId,
      year: p.year,
      category: p.category,
    })),
  };
}

async function main() {
  console.log('ğŸ”· YAGOKORO GraphRAG - ç”ŸæˆAIç³»è­œåˆ†æ\n');
  console.log(`ğŸ¦™ Ollamaãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: ${OLLAMA_BASE_URL} (${OLLAMA_MODEL})`);

  // è«–æ–‡åé›†
  console.log('\nğŸ“š è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ä¸­...');
  const papers = await collectPapers();
  console.log(`   ${papers.length}ä»¶ã®è«–æ–‡ã‚’ç™ºè¦‹`);

  // GraphRAGæŠ½å‡º
  const result = await extractEntitiesAndRelations(papers);

  // å‡ºåŠ›ç”Ÿæˆ
  await mkdir(OUTPUT_DIR, { recursive: true });

  console.log('\nğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆä¸­...');

  // 1. ãƒ¡ã‚¤ãƒ³ãƒ¬ãƒãƒ¼ãƒˆ
  const report = generateMarkdownReport(result);
  await writeFile(join(OUTPUT_DIR, 'genai-genealogy-graphrag.md'), report);

  // 2. JSONãƒ‡ãƒ¼ã‚¿
  const jsonData = generateJsonOutput(result);
  await writeFile(join(OUTPUT_DIR, 'genai-graphrag-data.json'), JSON.stringify(jsonData, null, 2));

  console.log(`
âœ… GraphRAGåˆ†æå®Œäº†!

ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:
   â€¢ outputs/genai-genealogy-graphrag.md - GraphRAGç³»è­œãƒ¬ãƒãƒ¼ãƒˆ
   â€¢ outputs/genai-graphrag-data.json    - æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿

ğŸ“Š æŠ½å‡ºçµ±è¨ˆ:
   â€¢ è«–æ–‡æ•°: ${papers.length}ä»¶
   â€¢ ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: ${result.entities.length}ä»¶
   â€¢ é–¢ä¿‚: ${result.relations.length}ä»¶
`);
}

main().catch(console.error);

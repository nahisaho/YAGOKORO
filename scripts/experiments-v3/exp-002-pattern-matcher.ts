/**
 * EXP-002: PatternMatcher å®Ÿé¨“
 * 
 * v3.0.0ã®æ–°æ©Ÿèƒ½ - å‹•è©ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹é–¢ä¿‚ã‚¿ã‚¤ãƒ—æ¨è«–
 */
import { PatternMatcher } from '../../libs/extractor/src/pattern/pattern-matcher.js';
import type { DocumentEntity } from '../../libs/extractor/src/types.js';
import * as fs from 'fs';
import * as path from 'path';

async function runExperiment() {
  console.log('='.repeat(60));
  console.log('EXP-002: PatternMatcher ã«ã‚ˆã‚‹é–¢ä¿‚ã‚¿ã‚¤ãƒ—æ¨è«–');
  console.log('='.repeat(60));
  
  // ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå®Ÿéš›ã®è«–æ–‡ã‹ã‚‰æŠ½å‡ºã—ãŸæ–‡ç« ï¼‰
  const testTexts = [
    // DEVELOPED_BY ãƒ‘ã‚¿ãƒ¼ãƒ³
    "BERT was developed by Google AI Language team in 2018.",
    "GPT-3 was created by OpenAI researchers.",
    "The Transformer architecture was introduced by Vaswani et al.",
    
    // TRAINED_ON ãƒ‘ã‚¿ãƒ¼ãƒ³
    "BERT was trained on BookCorpus and Wikipedia datasets.",
    "The model was fine-tuned on the SQuAD dataset.",
    "GPT-3 was trained using a massive web crawl corpus.",
    
    // USES_TECHNIQUE ãƒ‘ã‚¿ãƒ¼ãƒ³
    "BERT uses masked language modeling for pre-training.",
    "GPT-3 employs few-shot learning techniques.",
    "The model is based on the Transformer architecture.",
    
    // DERIVED_FROM ãƒ‘ã‚¿ãƒ¼ãƒ³
    "RoBERTa is derived from BERT with improved training.",
    "DistilBERT was distilled from BERT using knowledge distillation.",
    "GPT-2 builds upon the original GPT architecture.",
    
    // EVALUATED_ON ãƒ‘ã‚¿ãƒ¼ãƒ³
    "BERT was evaluated on GLUE benchmark tasks.",
    "The model achieved state-of-the-art results on SQuAD.",
    "Performance was measured on the MMLU benchmark.",
    
    // COLLABORATES_WITH ãƒ‘ã‚¿ãƒ¼ãƒ³
    "Google and DeepMind collaborated on this research.",
    "The work was done in partnership with Stanford University.",
  ];
  
  // ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®å®šç¾©
  const entities: DocumentEntity[] = [
    { id: '1', name: 'BERT', type: 'AIModel', mentions: [] },
    { id: '2', name: 'GPT-3', type: 'AIModel', mentions: [] },
    { id: '3', name: 'GPT-2', type: 'AIModel', mentions: [] },
    { id: '4', name: 'GPT', type: 'AIModel', mentions: [] },
    { id: '5', name: 'Transformer', type: 'Architecture', mentions: [] },
    { id: '6', name: 'RoBERTa', type: 'AIModel', mentions: [] },
    { id: '7', name: 'DistilBERT', type: 'AIModel', mentions: [] },
    { id: '8', name: 'Google AI', type: 'Organization', mentions: [] },
    { id: '9', name: 'OpenAI', type: 'Organization', mentions: [] },
    { id: '10', name: 'DeepMind', type: 'Organization', mentions: [] },
    { id: '11', name: 'Google', type: 'Organization', mentions: [] },
    { id: '12', name: 'Stanford University', type: 'Organization', mentions: [] },
    { id: '13', name: 'BookCorpus', type: 'Dataset', mentions: [] },
    { id: '14', name: 'Wikipedia', type: 'Dataset', mentions: [] },
    { id: '15', name: 'SQuAD', type: 'Benchmark', mentions: [] },
    { id: '16', name: 'GLUE', type: 'Benchmark', mentions: [] },
    { id: '17', name: 'MMLU', type: 'Benchmark', mentions: [] },
    { id: '18', name: 'masked language modeling', type: 'Technique', mentions: [] },
    { id: '19', name: 'few-shot learning', type: 'Technique', mentions: [] },
    { id: '20', name: 'knowledge distillation', type: 'Technique', mentions: [] },
  ];
  
  // PatternMatcherã®åˆæœŸåŒ–
  const matcher = new PatternMatcher({
    minConfidence: 0.3,
    useDefaultPatterns: true,
    entityWindowSize: 100,
  });
  
  console.log('\nğŸ” ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°å®Ÿè¡Œä¸­...');
  console.log(`   ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³`);
  console.log(`   æœ€å°ä¿¡é ¼åº¦: 0.3`);
  console.log(`   ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦: 100æ–‡å­—`);
  
  const allMatches: any[] = [];
  
  // å„ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
  testTexts.forEach((text, index) => {
    const matches = matcher.match(text, entities);
    
    if (matches.length > 0) {
      matches.forEach(match => {
        allMatches.push({
          textIndex: index + 1,
          text: text,
          pattern: match.patternName,
          relationType: match.relationType,
          confidence: match.confidence,
          source: match.sourceEntity?.name || match.matchedText,
          target: match.targetEntity?.name || 'N/A',
          matchedText: match.matchedText,
        });
      });
    }
  });
  
  console.log('\nğŸ“Š ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°çµæœ:');
  console.log(`   ç·ãƒ†ã‚­ã‚¹ãƒˆæ•°: ${testTexts.length}`);
  console.log(`   æ¤œå‡ºãƒãƒƒãƒæ•°: ${allMatches.length}`);
  
  // é–¢ä¿‚ã‚¿ã‚¤ãƒ—åˆ¥ã®çµ±è¨ˆ
  const byRelationType = allMatches.reduce((acc, m) => {
    acc[m.relationType] = (acc[m.relationType] || 0) + 1;
    return acc;
  }, {} as Record<string, number>);
  
  console.log('\nğŸ“ˆ é–¢ä¿‚ã‚¿ã‚¤ãƒ—åˆ¥æ¤œå‡ºæ•°:');
  console.log('â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”');
  console.log('â”‚ é–¢ä¿‚ã‚¿ã‚¤ãƒ—           â”‚ æ¤œå‡ºæ•° â”‚');
  console.log('â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤');
  Object.entries(byRelationType).sort((a, b) => b[1] - a[1]).forEach(([type, count]) => {
    console.log(`â”‚ ${type.padEnd(20)} â”‚ ${String(count).padStart(6)} â”‚`);
  });
  console.log('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜');
  
  // è©³ç´°çµæœ
  console.log('\nğŸ” æ¤œå‡ºã•ã‚ŒãŸé–¢ä¿‚å€™è£œï¼ˆä¸Šä½15ä»¶ï¼‰:');
  console.log('â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”');
  console.log('â”‚ No â”‚ ã‚½ãƒ¼ã‚¹               â”‚ é–¢ä¿‚ã‚¿ã‚¤ãƒ—           â”‚ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ           â”‚ ä¿¡é ¼åº¦ â”‚');
  console.log('â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤');
  
  allMatches.slice(0, 15).forEach((match, i) => {
    const source = (match.source || '-').substring(0, 20).padEnd(20);
    const rel = match.relationType.substring(0, 20).padEnd(20);
    const target = (match.target || '-').substring(0, 20).padEnd(20);
    const conf = match.confidence.toFixed(2).padStart(6);
    console.log(`â”‚ ${String(i + 1).padStart(2)} â”‚ ${source} â”‚ ${rel} â”‚ ${target} â”‚ ${conf} â”‚`);
  });
  console.log('â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜');
  
  // ä½¿ç”¨ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ä¸€è¦§
  const patternUsage = allMatches.reduce((acc, m) => {
    acc[m.pattern] = (acc[m.pattern] || 0) + 1;
    return acc;
  }, {} as Record<string, number>);
  
  console.log('\nğŸ¯ ä½¿ç”¨ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³:');
  Object.entries(patternUsage).sort((a, b) => b[1] - a[1]).forEach(([pattern, count]) => {
    console.log(`   - ${pattern}: ${count}å›`);
  });
  
  // çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
  const outputPath = path.join(process.cwd(), 'outputs/experiments/exp-002-results.json');
  fs.writeFileSync(outputPath, JSON.stringify({
    experiment: 'EXP-002',
    title: 'PatternMatcher ã«ã‚ˆã‚‹é–¢ä¿‚ã‚¿ã‚¤ãƒ—æ¨è«–',
    timestamp: new Date().toISOString(),
    config: {
      minConfidence: 0.3,
      useDefaultPatterns: true,
      entityWindowSize: 100,
    },
    statistics: {
      totalTexts: testTexts.length,
      totalMatches: allMatches.length,
      byRelationType,
      patternUsage,
    },
    results: allMatches,
  }, null, 2));
  
  console.log(`\nâœ… çµæœã‚’ä¿å­˜: ${outputPath}`);
  
  return {
    totalMatches: allMatches.length,
    byRelationType,
    patternUsage,
  };
}

runExperiment().catch(console.error);

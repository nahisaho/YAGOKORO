#!/usr/bin/env node
/**
 * ç”ŸæˆAIç³»è­œè«–æ–‡ã‚¤ãƒ³ã‚¸ã‚§ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
 *
 * arXivã‹ã‚‰è«–æ–‡ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€Docling(ãƒ­ãƒ¼ã‚«ãƒ«)ã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã€
 * LazyGraphRAGç”¨ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
 *
 * Usage:
 *   npx tsx scripts/ingest-genai-papers.ts
 *
 * Options:
 *   --dry-run     å®Ÿéš›ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã›ãšãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
 *   --category    ç‰¹å®šã‚«ãƒ†ã‚´ãƒªã®ã¿å‡¦ç†
 *   --limit       å‡¦ç†ã™ã‚‹è«–æ–‡æ•°ã‚’åˆ¶é™
 */

import * as fs from 'fs';
import * as path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// è«–æ–‡ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿
const papersPath = path.join(__dirname, '../data/genai-papers.json');
const papersData = JSON.parse(fs.readFileSync(papersPath, 'utf-8'));

interface Paper {
  arxivId: string;
  title: string;
  year: number;
}

interface Category {
  name: string;
  papers: Paper[];
}

interface ProcessResult {
  arxivId: string;
  title: string;
  status: 'success' | 'failed' | 'skipped';
  chunks?: number;
  error?: string;
}

async function main() {
  const args = process.argv.slice(2);
  const dryRun = args.includes('--dry-run');
  const categoryFilter = args.find(a => a.startsWith('--category='))?.split('=')[1];
  const limitArg = args.find(a => a.startsWith('--limit='))?.split('=')[1];
  const limit = limitArg ? parseInt(limitArg, 10) : undefined;

  console.log('ğŸ§  ç”ŸæˆAIç³»è­œè«–æ–‡ã‚¤ãƒ³ã‚¸ã‚§ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ\n');

  // Doclingç’°å¢ƒãƒã‚§ãƒƒã‚¯
  const venvPython = path.join(__dirname, '../.venv/bin/python');
  if (!fs.existsSync(venvPython) && !dryRun) {
    console.error('âŒ Pythonä»®æƒ³ç’°å¢ƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“');
    console.log('   ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãã ã•ã„:');
    console.log('   python3 -m venv .venv && source .venv/bin/activate && pip install docling');
    process.exit(1);
  }

  // ã‚«ãƒ†ã‚´ãƒªã¨è«–æ–‡ã‚’åé›†
  const categories: Record<string, Category> = papersData.categories;
  const allPapers: Array<Paper & { category: string }> = [];

  for (const [key, cat] of Object.entries(categories)) {
    if (categoryFilter && key !== categoryFilter) continue;
    for (const paper of cat.papers) {
      allPapers.push({ ...paper, category: cat.name });
    }
  }

  const papersToProcess = limit ? allPapers.slice(0, limit) : allPapers;

  console.log(`ğŸ“š è«–æ–‡ç·æ•°: ${papersData.totalPapers}`);
  console.log(`ğŸ“‚ å‡¦ç†å¯¾è±¡: ${papersToProcess.length} ä»¶`);
  if (categoryFilter) console.log(`ğŸ·ï¸  ã‚«ãƒ†ã‚´ãƒª: ${categoryFilter}`);
  if (dryRun) console.log('ğŸ” ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ ãƒ¢ãƒ¼ãƒ‰\n');
  console.log('â”€'.repeat(60) + '\n');

  // ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«è¡¨ç¤º
  const byCategory = new Map<string, Paper[]>();
  for (const paper of papersToProcess) {
    const cat = paper.category;
    if (!byCategory.has(cat)) byCategory.set(cat, []);
    byCategory.get(cat)!.push(paper);
  }

  for (const [category, papers] of byCategory) {
    console.log(`\nğŸ“ ${category} (${papers.length}ä»¶)`);
    for (const paper of papers) {
      console.log(`   â€¢ [${paper.arxivId}] ${paper.title} (${paper.year})`);
    }
  }

  if (dryRun) {
    console.log('\nâœ… ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Œäº†ã€‚å®Ÿè¡Œã™ã‚‹ã«ã¯ --dry-run ã‚’å¤–ã—ã¦ãã ã•ã„ã€‚');
    return;
  }

  console.log('\n' + 'â”€'.repeat(60));
  console.log('ğŸš€ ã‚¤ãƒ³ã‚¸ã‚§ã‚¹ãƒˆé–‹å§‹ (Docling ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ¼ãƒ‰)...\n');

  // å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆESMå¯¾å¿œï¼‰
  const { DoclingDocumentProcessor } = await import('../libs/graphrag/src/ingest/index.js');

  const processor = new DoclingDocumentProcessor({
    chunkSize: 1000,
    chunkOverlap: 200,
  });

  const results: ProcessResult[] = [];
  const outputDir = path.join(__dirname, '../data/chunks');
  if (!fs.existsSync(outputDir)) {
    fs.mkdirSync(outputDir, { recursive: true });
  }

  for (let i = 0; i < papersToProcess.length; i++) {
    const paper = papersToProcess[i];
    const progress = `[${i + 1}/${papersToProcess.length}]`;

    console.log(`${progress} å‡¦ç†ä¸­: ${paper.arxivId} - ${paper.title}`);

    try {
      const result = await processor.processArxivPaper(paper.arxivId);

      // ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜
      const chunkFile = path.join(outputDir, `${paper.arxivId.replace(/\./g, '_')}.json`);
      fs.writeFileSync(chunkFile, JSON.stringify({
        arxivId: paper.arxivId,
        title: paper.title,
        category: paper.category,
        year: paper.year,
        paper: result.paper,
        chunks: result.chunks,
        tables: result.tables,
        stats: result.stats,
        processedAt: new Date().toISOString(),
      }, null, 2));

      console.log(`   âœ… ${result.chunks.length} ãƒãƒ£ãƒ³ã‚¯ä½œæˆ (${result.stats.totalCharacters.toLocaleString()} æ–‡å­—, ${result.stats.numTables} ãƒ†ãƒ¼ãƒ–ãƒ«)`);

      results.push({
        arxivId: paper.arxivId,
        title: paper.title,
        status: 'success',
        chunks: result.chunks.length,
      });

      // arXiv APIãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­– + Doclingå‡¦ç†æ™‚é–“è€ƒæ…®ï¼ˆ5ç§’å¾…æ©Ÿï¼‰
      if (i < papersToProcess.length - 1) {
        await sleep(5000);
      }
    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      console.log(`   âŒ ã‚¨ãƒ©ãƒ¼: ${errorMsg}`);

      results.push({
        arxivId: paper.arxivId,
        title: paper.title,
        status: 'failed',
        error: errorMsg,
      });
    }
  }

  // ã‚µãƒãƒªãƒ¼å‡ºåŠ›
  console.log('\n' + 'â•'.repeat(60));
  console.log('ğŸ“Š å‡¦ç†çµæœã‚µãƒãƒªãƒ¼\n');

  const successful = results.filter(r => r.status === 'success');
  const failed = results.filter(r => r.status === 'failed');
  const totalChunks = successful.reduce((sum, r) => sum + (r.chunks || 0), 0);

  console.log(`âœ… æˆåŠŸ: ${successful.length} ä»¶`);
  console.log(`âŒ å¤±æ•—: ${failed.length} ä»¶`);
  console.log(`ğŸ“¦ ç·ãƒãƒ£ãƒ³ã‚¯æ•°: ${totalChunks.toLocaleString()}`);

  if (failed.length > 0) {
    console.log('\nå¤±æ•—ã—ãŸè«–æ–‡:');
    for (const f of failed) {
      console.log(`  â€¢ ${f.arxivId}: ${f.error}`);
    }
  }

  // çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
  const resultFile = path.join(outputDir, '_ingest-results.json');
  fs.writeFileSync(resultFile, JSON.stringify({
    timestamp: new Date().toISOString(),
    summary: {
      total: results.length,
      successful: successful.length,
      failed: failed.length,
      totalChunks,
    },
    results,
  }, null, 2));

  console.log(`\nğŸ“„ çµæœä¿å­˜: ${resultFile}`);
  console.log('âœ¨ å®Œäº†!\n');
}

function sleep(ms: number): Promise<void> {
  return new Promise(resolve => setTimeout(resolve, ms));
}

main().catch(console.error);

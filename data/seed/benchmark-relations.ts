/**
 * AIãƒ¢ãƒ‡ãƒ«ã¨ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯è©•ä¾¡ã®é–¢ä¿‚ã‚’è¿½åŠ 
 */

import neo4j from 'neo4j-driver';

const driver = neo4j.driver(
  'bolt://localhost:7687',
  neo4j.auth.basic('neo4j', 'password')
);

// ãƒ¢ãƒ‡ãƒ«ã¨ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯ã®è©•ä¾¡é–¢ä¿‚
const evaluations = [
  // SWE-bench ã‚¹ã‚³ã‚¢
  { model: 'Claude 3.5 Sonnet', benchmark: 'SWE-bench', score: 49.0, note: '2024å¹´10æœˆæ™‚ç‚¹ã§ãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹' },
  { model: 'GPT-4o', benchmark: 'SWE-bench', score: 33.2, note: '2024å¹´' },
  { model: 'DeepSeek-V3', benchmark: 'SWE-bench', score: 42.0, note: '2024å¹´æœ«' },
  { model: 'Claude 3 Opus', benchmark: 'SWE-bench', score: 22.0, note: '2024å¹´3æœˆ' },
  { model: 'Gemini 1.5 Pro', benchmark: 'SWE-bench', score: 28.5, note: '2024å¹´' },
  
  // MMLU ã‚¹ã‚³ã‚¢
  { model: 'GPT-4', benchmark: 'MMLU', score: 86.4, note: '2023å¹´' },
  { model: 'GPT-4o', benchmark: 'MMLU', score: 88.7, note: '2024å¹´' },
  { model: 'Claude 3 Opus', benchmark: 'MMLU', score: 86.8, note: '2024å¹´3æœˆ' },
  { model: 'Claude 3.5 Sonnet', benchmark: 'MMLU', score: 88.7, note: '2024å¹´6æœˆ' },
  { model: 'Gemini Ultra', benchmark: 'MMLU', score: 90.0, note: '2023å¹´12æœˆ' },
  { model: 'Gemini 1.5 Pro', benchmark: 'MMLU', score: 85.9, note: '2024å¹´' },
  { model: 'Llama 3.1 405B', benchmark: 'MMLU', score: 88.6, note: '2024å¹´7æœˆ' },
  { model: 'Qwen2.5', benchmark: 'MMLU', score: 85.0, note: '72Bç‰ˆ' },
  { model: 'DeepSeek-V3', benchmark: 'MMLU', score: 88.5, note: '2024å¹´æœ«' },
  { model: 'Mixtral 8x22B', benchmark: 'MMLU', score: 77.8, note: 'MoE' },
  { model: 'Phi-3', benchmark: 'MMLU', score: 78.0, note: 'Smallç‰ˆ 3.8B' },
  
  // HumanEval ã‚¹ã‚³ã‚¢
  { model: 'GPT-4', benchmark: 'HumanEval', score: 67.0, note: '2023å¹´' },
  { model: 'GPT-4o', benchmark: 'HumanEval', score: 90.2, note: '2024å¹´' },
  { model: 'Claude 3.5 Sonnet', benchmark: 'HumanEval', score: 92.0, note: '2024å¹´10æœˆ' },
  { model: 'Claude 3 Opus', benchmark: 'HumanEval', score: 84.9, note: '2024å¹´3æœˆ' },
  { model: 'Gemini 1.5 Pro', benchmark: 'HumanEval', score: 84.1, note: '2024å¹´' },
  { model: 'Llama 3.1 405B', benchmark: 'HumanEval', score: 89.0, note: '2024å¹´7æœˆ' },
  { model: 'DeepSeek-V3', benchmark: 'HumanEval', score: 82.6, note: '2024å¹´æœ«' },
  { model: 'Qwen2.5', benchmark: 'HumanEval', score: 84.5, note: '72Bç‰ˆ' },
  { model: 'StarCoder 2', benchmark: 'HumanEval', score: 46.3, note: '15Bç‰ˆ' },
  { model: 'CodeLlama', benchmark: 'HumanEval', score: 53.7, note: '34Bç‰ˆ' },
  { model: 'Phi-3', benchmark: 'HumanEval', score: 62.0, note: 'Smallç‰ˆ' },
  
  // LMSYS Chatbot Arena
  { model: 'GPT-4o', benchmark: 'LMSYS Chatbot Arena', score: 1290, note: 'ELO 2024å¹´' },
  { model: 'Claude 3.5 Sonnet', benchmark: 'LMSYS Chatbot Arena', score: 1280, note: 'ELO 2024å¹´' },
  { model: 'Claude 3 Opus', benchmark: 'LMSYS Chatbot Arena', score: 1248, note: 'ELO 2024å¹´' },
  { model: 'Gemini 1.5 Pro', benchmark: 'LMSYS Chatbot Arena', score: 1260, note: 'ELO 2024å¹´' },
  { model: 'Llama 3.1 405B', benchmark: 'LMSYS Chatbot Arena', score: 1210, note: 'ELO 2024å¹´' },
  { model: 'DeepSeek-V3', benchmark: 'LMSYS Chatbot Arena', score: 1310, note: 'ELO 2024å¹´æœ«' },
  { model: 'Qwen2.5', benchmark: 'LMSYS Chatbot Arena', score: 1150, note: 'ELO 72Bç‰ˆ' },
  
  // GSM8K (æ•°å­¦æŽ¨è«–)
  { model: 'GPT-4', benchmark: 'GSM8K', score: 92.0, note: '2023å¹´' },
  { model: 'Claude 3 Opus', benchmark: 'GSM8K', score: 95.0, note: '2024å¹´' },
  { model: 'Claude 3.5 Sonnet', benchmark: 'GSM8K', score: 96.4, note: '2024å¹´' },
  { model: 'Gemini Ultra', benchmark: 'GSM8K', score: 94.4, note: '2023å¹´' },
  { model: 'Llama 3.1 405B', benchmark: 'GSM8K', score: 96.8, note: '2024å¹´' },
  { model: 'DeepSeek-V3', benchmark: 'GSM8K', score: 89.3, note: '2024å¹´' },
  { model: 'Phi-3', benchmark: 'GSM8K', score: 90.8, note: 'Mediumç‰ˆ' },
  
  // BIG-Bench Hard
  { model: 'GPT-4', benchmark: 'BIG-Bench Hard', score: 83.1, note: '2023å¹´ CoT' },
  { model: 'Claude 3 Opus', benchmark: 'BIG-Bench Hard', score: 86.8, note: '2024å¹´ CoT' },
  { model: 'Gemini Ultra', benchmark: 'BIG-Bench Hard', score: 83.6, note: '2023å¹´ CoT' },
  { model: 'PaLM 2', benchmark: 'BIG-Bench Hard', score: 78.1, note: 'CoT' },
  
  // TruthfulQA
  { model: 'GPT-4', benchmark: 'TruthfulQA', score: 59.0, note: '2023å¹´' },
  { model: 'Claude 3 Opus', benchmark: 'TruthfulQA', score: 64.2, note: '2024å¹´' },
  { model: 'Llama 3.1 405B', benchmark: 'TruthfulQA', score: 52.3, note: '2024å¹´' },
];

async function addBenchmarkRelations() {
  const session = driver.session();
  
  try {
    console.log('ðŸ† ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯è©•ä¾¡é–¢ä¿‚ã®è¿½åŠ ...\n');
    
    let added = 0;
    let skipped = 0;
    
    for (const eval_ of evaluations) {
      // ãƒ¢ãƒ‡ãƒ«ã¨ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
      const checkResult = await session.run(`
        MATCH (m:Entity {name: $model, type: 'AIModel'})
        MATCH (b:Entity {name: $benchmark, type: 'Benchmark'})
        RETURN m, b
      `, { model: eval_.model, benchmark: eval_.benchmark });
      
      if (checkResult.records.length === 0) {
        console.log(`  âš ï¸  ã‚¹ã‚­ãƒƒãƒ—: ${eval_.model} â†’ ${eval_.benchmark} (ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãªã—)`);
        skipped++;
        continue;
      }
      
      // æ—¢å­˜ã®é–¢ä¿‚ã‚’ãƒã‚§ãƒƒã‚¯
      const existingResult = await session.run(`
        MATCH (m:Entity {name: $model})-[r:EVALUATED_ON]->(b:Entity {name: $benchmark})
        RETURN r
      `, { model: eval_.model, benchmark: eval_.benchmark });
      
      if (existingResult.records.length > 0) {
        console.log(`  â­ï¸  æ—¢å­˜: ${eval_.model} â†’ ${eval_.benchmark}`);
        skipped++;
        continue;
      }
      
      // é–¢ä¿‚ã‚’è¿½åŠ 
      await session.run(`
        MATCH (m:Entity {name: $model, type: 'AIModel'})
        MATCH (b:Entity {name: $benchmark, type: 'Benchmark'})
        CREATE (m)-[:EVALUATED_ON {score: $score, note: $note}]->(b)
      `, { 
        model: eval_.model, 
        benchmark: eval_.benchmark,
        score: eval_.score,
        note: eval_.note
      });
      
      console.log(`  âœ… è¿½åŠ : ${eval_.model} â†’ ${eval_.benchmark} (${eval_.score})`);
      added++;
    }
    
    console.log(`\nðŸ“Š çµæžœ: ${added}ä»¶è¿½åŠ , ${skipped}ä»¶ã‚¹ã‚­ãƒƒãƒ—`);
    
    // çµ±è¨ˆã‚’è¡¨ç¤º
    const statsResult = await session.run(`
      MATCH ()-[r:EVALUATED_ON]->()
      RETURN count(r) as count
    `);
    const evalCount = statsResult.records[0].get('count').toNumber();
    
    const relStats = await session.run(`
      MATCH ()-[r]->()
      RETURN type(r) as type, count(*) as count
      ORDER BY count DESC
    `);
    
    console.log('\nðŸ“ˆ ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµ±è¨ˆ:');
    for (const record of relStats.records) {
      console.log(`   ${record.get('type')}: ${record.get('count').toNumber()}`);
    }
    
  } finally {
    await session.close();
    await driver.close();
  }
}

addBenchmarkRelations().catch(console.error);
